<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring Environment环境抽象源码分析篇]]></title>
    <url>%2F2019%2F09%2F16%2FSpring-Environment%E7%8E%AF%E5%A2%83%E6%8A%BD%E8%B1%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E7%AF%87%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring ApplicationContext refresh函数源码分析篇]]></title>
    <url>%2F2019%2F09%2F16%2FSpring-ApplicationContext-refresh%E5%87%BD%E6%95%B0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E7%AF%87%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC源码分析篇]]></title>
    <url>%2F2019%2F09%2F16%2FSpring-IOC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E7%AF%87%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP源码分析篇]]></title>
    <url>%2F2019%2F09%2F16%2FSpring-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E7%AF%87%2F</url>
    <content type="text"></content>
      <categories>
        <category>Spring AOP</category>
      </categories>
      <tags>
        <tag>Spring AOP</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux统计文件夹下的文件数目]]></title>
    <url>%2F2019%2F09%2F15%2FLinux%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6%E6%95%B0%E7%9B%AE%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Shiro常见异常]]></title>
    <url>%2F2019%2F09%2F15%2FShiro%E5%B8%B8%E8%A7%81%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[验证异常 AuthenticationException：Shiro在登录认证中，认证失败需要抛出异常。 CredentitalsException：凭证异常 IncorrectCredentialsException：输入密码错误 ExpiredCredentialsException：凭证过期 AccountException：账号异常 UnknownAccountException：账号不存在 ExcessiveAttemptsException：认证次数超过限制 DisabledAccountException：禁用账号 LockedAccountException：账号被锁定 ConcurrentAccessException：并发访问异常(多个用户同时访问) UnsupportedTokenException：使用了不支持的Token 授权异常 (授权只能在成功的认证之后执行，因为授权数据（角色、权限等）必须总是与已知的标识相关联。这样的已知身份只能在成功登录时获得。) AuthorizationException：Shiro在授权过程，授权异常。 UnauthenticatedException：当尚未完成成功认证时，尝试执行授权操作时引发异常 UnauthorizedException：抛出以指示请求的操作或对请求的资源的访问是不允许的。 HostUnauthorizedException：主机未经验证异常。]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro权限注解AOP实现原理分析]]></title>
    <url>%2F2019%2F09%2F15%2FShiro%E6%9D%83%E9%99%90%E6%B3%A8%E8%A7%A3AOP%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[概述前不久学习了Shiro 1.4.0提供的权限注解实现权限拦截。最开始猜测实现方式是基于AspectJ方式，即基于@Apsect配合@Pointcut和@After,@AfterReturning,@AfterThrowing,@Around,@Before实现。具体Spring基于Aspect，AOP实现类可以查看AnnotationAwareAspectJAutoProxyCreator。在此提供该类的UML图： 你可以看到Spring AOP实现继承类大致为ProxyConfig-&gt;ProxyProcessorSupport-&gt;AbstractAutoProxyCreator -&gt;AbstractAdvisorAutoProxyCreator这条路线。其中Spring常见AOP实现类有3个。 DefaultAdvisorAutoProxyCreator：寻找当前BeanFactory中所有的候选Advisor(有一个切点和一个通知构成)，将这些Advisor应用到所有符合切点的Bean中。基于Advisor 匹配规则。 BeanNameAutoProxyCreator：基于Bean配置名规则 AnnotationAwareAspectJAutoProxyCreator：基于Bean中@AspectJ注解匹配规则。 而Shiro权限注解实现原理是基于DefaultAdvisorAutoProxyCreator实现的。其权限注解处理Advisor实现类是AuthorizationAttributeSourceAdvisor。该类继承了StaticMethodMatcherPointcutAdvisor，内部只对Shiro提供的5个权限注解标注的方法或者类进行切面增强。StaticMethodMatcherPointcutAdvisor是静态方法切点基类，默认匹配所有的的类。StaticMethodMatcherPointcut包括两个主要的子类分别是 JdkRegexpMethodPointcut和NameMatchMethodPointcut。前者提供正则表达式匹配方法切面，而后者作为正则表达式的替代，不处理重载方法，默认实现检测xxx*, *xxx 和*xxx*。 AuthorizationAttributeSourceAdvisor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class AuthorizationAttributeSourceAdvisor extends StaticMethodMatcherPointcutAdvisor &#123; private static final Class&lt;? extends Annotation&gt;[] AUTHZ_ANNOTATION_CLASSES = new Class[] &#123; RequiresPermissions.class, RequiresRoles.class, RequiresUser.class, RequiresGuest.class, RequiresAuthentication.class &#125;; protected SecurityManager securityManager = null; /** * Create a new AuthorizationAttributeSourceAdvisor. */ public AuthorizationAttributeSourceAdvisor() &#123; setAdvice(new AopAllianceAnnotationsAuthorizingMethodInterceptor()); &#125; public SecurityManager getSecurityManager() &#123; return securityManager; &#125; public void setSecurityManager(org.apache.shiro.mgt.SecurityManager securityManager) &#123; this.securityManager = securityManager; &#125; public boolean matches(Method method, Class targetClass) &#123; Method m = method; if ( isAuthzAnnotationPresent(m) ) &#123; return true; &#125; //The 'method' parameter could be from an interface that doesn't have the annotation. //Check to see if the implementation has it. if ( targetClass != null) &#123; try &#123; m = targetClass.getMethod(m.getName(), m.getParameterTypes()); return isAuthzAnnotationPresent(m) || isAuthzAnnotationPresent(targetClass); &#125; catch (NoSuchMethodException ignored) &#123; //default return value is false. If we can't find the method, then obviously //there is no annotation, so just use the default return value. &#125; &#125; return false; &#125; // 检测类上是否存在权限验证注解 private boolean isAuthzAnnotationPresent(Class&lt;?&gt; targetClazz) &#123; for( Class&lt;? extends Annotation&gt; annClass : AUTHZ_ANNOTATION_CLASSES ) &#123; Annotation a = AnnotationUtils.findAnnotation(targetClazz, annClass); if ( a != null ) &#123; return true; &#125; &#125; return false; &#125; // 检测方法上是否存在权限验证注解 private boolean isAuthzAnnotationPresent(Method method) &#123; for( Class&lt;? extends Annotation&gt; annClass : AUTHZ_ANNOTATION_CLASSES ) &#123; Annotation a = AnnotationUtils.findAnnotation(method, annClass); if ( a != null ) &#123; return true; &#125; &#125; return false; &#125;&#125; Shiro注解权限验证MethodInterceptor该类是Shiro权限注解拦截器。初始化时，interceptors添加了5个方法拦截器，分别对5种权限验证方法进行拦截。 123456789101112131415161718192021222324252627public class AopAllianceAnnotationsAuthorizingMethodInterceptor extends AnnotationsAuthorizingMethodInterceptor implements MethodInterceptor &#123; public AopAllianceAnnotationsAuthorizingMethodInterceptor() &#123; List&lt;AuthorizingAnnotationMethodInterceptor&gt; interceptors = new ArrayList&lt;AuthorizingAnnotationMethodInterceptor&gt;(5); //use a Spring-specific Annotation resolver - Spring's AnnotationUtils is nicer than the //raw JDK resolution process. AnnotationResolver resolver = new SpringAnnotationResolver(); //we can re-use the same resolver instance - it does not retain state: interceptors.add(new RoleAnnotationMethodInterceptor(resolver)); interceptors.add(new PermissionAnnotationMethodInterceptor(resolver)); interceptors.add(new AuthenticatedAnnotationMethodInterceptor(resolver)); interceptors.add(new UserAnnotationMethodInterceptor(resolver)); interceptors.add(new GuestAnnotationMethodInterceptor(resolver)); setMethodInterceptors(interceptors); &#125; ... public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; org.apache.shiro.aop.MethodInvocation mi = createMethodInvocation(methodInvocation); return super.invoke(mi); &#125;&#125; 该类通过调用invoke方法，进而调用超级父类AuthorizingMethodInterceptor的invoke方法，在该方法中会先执行assertAuthorized方法，进行权限校验，校验不通过抛出AuthorizationException。 12345678910public abstract class AuthorizingMethodInterceptor extends MethodInterceptorSupport &#123; public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; assertAuthorized(methodInvocation); return methodInvocation.proceed(); &#125; protected abstract void assertAuthorized(MethodInvocation methodInvocation) throws AuthorizationException;&#125; assertAuthorized方法最终执行还是AnnotationsAuthorizingMethodInterceptor。而AuthorizingMethodInterceptor有5个具体的实现类。如下： RoleAnnotationMethodInterceptor PermissionAnnotationMethodInterceptor AuthenticatedAnnotationMethodInterceptor UserAnnotationMethodInterceptor GuestAnnotationMethodInterceptor 12345678910111213141516public abstract class AnnotationsAuthorizingMethodInterceptor extends AuthorizingMethodInterceptor &#123; ... protected void assertAuthorized(MethodInvocation methodInvocation) throws AuthorizationException &#123; //default implementation just ensures no deny votes are cast: Collection&lt;AuthorizingAnnotationMethodInterceptor&gt; aamis = getMethodInterceptors(); if (aamis != null &amp;&amp; !aamis.isEmpty()) &#123; for (AuthorizingAnnotationMethodInterceptor aami : aamis) &#123; if (aami.supports(methodInvocation)) &#123; aami.assertAuthorized(methodInvocation); &#125; &#125; &#125; &#125;&#125; AuthorizingAnnotationMethodInterceptor首先从子类获取AuthorizingAnnotationHandler，再调用该实现类的assertAuthorized方法。 123456789101112131415161718192021222324252627282930public abstract class AuthorizingAnnotationMethodInterceptor extends AnnotationMethodInterceptor&#123; public AuthorizingAnnotationMethodInterceptor( AuthorizingAnnotationHandler handler ) &#123; super(handler); &#125; public AuthorizingAnnotationMethodInterceptor( AuthorizingAnnotationHandler handler, AnnotationResolver resolver) &#123; super(handler, resolver); &#125; public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; assertAuthorized(methodInvocation); return methodInvocation.proceed(); &#125; public void assertAuthorized(MethodInvocation mi) throws AuthorizationException &#123; try &#123; ((AuthorizingAnnotationHandler)getHandler()).assertAuthorized(getAnnotation(mi)); &#125; catch(AuthorizationException ae) &#123; // Annotation handler doesn't know why it was called, so add the information here if possible. // Don't wrap the exception here since we don't want to mask the specific exception, such as // UnauthenticatedException etc. if (ae.getCause() == null) ae.initCause(new AuthorizationException("Not authorized to invoke method: " + mi.getMethod())); throw ae; &#125; &#125;&#125; RoleAnnotationMethodInterceptor下面分析一下RoleAnnotationMethodInterceptor。 1234567891011public class RoleAnnotationMethodInterceptor extends AuthorizingAnnotationMethodInterceptor &#123; public RoleAnnotationMethodInterceptor() &#123; super( new RoleAnnotationHandler() ); &#125; // 具体校验逻辑交给RoleAnnotationHandler public RoleAnnotationMethodInterceptor(AnnotationResolver resolver) &#123; super(new RoleAnnotationHandler(), resolver); &#125;&#125; RoleAnnotationHandler 1234567891011121314151617181920212223242526272829public class RoleAnnotationHandler extends AuthorizingAnnotationHandler &#123; ... public void assertAuthorized(Annotation a) throws AuthorizationException &#123; if (!(a instanceof RequiresRoles)) return; RequiresRoles rrAnnotation = (RequiresRoles) a; String[] roles = rrAnnotation.value(); if (roles.length == 1) &#123; getSubject().checkRole(roles[0]); return; &#125; if (Logical.AND.equals(rrAnnotation.logical())) &#123; getSubject().checkRoles(Arrays.asList(roles)); return; &#125; if (Logical.OR.equals(rrAnnotation.logical())) &#123; // Avoid processing exceptions unnecessarily - "delay" throwing the exception by calling hasRole first boolean hasAtLeastOneRole = false; for (String role : roles) if (getSubject().hasRole(role)) hasAtLeastOneRole = true; // Cause the exception if none of the role match, note that the exception message will be a bit misleading if (!hasAtLeastOneRole) getSubject().checkRole(roles[0]); &#125; &#125;&#125; 实现类似编程式AOP 定义一个注解LogPrinter 12345@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface LogPrinter &#123; String value() default "";&#125; 继承StaticMethodMatcherPointcutAdvisor 1234567891011121314151617181920212223242526272829public class LogPrinterAdvisor extends StaticMethodMatcherPointcutAdvisor &#123; public LogPrinterAdvisor() &#123; setAdvice(new LogPrinterMethodInterceptor()); &#125; @Override public boolean matches(@NonNull Method method, Class&lt;?&gt; targetClass) &#123; Method m = method; if (isAnnotationPresent(m)) &#123; return true; &#125; if (targetClass != null) &#123; try &#123; m = targetClass.getMethod(m.getName(), m.getParameterTypes()); return isAnnotationPresent(m); &#125; catch (NoSuchMethodException ignored) &#123; &#125; &#125; return false; &#125; private boolean isAnnotationPresent(Method method) &#123; Annotation a = AnnotationUtils.findAnnotation(method, LogPrinter.class); return a != null; &#125;&#125; 实现MethodInterceptor接口，定义切面处理逻辑 123456789public class LogPrinterMethodInterceptor implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; LogPrinter logPrinter = invocation.getMethod().getAnnotation(LogPrinter.class); System.out.println("log printer: "+logPrinter.value()); return invocation.proceed(); &#125;&#125; 定义测试类，并添加LogPrinter注解 12345678@Componentpublic class HelloWorld &#123; @LogPrinter("hello world") public void hello() &#123; System.out.println("Hello"); &#125;&#125; 启动类 12345678910111213141516171819202122@SpringBootApplicationpublic class LogAdvisorApplication &#123; @Bean public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() &#123; DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); defaultAdvisorAutoProxyCreator.setProxyTargetClass(true); return defaultAdvisorAutoProxyCreator; &#125; @Bean public LogPrinterAdvisor logPrinterAdvisor() &#123; return new LogPrinterAdvisor(); &#125; public static void main(String[] args) &#123; ConfigurableApplicationContext context = SpringApplication.run(LogAdvisorApplication.class, args); HelloWorld helloWorld = context.getBean(HelloWorld.class); helloWorld.hello(); context.close(); &#125;&#125; 总结与思考Shiro的注解式权限，核心配置是一个DefaultAdvisorAutoProxyCreator和继承静态方法顾问StaticMethodMatcherPointcutAdvisor。其中5种权限注解，使用了统一的代码架构，用到了模板 设计模式。在架构实现上要好于AspectJ注解实现。]]></content>
      <categories>
        <category>Spring AOP</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
        <tag>Spring AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈互联网后端基础设施]]></title>
    <url>%2F2019%2F09%2F14%2F%E8%B0%88%E8%B0%88%E4%BA%92%E8%81%94%E7%BD%91%E5%90%8E%E7%AB%AF%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%2F</url>
    <content type="text"><![CDATA[转载：谈谈互联网后端基础设施本文更新于2018.09.14, 更新了后端基础设施框图，增加了负载均衡、Web服务器以及大数据存储和多维数据分析等部分 对于一个互联网企业，后端服务是必不可少的一个组成部分。抛开业务应用来说，往下的基础服务设施做到哪些才能够保证业务的稳定可靠、易维护、高可用呢？纵观整个互联网技术体系再结合公司的目前状况，个人认为必不可少或者非常关键的后端基础技术/设施如下图所示： 这里的后端基础设施主要指的是应用在线上稳定运行需要依赖的关键组件/服务等。开发或者搭建好以上的后端基础设施，一般情况下是能够支撑很长一段时间内的业务的。此外，对于一个完整的架构来说，还有很多应用感知不到的系统基础服务，如负载均衡、自动化部署、系统安全等，并没有包含在本文的描述范围内。 Api网关在移动app的开发过程中，通常后端提供的接口需要以下功能的支持： 负载均衡 api访问权限控制 用户鉴权 一般的做法，使用nginx做负载均衡，然后在每个业务应用里做api接口的访问权限控制和用户鉴权，更优化一点的方式则是把后两者做成公共类库供所有业务调用。但从总体上来看，这三种特性都属于业务的公共需求，更可取的方式则是集成到一起作为一个服务，既可以动态地修改权限控制和鉴权机制，也可以减少每个业务集成这些机制的成本。这种服务就是Api网关(http://blog.csdn.net/pzxwhc/article/details/49873623)，可以选择自己实现，也可以使用开源软件实现，如[Kong](https://getkong.org/)。如下图所示： 但是以上方案的一个问题是由于所有api请求都要经过网关，它很容易成为系统的性能瓶颈。因此，可以采取的方案是：去掉api网关，让业务应用直接对接统一认证中心，在基础框架层面保证每个api调用都需要先通过统一认证中心的认证，这里可以采取缓存认证结果的方式避免对统一认证中心产生过大的请求压力。 业务应用和后端基础框架业务应用分为：在线业务应用和内部业务应用。 在线业务应用：直接面向互联网用户的应用、接口等，典型的特点就是：请求量大、高并发、高可用、对故障的容忍度低。 内部业务应用：这个是面向公司内部的应用。比如，内部数据管理平台、广告投放平台等。相比起在线业务应用，其特点: 数据保密性高、压力小、并发量小、允许故障的发生。 业务应用基于后端的基础框架开发，针对Java后端来说，应该有的几个框架如下： MVC框架：从十年前流行的Struts1、2到现在最为推崇的SpringMVC、Jersey以及国人开发的JFinal、阿里的WebX等等，这些框架尤其是后面流行的这些都是各有千秋的。选型的主要因素是看你的团队是否有一个对某框架能够做二次开发、定制的人在。很多时候，针对这些通用的框架，你是需要做一些特定的开发才能满足特定的需求的。比如，很多团队传递参数使用的都是UnderScore的命名法(下划线连接单词)，但是Java中确是使用LowCamel命名的。对于SpringMVC，可以通过注解的alias来指定，但这样需要对每一个参数都要指定alias有点效率太低，此外ModelAttribute也不支持别名，更好的方式是在框架层面统一对参数做Camel命名的转换达到目的。 IOC框架：ioc带来的好处无须多言。目前Java中最为流行的Spring自诞生就天然支持IOC。 ORM框架：MyBatis是目前最为流行的orm框架。此外，Spring ORM中提供的JdbcTemplate也很不错。当然，对于分库分表、主从分离这些需求，一般就需要实现自己的ORM框架来支持了，像阿里的tddl、当当的sharding-jdbc(从datasource层面解决了分库分表、读写分离的问题，对应用透明、零侵入)。此外，为了在服务层面统一解决分库分表、主从分离、主备切换、缓存、故障恢复等问题，很多公司都是有自己的数据库中间件的，比如阿里的Cobar、360的Atlas、网易的DDB，还有官方提供的MySQL Proxy以及开源的MyCat、kingshard和收费的oneproxy。目前，线上有一定规模使用的应该是kingshard，当然如果不缺钱也可以上oneproxy。 缓存框架：缓存框架主要指的是对redis、memcached这些缓存服务器的操作统一封装，一般使用Spring的RedisTemplate即可，也可以使用jedis做自己的封装，支持客户端分布式方案、主从等。 JavaEE应用性能检测框架：对于线上的JavaEE应用，需要有一个统一的框架集成到每一个业务中检测每一个请求、方法调用、jdbc连接、redis连接等的耗时、状态等。jwebap是一个可以使用的性能检测工具，但由于其已经很多年没有更新，有可能的话建议基于此项目做二次开发。 一般来说，以上几个框架即可以完成一个后端应用的雏形。 对于这些框架来说，最为关键的是根据团队技术构成选择最合适的，有能力开发自己的框架则更好。此外，这里需要提供一个后端应用的模板或生成工具(如maven的archetype)给团队成员使用，可以让大家在开发新的应用的时候，迅速的生成雏形应用，而无需再做一些框架搭建的重复性劳动。 基础服务软件负载均衡器、Web/应用服务器缓存、数据库、搜索引擎、消息队列这些都是应用依赖的后端基础服务软件，他们的性能直接影响到了应用的整体性能，有时候你代码写的再好也许就是因为这些服务导致应用性能无法提升上去。 负载均衡器和Web/应用服务器业务应用最终是需要运行在Web/应用服务器中才能对外提供服务的。Nginx、Apache Http Server、微软的IIS是常用的Web服务器Tomcat、Jetty是常用的Servlet容器；JBoss、Weblogic是常用的JavaEE应用服务器。互联网技术领域，常选择Nginx为Web服务器，Tomcat做Servlet容器。 进一步的，如果想要部署多了克隆的业务应用结点一起对外提供服务，那么则需要负责均衡器反向代理多个克隆服务节点共同对外提供服务。LVS做四层流量转发，Nginx做七层流量转发，HaProxy兼具七层、四层流量转发功能。此外DNS轮训也是一种负载均衡方案。当然，F5等硬件负载均衡器性能会更高。 缓存如缓存五分钟法则所讲：如果一个数据频繁被访问，那么就应该放内存中。这里的缓存就是一种读写效率都非常高的存储方案，能够应对高并发的访问请求，通常情况下也不需要持久化的保证。但相对其他存储来说，缓存一般是基于内存的，成本比较昂贵，因此不能滥用。 缓存可以分为：本地缓存和分布式缓存。 本地缓存：主要指的是内存中的缓存机制。在Java中，Google Guava中就提供了本地缓存的实现机制。当然使用java的ConncurrentHashMap你也可以实现自己的本地缓存方案。 分布式缓存：指的单独的缓存服务。几年前比较流行的是memcached，但其只是一个KV的存储，支持的数据结构太少。现在最为流行的就是Redis，能够支持丰富的数据结构，基于事件驱动的单线程非阻塞IO也能够应对高并发的场景。集群方案除了官方的redis cluster, 目前比较流行的还有豌豆荚的codis、twitter的twemproxy。 对于缓存的使用，需要注意以下几点： 缓存的失效机制：当给某一个key设置了有效期，那么缓存何时对此key进行删除呢？一般来说会有以下几种方式： 守护进程定时去扫描key，找到已经失效的key，然后删除 读取key的时候先去判断key是否失效，如果失效则删除并返回空。 缓存的淘汰机制：是当缓存内存达到上限时如何删除缓存中的key。Redis提供了以下数据淘汰策略： volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru：从数据集中挑选最近最少使用的数据淘汰 allkeys-random：从数据集中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 对于其具体的实现机制，可以参考《Redis设计与实现》一书 缓存的更新机制: 通常来说有四种方式：Cache aside, Read through, Write through, Write behind caching，具体的可见陈皓大神的这篇总结：缓存更新的套路。 缓存的服务过载保护：缓存的服务过载指的是由于缓存失效，而引起后端服务的压力骤增，进一步产生雪崩效应。这个现象和缓存更新是相关的，采取何种策略在缓存失效的时候去更新缓存直接决定了服务过载的保护机制。通常的分为客户端和服务端的应对方案。前者的方案有：基于超时的简单模式、基于超时的常规模式、基于刷新的简单模式、基于刷新的常规模式、基于刷新的续费模式。后者的方案则是很常见的流量控制和服务降级。具体的可以看美团技术团队总结的这篇文章：Cache应用中的服务过载案例研究。 数据库数据库是后端开发中非常常见的一个服务组件。对于数据库的选型，要根据业务的特点和数据结构的特点来决定。 从存储介质上，数据库可以分为： 内存数据库： 数据主要存储在内存中，同时也可以采取措施对数据进行持久化到硬盘中。如Redis、H2DB的内存模式。对于这种数据库，由于内存成本昂贵，因此一定要做好存储的量化分析、容量预估，防止内存不足造成服务不可用。 硬盘数据库：数据存储在硬盘上的这种数据库是最为常见的。MySQL、Oracle、Postgresql、HBASE、H2DB、SqlLite等等都是硬盘数据库。此外，SSDB是基于SSD硬盘的KV数据库，支持的数据接口很丰富，是Redis的另外一个选择。 从存储数据类型、数据模式上，数据库可以分为： 关系型数据库：MySQL、Oracle、Postgresql都是关系型数据库的，是采用关系模型(关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织)来组织数据的数据库。 非关系型数据库：非关系型数据库是相对关系型数据库来讲的。以键值对存储，且结构不固定，每一个元组可以有不一样的字段，每个元组可以根据需要增加一些自己的键值对，这样就不会局限于固定的结构，可以减少一些时间和空间的开销。但是，其没有关系型数据库那种严格的数据模式，并不适合复杂的查询以及需要强事务管理的业务。非关系型数据库又可以分为： KV数据库：主要以(key,value)键值对存储数据的数据库。以Redis、RocksDB(levelDB)、SSDB为代表。 文档数据库：总体形式上也是键值对的形式，但是值里面又可以有各种数据结构：数组、键值对、字符串等等。以mongodb、couchdb为代表。 列数据库：也叫作稀疏大数据库，一般是用来存储海量数据的。相对于行数据库，这种数据库是以列为单位存储数据在介质上的。以Hbase、Cassendra为代表。 和数据库相关的一个很重要的就是数据库的索引。有一种说法是：“掌握了索引就等于掌握了数据库”。暂且不去评判此说法是否真的准确，但索引的确关系着数据库的读写性能。需要对数据库的索引原理做到足够的了解才能更好的使用各种数据库。通常来说，Mysql、Oracle、Mongodb这些都是使用的B树作为索引，是考虑到传统硬盘的特点后兼顾了读写性能以及范围查找需求的选择，而Hbase用得LSM则是为了提高写性能对读性能做了牺牲。 搜索引擎搜索引擎也是后端应用中一个很关键的组件，尤其是对内容类、电商类的应用，通过关键词、关键字搜索内容、商品是一个很常见的用户场景。比较成熟的开源搜索引擎有Solr和Elasticsearch，很多中小型互联网公司搜索引擎都是基于这两个开源系统搭建的。它们都是基于Lucence来实现的，不同之处主要在于termIndex的存储、分布式架构的支持等等。 对于搜索引擎的使用，从系统熟悉、服务搭建、功能定制，需要花费较长时间。在这个过程中，需要注意以下问题： 搜索引擎与公司现有数据系统的集成。现有的持久化、供搜索的数据的载体是什么, 如何让搜索引擎在全量和增量建索引过程中无缝集成原来的数据载体，才能发挥搜索引擎自身的实时性, 水平扩展性(性能与容量和机器数量成正比)等优势。 和数据库一样，对搜索引擎的索引机制也需要做到深入的了解。 更为详细的对于搜索引擎的工程化实践可以参考有赞工程师的这篇文章：有赞搜索引擎实践(工程篇) 另外，搜索引擎还可以用在数据的多维分析上，就是GrowingIO、MixPanel中的可以任意维度查询数据报表的功能。当然，druid也许是一个更好的实现多维分析的方案，官方也有其与es的比较：http://druid.io/docs/latest/comparisons/druid-vs-elasticsearch.html。 消息队列软件的组织结构，从开始的面向组件到SOA、SAAS是一个逐渐演变的过程。而到了今天微服务盛行的时代，你都不好意思说自己的系统只是单一的一个系统而没有解耦成一个个service。当然，小的系统的确没有拆分的必要性，但一个复杂的系统拆成一个个service做微服务架构确实是不得不做的事情。 那么问题就来了，service之间的通信如何来做呢？使用什么协议？通过什么方式调用？都是需要考虑的问题。 先抛开协议不谈，service之间的调用方式可以分为同步调用以及异步调用。同步调用的方式无需多说，那么异步调用是怎么进行的呢？一种很常见的方式就是使用消息队列，调用方把请求放到队列中即可返回，然后等待服务提供方去队列中去获取请求进行处理，然后把结果返回给调用方即可（可以通过回调）。 异步调用就是消息中间件一个非常常见的应用场景。此外，消息队列的应用场景还有以下： 解耦：一个事务，只关心核心的流程，需要依赖其他系统但不那么重要的事情，有通知即可，无须等待结果。 最终一致性：指的是两个系统的状态保持一致，要么都成功，要么都失败，可以有一定的延迟，只要最终达到一致性即可。 广播：这是消息队列最基本的功能。生产者只需要发布消息，无须关心有哪些订阅者来消费消息。 错峰与流控：当上下游系统处理能力不同的时候就需要类似消息队列的方式做为缓冲区来隔开两个系统。 目前主流的消息队列软件，主要有以下几种： ActiveMQ：Java中最为简单的消息队列，是对JMS的实现，没有规定消息的顺序、安全、重发等特性。 RabbitMQ：是对AMQP协议的实现，对于消息的顺序性、安全、重发等都做了很好的支持。比较适合不允许数据丢失、有事务需求的业务场景下的消息传输。 Kafka：是基于Log的消息队列，底层依赖于文件的顺序读取，是append-only的。适合对数据丢失不敏感、强调性能的一些海量日志传输场景中。是最近几年大数据领域很火的一个技术。 ZeroMQ：是一个网络编程的Pattern库，将常见的网络请求形式（分组管理，链接管理，发布订阅等）模式化、组件化，简而言之socket之上、MQ之下。对于MQ来说，网络传输只是它的一部分，更多需要处理的是消息存储、路由、Broker服务发现和查找、事务、消费模式（ack、重投等）、集群服务等。 文件存储不管是业务应用、依赖的后端服务还是其他的各种服务，最终还是要依赖于底层文件存储的。通常来说，文件存储需要满足的特性有：可靠性、容灾性、稳定性，即要保证存储的数据不会轻易丢失，即使发生故障也能够有回滚方案，也要保证高可用率。在底层可以采用传统的RAID作为解决方案，再上一层，目前hadoop的hdfs则是最为普遍的分布式文件存储方案，当然还有NFS、Samba这种共享文件系统也提供了简单的分布式存储的特性。 此外，如果文件存储确实成为了应用的瓶颈或者必须提高文件存储的性能从而提升整个系统的性能时，那么最为直接和简单的做法就是抛弃传统机械硬盘，用SSD硬盘替代。像现在很多公司在解决业务性能问题的时候，最终的关键点往往就是SSD。这也是用钱换取时间和人力成本最直接和最有效的方式。在数据库部分描述的SSDB就是对LevelDB封装之后，利用SSDB的特性的一种高性能KV数据库。 至于HDFS，如果要使用上面的数据，是需要通过hadoop的。类似xx on yarn的一些技术就是将非hadoop技术跑在hdfs上的解决方案(当然也是为了使用MR)。 统一认证中心统一认证中心，主要是对app用户、内部用户、app等的认证服务，包括 用户的注册、登录验证、token鉴权 内部信息系统用户的管理和登录鉴权 App的管理，包括app的secret生成，app信息的验证(如验证接口签名)等。 之所以需要统一认证中心，就是为了能够集中对这些所有app都会用到的信息进行管理，也给所有应用提供统一的认证服务。尤其是在有很多业务需要共享用户数据的时候，构建一个统一认证中心是非常必要的。此外，通过统一认证中心构建移动app的单点登录也是水到渠成的事情(模仿web的机制，将认证后的信息加密存储到本地磁盘中供多个app使用)。 单点登录系统目前很多大的在线web网站都是有单点登录系统的，通俗的来说就是只需要一次用户登录，就能够进入多个业务应用(权限可以不相同)，非常方便用户的操作。而在移动互联网公司中，内部的各种管理、信息系统同样也需要单点登录系统。目前，比较成熟的、用的最多的单点登录系统应该是耶鲁大学开源的CAS, 可以基于https://github.com/apereo/cas/tree/master/cas-server-webapp来定制开发的。此外，国人开源的[kisso](http://git.oschina.net/juapk/kisso)的这个也不错。基本上，单点登录的原理都类似下图所示： 统一配置中心在Java后端应用中，一种读写配置比较通用的方式就是将配置文件写在propeties、yaml、HCON文件中，修改的时候只需要更新文件重新部署即可，可以做到不牵扯代码层面改动的目的。统一配置中心，则是基于这种方式之上的统一对所有业务或者基础后端服务的相关配置文件进行管理的统一服务, 具有以下特性： 能够在线动态修改配置文件并生效 配置文件可以区分环境(开发、测试、生产等) 使用方便: 在java中可以通过注解、xml配置的方式引入相关配置 disconf是可以在生产环境使用的一个方案，也可能根据自己的需求开发自己的配置中心(可以选择zookeeper作为配置存储)。 服务治理框架对于外部API调用或者客户端对后端api的访问，可以使用http协议或者说restful(当然也可以直接通过最原始的socket来调用)。但对于内部服务间的调用，一般都是通过RPC机制来调用的。目前主流的RPC协议有： RMI Hessian Thrift Dubbo 这些RPC协议各有优劣点，需要针对业务需求做出相应的最好的选择。 这样，当你的系统服务在逐渐增多，RPC调用链越来越复杂，很多情况下，需要不停的更新文档来维护这些调用关系。一个对这些服务进行管理的框架可以大大节省因此带来的繁琐的人力工作。 传统的ESB(企业服务总线)本质就是一个服务治理方案，但esb作为一种proxy的角色存在于client和server之间，所有请求都需要经过esb，使得esb很容易成为性能瓶颈。因此，基于传统的esb，更好的一种设计如下图所示： 如图，以配置中心为枢纽，调用关系只存在于client和提供服务的server之间，就避免了传统esb的性能瓶颈问题。对于这种设计，esb应该支持的特性如下： 服务提供方的注册、管理 服务消费者的注册、管理 服务的版本管理、负载均衡、流量控制、服务降级等 服务的容错、熔断等 阿里开源的dubbo则对以上做了很好的实现，也是目前很多公司都在使用的方案。但由于某些原因，dubbo现已不再维护，推荐大家使用当当后来维护的dubbox。 统一调度中心在很多业务中，定时调度是一个非常普遍的场景，比如定时去抓取数据、定时刷新订单的状态等。通常的做法就是针对各自的业务依赖Linux的cron机制或者java中的quartz。统一调度中心则是对所有的调度任务进行管理，这样能够统一对调度集群进行调优、扩展、任务管理等。azkaban和oozie是hadoop的流式工作管理引擎，也可以作为统一调度中心来使用。当然，你也可以使用cron或者quartz来实现自己的统一调度中心。 根据cron表达式调度任务 动态修改、停止、删除任务 支持任务工作流：比如一个任务完成之后再执行下一个任务 任务支持脚本、代码、url等多种形式 任务执行的日志记录、故障报警 对于Java的quartz这里需要说明一下：这个quartz需要和spring quartz区分，后者是spring对quartz框架的简单实现也是目前使用的最多的一种调度方式。但其并没有做高可用集群的支持。而quartz虽然有集群的支持，但是配置起来非常复杂。现在很多方案都是使用zookeeper来实现spring quartz集群的。这里有一个国人开源的uncode-shcedule对此实现的还不错，可以根据自己的业务需求做二次开发。此外，当当开源的elastic-job则在此之上又加入了弹性资源利用等更为强大的功能。 统一日志服务日志是开发过程必不可少的东西。有时候，打印日志的时机、技巧是很能体现出工程师编码水平的。毕竟，日志是线上服务能够定位、排查异常最为直接的信息。 通常的，将日志分散在各个业务中非常不方便对问题的管理和排查。统一日志服务则使用单独的日志服务器记录日志，各个业务通过统一的日志框架将日志输出到日志服务器上。 可以通过实现log4j后者logback的appender来实现统一日志框架，然后通过RPC调用将日志打印到日志服务器上。 数据基础设施数据是最近几年非常火的一个领域。从《精益数据分析》到《增长黑客》，都是在强调数据的非凡作用。很多公司也都在通过数据推动产品设计、市场运营、研发等。详细的可见之前的一篇《数据杂谈》，对数据相关的东西做过一些总结。这里需要说明的一点是，只有当你的数据规模真的到了单机无法处理的规模才应该上大数据相关技术，千万不要为了大数据而大数据。很多情况下使用单机程序+mysql就能解决的问题非得上hadoop即浪费时间又浪费人力。 这里需要补充一点的是，对于很多公司，尤其是离线业务并没有那么密集的公司，在很多情况下大数据集群的资源是被浪费的。因此诞生了xx on yarn一系列技术让非hadoop系的技术可以利用大数据集群的资源，能够大大提高资源的利用率，如Docker on yarn(Hulu的VoidBox)。 数据高速公路接着上面讲的统一日志服务，其输出的日志最终是变成数据到数据高速公路上供后续的数据处理程序消费的。这中间的过程包括日志的收集、传输。 收集：统一日志服务将日志打印在日志服务上之后，需要日志收集机制将其集中起来。目前，常见的日志收集方案有：scribe、Chukwa、Kakfa和Flume。对比如下图所示： 传输：通过消息队列将数据传输到数据处理服务中。对于日志来说，通常选择kafka这种消息队列即可。 此外，这里还有一个关键的技术就是数据库和数据仓库间的数据同步问题，即将需要分析的数据从数据库中同步到诸如hive这种数据仓库时使用的方案。比较简单的、用的也比较多的可以使用sqoop进行基于时间戳的数据同步，此外，阿里开源的canal实现了基于binlog增量同步，更加适合通用的同步场景，但是基于canal你还是需要做不少的业务开发工作的。推荐另一款国人开源的MySQL-Binlog，原理和canal类似，默认提供了任务的后台管理功能，只需要实现接收到binlog后的处理逻辑即可。 离线数据处理离线数据分析是可以有延迟的，一般针对是非实时需求的数据分析工作，产生的也是T-1的报表。目前最常用的离线数据分析技术除了hadoop还有spark。相比hadoop，spark性能上有很大优势，当然对硬件资源要求也高。 对于hadoop，传统的MR编写很复杂，也不利于维护，可以选择使用hive来用sql替代编写mr，但是前提务必要对hive的原理做到了解。可以参见美团的这篇博文来学习:Hive SQL的编译过程。而对于spark，也有类似hive的spark sql。 此外，对于离线数据分析，还有一个很关键的就是数据倾斜问题。所谓数据倾斜指的是region数据分布不均，造成有的结点负载很低，而有些却负载很高，从而影响整体的性能。因此，处理好数据倾斜问题对于数据处理是很关键的。对于hive的数据倾斜，可见:hive大数据倾斜总结。对于spark的倾斜问题，可见：Spark性能优化指南——高级篇。 实时数据处理相对于离线数据分析，实时数据分析也叫在线数据分析，针对的是对数据有实时要求的业务场景，如广告结算、订单结算等。目前，比较成熟的实时技术有storm和spark streaming。相比起storm，spark streaming其实本质上还是基于批量计算的。如果是对延迟很敏感的场景，还是应该使用storm。 对于实时数据分析，需要注意的就是实时数据处理结果写入存储的时候，要考虑并发的问题，虽然对于storm的bolt程序来说不会有并发的问题，但是写入的存储介质是会面临多任务同时读写的。通常采用的方案就是采用时间窗口的方式对数据做缓冲后批量写入。 此外，实时数据处理一般情况下都是基于增量处理的，相对于离线来说并非可靠的，一旦出现故障(如集群崩溃)或者数据处理失败，是很难对数据恢复或者修复异常数据的。因此结合离线+实时是目前最普遍采用的数据处理方案。Lambda架构就是一个结合离线和实时数据处理的架构方案。 数据存储不论是源数据、离线处理得到的数据还是实时数据处理的数据最终都是要做持久化存储的。目前，大数据领域的常用存储方案有： HDFS: 直接存储在Hadoop的文件系统上，包括ORC、Parquet、Sequence的存储格式。此种存储是静态数据存储方式。适用于高吞吐量的离线大数据分析场景。这类存储的局限性是数据无法进行随机的读写。 HBase: 和Cassandra一样都属于动态数据存储。适用于大数据随机读写场景。这类存储的局限性是批量读取吞吐量远不如 HDFS，不适用于批量数据分析的场景。 Kudu: 在静态数据和动态数据的折中实现，平衡了随机读写和批量分析的性能，既支持随机读写，又支持OLAP分析。 多维数据分析数据的最终用途是用来分析的，即能够在多个维度以及其组合上输出统计报表数据。目前主要有两种解决此问题的方案：ROLAP和MOLAP。 ROLAP：使用关系型数据库或者扩展的关系型数据库来管理数据仓库数据，以Hive、Spark SQL、Presto、Impala为代表，其中后两者是MPP架构，能够达到秒级的响应。 MOLAP：基于数据立方体的多位存储引擎，用空间换时间，把所有的分析情况都物化为物理表或者视图。以Druid、Pinot和Kylin为代表，不同于ROLAP, 其原生的支持多维的数据查询。 其中，ROLAP能够组合任意维度进行数据展示和分析（Adhoc Query,数据即席查询），可以在离线和实时数据处理产生的定制报表无法满足数据需求方时，提供给一个可以根据自己的需求灵活的选择查询条件进行分析的工具，能够大大提高数据分析师、产品经理的工作效率。如果想进一步提供给需求方更加直观的UI操作界面，可以搭建内部的Hue。 而MOLAP虽然不能满足任意维度查询，但是其空间换时间，性能是好于ROLAP的，也是多维数据实时分析的一种常用方案。对于其中常用的三个框架，对比如下： . 使用场景 语言 协议 特点 Druid 实时处理分析 Java JSON 实时聚合 Pinot 实时处理分析 Java JSON 实时聚合 Kylin OLAP分析引擎 Java JDBC/OLAP 预处理、cache 其中，Druid相对比较轻量级，用的人较多，比较成熟。 故障监控对于面向用户的线上服务，发生故障是一件很严重的事情。因此，做好线上服务的故障检测告警是一件非常重要的事情。可以将故障监控分为以下两个层面的监控： 系统监控：主要指的对主机的带宽、cpu、内存、硬盘、io等硬件资源的监控。这可以使用开源的nagios、cacti等开源软件进行监控。目前，市面上也有很多第三方服务能够提供对于主机资源的监控，如监控宝等。对于分布式服务集群(如hadoop、storm、kafka、flume等集群)的监控则可以使用ganglia。此外，小米开源的OpenFalcon也很不错，涵盖了系统监控、JVM监控等，也支持自定义的监控机制。 业务监控：是在主机资源层面以上的监控，比如app的pv、uv数据异常、交易失败等。需要业务中加入相关的监控代码，比如在异常抛出的地方，加一段日志记录。 监控还有一个关键的步骤就是告警。告警的方式有很多种：邮件、im、短信等。考虑到故障的重要性不同、告警的合理性、便于定位问题等因素，有以下建议： 告警日志要记录发生故障的机器id，尤其是在集群服务中，如果没有记录机器id，那么对于后续的问题定位会很困难。 要对告警做聚合，不要每一个故障都单独进行告警，这样会对工程师造成极大的困扰。 要对告警做等级划分，不能对所有告警都做同样的优先级处理。 使用微信做为告警软件，能够在节省短信成本的情况下，保证告警的到达率。 故障告警之后，那么最最关键的就是应对了。对于创业公司来说，24小时待命是必备的素质，当遇到告警的时候，需要尽快对故障做出反应，找到问题所在，并能在可控时间内解决问题。对于故障问题的排查，基本上都是依赖于日志的。只要日志打的合理，一般情况下是能够很快定位到问题所在的，但是如果是分布式服务，并且日志数据量特别大的情况下，如何定位日志就成为了难题。这里有几个方案： 建立ELK(Elastic+Logstash+Kibana)日志集中分析平台，便于快速搜索、定位日志。对于ELK的介绍，可以见：使用Elasticsearch + Logstash + Kibana搭建日志集中分析平台实践 建立分布式请求追踪系统(也可以叫全链路监测系统)，对于分布式系统尤其是微服务架构，能够极大的方便在海量调用中快速定位并收集单个异常请求信息，也能快速定位一条请求链路的性能瓶颈。唯品会的Mercury、阿里的鹰眼、新浪的WatchMan、Twitter开源的Zipkin基本都是基于Google的Dapper论文而来。此外，腾讯的染色日志机制本质上也是在链路追踪之上根据响应信息做了染色机制。Apache正在孵化中的HTrace则是针对大的分布式系统诸如hdfs文件系统、hbase存储引擎而设计的分布式追踪方案。这里需要提到的一点是，如果你的微服务实现使用了Spring cloud，那么Spring Cloud Sleuth则是最佳的分布式跟踪实现方案。 扩展一. NetFlix近几年Netflix开源了其内部很多的服务：https://github.com/Netflix，包括大数据、构建交付工具、通用运行时服务类库、数据持久化、安全等。里面有一些对应了上面所说的基础设施： zuul 这是Netflix所有后端服务最前端的一道门，也就是我们上面说的Api网关, 主要包含了以下功能： 认证授权和安全：识别合法的外部请求，拒绝非法的。 监控：跟踪记录所有有意义的数据以便于给我们一个精确的产品视图。 动态路由：根据需要动态把请求路由到合适的后端服务上。 压力测试：渐进式的增加对集群的压力直到最大值。 限流：对每一种类型的请求都限定流量，拒绝超出的请求。 静态响应控制：对于某些请求直接在边缘返回而不转发到后端集群。 多区域弹性：在aws的多个region中进行请求路由。 Eureka 是Netflix的服务注册发现服务，类似于dubbo的功能。包括负载均衡和容错。 Hystrix hystrix是一个类库。基于命令模式，实现依赖服务的容错、降级、隔离等。在依赖多个第三方服务的时候非常有用。此外，还可以通过自定义实现dubbo的filter来给dubbo添加hystrix的特性支持。 此外，Netflix的这些开源组件统称做Netflix oss，提供了一整套分布式系统解决方案，涵盖了做分布式微服务需要的服务发现、服务容错、负载均衡、权限控制等。当然，如果你直接选用docker的话，那么K8s本身也提供了这些东西。 二. Spring CloudSpringCloud Netflix系列Spring cloud给我们构建分布式系统提供了一整套开发工具和框架，基本上也涵盖了本文讲述的各个组件，其子项目Spring Cloud Netflix则能够集成Netflix的各个组件。现在很多公司和团队都是基于Spring cloud这一套东西在做微服务实现的。不过，spring cloud包含很多子项目，想要吃透这些得花不小的成本。 Spring Cloud Config 统一配置中心，类似于前文说过的disconf,不过其配置文件时存储在版本管理系统如git、svn上的。其配置的实时在线更新则需要依赖Spring Cloud Bus。 Spring Cloud Security 提供了oauth2客户端的负载均衡以及认证header等安全服务，可以做为Api网关的实现。 Spring Cloud Consul/Zookeepr 服务统一发现、注册、配置服务。类似于dubbo。 Spring Cloud Bus 提供了服务之间通信的分布式消息事件总线，主要用来在集群中传播状态改变（如配置改动）。 Spring Cloud Sleuth 分布式跟踪系统, 能够追踪单次请求的链路轨迹以及耗时等信息。 SpringCloud Alibaba系列 Spring Cloud Alibaba Nacos 服务注册与发现组件 Spring Cloud Alibaba Nacos Config 统一配置中心组件 Spring Cloud Alibaba Sentinel 服务熔断组件，以流量为切入点 Spring Cloud Alibaba Dubbo dubbo整合spring cloud Spring Cloud Alibaba seata 分布式事务组件 Spring Cloud Alibaba RocketMQ 分布式消息组件 Spring Cloud Alibaba ScheduleX 分布式调度任务组件]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>后端基础设施</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot减少if-else]]></title>
    <url>%2F2019%2F09%2F14%2FSpringBoot%E5%87%8F%E5%B0%91if-else%2F</url>
    <content type="text"><![CDATA[转载：在SpringBoot中，如何干掉太多if else !。文章中实现换个方式，不算完全转载。 项目代码github地址：策略设计模式解决代码过多的if else ! 需求这里虚拟一个业务需求，让大家容易理解。假设有一个订单系统，里面的一个功能是根据订单的不同类型作出不同的处理逻辑。 订单实体类： 1234567@Datapublic class Order &#123; private String id; private String type; private BigDecimal price;&#125; Service层接口： 1234public interface OrderService &#123; String handleOrder(Order order);&#125; 传统实现根据订单类型写一堆的if else： 123456789101112131415161718@Servicepublic class OrderServiceImpl implements OrderService &#123; @Override public String handleOrder(Order order) &#123; String type = order.getType(); if ("1".equals(type)) &#123; return "处理普通订单"; &#125; else if ("2".equals(type)) &#123; return "处理团购订单"; &#125; else if ("3".equals(type)) &#123; return "处理促销订单"; &#125; else &#123; return null; &#125; &#125;&#125; 策略模式实现利用策略模式，只需要两行即可实现业务逻辑：1234567891011@Servicepublic class OrderServiceImpl implements OrderService &#123; @Autowired private OrderHandlerContext orderHandlerContext; @Override public String handleOrder(Order order) &#123; return orderHandlerContext.getInstance(order.getType()).handle(order); &#125;&#125; 可以看到上面的方法中注入了OrderHandlerContext，这是一个处理器上下文，用来保存不同的业务处理器，具体在下文会讲解。我们从中获取一个订单处理器OrderHandler，调用其方法实现业务逻辑。现在可以了解到，我们主要的业务逻辑是在处理器中实现的，因此有多少个订单类型，就对应有多少个处理器。以后需求变化，增加了订单类型，只需要添加相应的处理器就可以，上述OrderServiceImpl完全不需改动。 我们先看看业务处理器的写法：1234567891011121314151617181920212223242526272829public interface OrderHandler &#123; String handle(Order order);&#125;@Component@OrderHandlerType("2")public class GroupOrderHandler implements OrderHandler &#123; @Override public String handle(Order order) &#123; return "处理团购订单"; &#125;&#125;@Component@OrderHandlerType("1")public class NormalOrderHandler implements OrderHandler &#123; @Override public String handle(Order order) &#123; return "处理普通订单"; &#125;&#125;@Component@OrderHandlerType("3")public class PromotionHandler implements OrderHandler &#123; @Override public String handle(Order order) &#123; return "处理促销订单"; &#125;&#125; 首先每个处理器都必须添加到Spring容器中，因此需要加上@Component注解，其次需要加上一个自定义注解@OrderHandlerType，用于标识该处理器对应哪个订单类型，最后就是实现OrderHandler接口，实现自己的业务逻辑。 自定义注解订单类型处理器@OrderHandlerType1234567@Target(&#123;ElementType.TYPE&#125;)@Documented@Retention(RetentionPolicy.RUNTIME)public @interface OrderHandlerType &#123; String value() default "";&#125; 实现OrderHandlerContext订单上下文逻辑逻辑中使用SmartInitializingSingleton获取Spring容器OrderHandler接口实现类。该接口在 所有单例实例化后调用。详细ConfigurableListableBeanFactory#preInstantiateSingletons()。 在单例预实例化阶段结束时调用，保证已经创建了所有常规单例bean 。 此方法中的{@link ListableBeanFactory#getBeansOfType}调用不会在引导期间触发意外的副作用。 注意：对于单例bean 不会触发此回调在{@link BeanFactory} bootstrap 之后根据需要懒洋洋地初始化，而不是任何其他bean范围。小心地将它用于具有预期引导语义的bean。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Component@Slf4jpublic class OrderHandlerContext implements SmartInitializingSingleton, ApplicationContextAware &#123; private ApplicationContext applicationContext; private final Map&lt;String, Class&lt;?&gt;&gt; orderHandlerMap = new HashMap&lt;&gt;(8); @Override public void afterSingletonsInstantiated() &#123; Map&lt;String, OrderHandler&gt; orderHandlers = applicationContext.getBeansOfType(OrderHandler.class); if (log.isInfoEnabled()) &#123; log.info("orderHandlers: &#123;&#125;", orderHandlers); &#125; if (!CollectionUtils.isEmpty(orderHandlers)) &#123; orderHandlers.forEach((key, value) -&gt; &#123; OrderHandlerType orderHandlerType = AnnotationUtils.findAnnotation(value.getClass(), OrderHandlerType.class); if (orderHandlerType != null) &#123; if (!orderHandlerMap.containsKey(orderHandlerType.value())) &#123; orderHandlerMap.put(orderHandlerType.value(), value.getClass()); &#125; else &#123; throw new IllegalArgumentException(String.format("OrderHandlerContext.orderHandlerMap already constains " + "order type %s,please check your logic.", orderHandlerType.value())); &#125; &#125; &#125;); if (log.isInfoEnabled()) &#123; log.info("orderHandlerMap: &#123;&#125;", JSONObject.toJSONString(orderHandlerMap)); &#125; &#125; else &#123; log.warn("not found order handler bean in beanFactory"); &#125; &#125; @Override public void setApplicationContext(@NonNull ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; public OrderHandler getInstance(String type) &#123; Class orderHandlerClass = orderHandlerMap.get(type); if (orderHandlerClass == null) &#123; throw new IllegalArgumentException("not found order handler for type: " + type); &#125; else &#123; return (OrderHandler) applicationContext.getBean(orderHandlerMap.get(type)); &#125; &#125;&#125; 总结利用策略模式可以简化繁杂的if else代码，方便维护，而利用自定义注解和自注册的方式，可以方便应对需求的变更。本文只是提供一个大致的思路，还有很多细节可以灵活变化，例如使用枚举类型、或者静态常量，作为订单的类型，相信你能想到更多更好的方法。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>策略设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro设计解析篇2]]></title>
    <url>%2F2019%2F09%2F13%2FShiro%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%E7%AF%872%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Shiro]]></title>
    <url>%2F2019%2F09%2F13%2FSpringBoot%E6%95%B4%E5%90%88Shiro%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Shiro设计解析篇1]]></title>
    <url>%2F2019%2F09%2F13%2FShiro%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%E7%AF%871%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Java开发建议]]></title>
    <url>%2F2019%2F09%2F13%2FJava%E5%BC%80%E5%8F%91%E5%BB%BA%E8%AE%AE%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Java后端技术概念]]></title>
    <url>%2F2019%2F09%2F13%2FJava%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[如何应对在线故障]]></title>
    <url>%2F2019%2F09%2F13%2F%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%9C%A8%E7%BA%BF%E6%95%85%E9%9A%9C%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[微服务杂谈]]></title>
    <url>%2F2019%2F09%2F13%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9D%82%E8%B0%88%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合JWT]]></title>
    <url>%2F2019%2F09%2F12%2FSpringBoot%E6%95%B4%E5%90%88JWT%2F</url>
    <content type="text"><![CDATA[概述 SpringBoot整合JWT(JSON Web Token)，其中springboot版本2.0.1.RELEASE，jwt版本0.9.1，spring boot security版本为2.0.1.RELEASE。Jwt详细讲解见链接：JWT(JSON Web Token)详细讲解。 关键POM.xml代码如下1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--spring boot starter security--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--jwt--&gt;&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 关键配置12345678910jwt: secret: secret #默认是15秒 expiration: 180 token: Authorization##配置不被spring security拦截的请求security: postPath: "/api/business/users/login" getPath: "/api/business/users/index" 关键代码JwtTokenUtils(Jwt token生成工具类)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123@Component@Slf4jpublic class JwtTokenUtils implements Serializable &#123; private static final String CLAIM_KEY_USERNAME = "sub"; private static final String CLAIM_KEY_CREATED = "created"; private static final long serialVersionUID = 5021913450632406869L; public String getUsernameFromToken(String token, String secret) &#123; String username; try &#123; final Claims claims = getClaimsFromToken(token, secret); username = claims.getSubject(); &#125; catch (Exception e) &#123; username = null; &#125; return username; &#125; public Date getCreatedDateFromToken(String token, String secret) &#123; Date created; try &#123; final Claims claims = getClaimsFromToken(token, secret); created = new Date((Long) claims.get(CLAIM_KEY_CREATED)); &#125; catch (Exception e) &#123; created = null; &#125; return created; &#125; public Date getExpirationDateFromToken(String token, String secret) &#123; Date expiration; try &#123; final Claims claims = getClaimsFromToken(token, secret); expiration = claims.getExpiration(); log.info("jwt解密:&#123;&#125;", claims); &#125; catch (Exception e) &#123; expiration = null; &#125; return expiration; &#125; private Claims getClaimsFromToken(String token, String secret) &#123; SecretKey secretKey = generalKey(secret); Claims claims; try &#123; claims = Jwts.parser() .setSigningKey(secretKey) .parseClaimsJws(token) .getBody(); &#125; catch (Exception e) &#123; log.debug("validate is token error ", e); claims = null; &#125; return claims; &#125; private Date generateExpirationDate(Long expiration) &#123; return new Date(System.currentTimeMillis() + expiration * 1000); &#125; private Boolean isTokenExpired(String token, String secret) &#123; final Date expiration = getExpirationDateFromToken(token, secret); return expiration.before(new Date()); &#125; private Boolean isCreatedBeforeLastPasswordReset(Date created, Date lastPasswordReset) &#123; return (lastPasswordReset != null &amp;&amp; created.before(lastPasswordReset)); &#125; public String generateToken(String userName, String secret, Long expiration) &#123; Map&lt;String, Object&gt; claims = new HashMap&lt;&gt;(2); claims.put(CLAIM_KEY_USERNAME, userName); claims.put(CLAIM_KEY_CREATED, new Date(System.currentTimeMillis())); return generateToken(claims, secret, expiration); &#125; private String generateToken(Map&lt;String, Object&gt; claims, String secret, Long expiration) &#123; //生成签名的时候使用的秘钥secret SecretKey secretKey = generalKey(secret); return Jwts.builder() .setHeaderParam("typ", "JWT") .setClaims(claims) .setExpiration(generateExpirationDate(expiration)) .signWith(SignatureAlgorithm.HS512, secretKey) .compact(); &#125; public Boolean canTokenBeRefreshed(String token, Date lastPasswordReset, String secret) &#123; final Date created = getCreatedDateFromToken(token, secret); return !isCreatedBeforeLastPasswordReset(created, lastPasswordReset) &amp;&amp; !isTokenExpired(token, secret); &#125; public String refreshToken(String token, String secret, Long expiration) &#123; String refreshedToken; try &#123; final Claims claims = getClaimsFromToken(token, secret); claims.put(CLAIM_KEY_CREATED, new Date()); refreshedToken = generateToken(claims, secret, expiration); &#125; catch (Exception e) &#123; refreshedToken = null; &#125; return refreshedToken; &#125; public Boolean validateToken(String token, String userName, String secret) &#123; final String username = getUsernameFromToken(token, secret); return ( username.equals(userName) &amp;&amp; !isTokenExpired(token, secret)); &#125; private SecretKey generalKey(String secret) &#123; // 使用base64解码 byte[] encodedKey = Base64.decodeBase64(secret); // 根据给定的字节数组使用AES加密算法构造一个密钥 SecretKey secretKey = new SecretKeySpec(encodedKey, 0, encodedKey.length, "AES"); return secretKey; &#125;&#125; JwtUserFactory(Jwt user工厂)12345678910111213141516171819public class JwtUserFactory &#123; private JwtUserFactory() &#123; &#125; public static JwtUser create(User user) &#123; return JwtUser.builder().id(user.getUserId()) .password(user.getUserPassword()) .username(user.getUserName()) .authorities(mapToGrantedAuthorities()).build(); &#125; /** * 获取权限 **/ private static List&lt;GrantedAuthority&gt; mapToGrantedAuthorities() &#123; return Collections.singletonList(new SimpleGrantedAuthority("ROLE_USER")); &#125;&#125; JwtUser(spring security UserDetails实现类)12345678910111213141516171819202122232425262728@Datapublic class JwtUser implements UserDetails, Serializable &#123; private Integer id; private String username; private String password; private Collection&lt;? extends GrantedAuthority&gt; authorities; @Override public boolean isAccountNonExpired() &#123; return true; &#125; @Override public boolean isAccountNonLocked() &#123; return true; &#125; @Override public boolean isCredentialsNonExpired() &#123; return true; &#125; @Override public boolean isEnabled() &#123; return true; &#125;&#125; JwtUserDetailsServiceImpl(Spring Security UserDetailsService实现类)1234567891011121314151617181920212223@Service@Slf4jpublic class JwtUserDetailsServiceImpl implements UserDetailsService &#123; // 实现验证的userService @Resource private UserService userService; @Resource private HttpServletRequest request; @Override public UserDetails loadUserByUsername(String userName) throws UsernameNotFoundException &#123; LambdaQueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;User&gt;().lambda().eq(User::getUserName, userName); User user = userService.getOne(wrapper); if (user != null) &#123; request.setAttribute("userInfo", user); return JwtUserFactory.create(user); &#125; else &#123; return null; &#125; &#125;&#125; JwtAuthenticationTokenFilter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Component@Slf4jpublic class JwtAuthenticationTokenFilter extends OncePerRequestFilter &#123; @Resource private UserDetailsService userDetailsService; @Resource private JwtTokenUtils jwtTokenUtils; private static final String FILTER_APPLIED = "__spring_security_JwtFilter_filterApplied"; /** * jwt token **/ @Value("$&#123;jwt.token&#125;") private String tokenHeader; /** * 私钥 **/ @Value("$&#123;jwt.secret&#125;") private String secret; /** * 过期时间 **/ @Value("$&#123;jwt.expiration&#125;") private String expiration; public static final String TOKEN_PREFIX = "00000000000"; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException &#123; log.info("tokenHeader: &#123;&#125;,secret: &#123;&#125;,expiration: &#123;&#125;", tokenHeader, secret, expiration); if (request.getAttribute(FILTER_APPLIED) != null) &#123; chain.doFilter(request, response); return; &#125; String tokenHeader = request.getHeader(this.tokenHeader); if (tokenHeader != null &amp;&amp; tokenHeader.startsWith(TOKEN_PREFIX)) &#123; String authToken = tokenHeader.substring(11); String username = jwtTokenUtils.getUsernameFromToken(authToken, secret); if (username != null &amp;&amp; jwtTokenUtils.validateToken(authToken, username, secret)) &#123; UserDetails userDetails = userDetailsService.loadUserByUsername(username); if (userDetails != null) &#123; UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken( userDetails, null, userDetails.getAuthorities()); authentication.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); SecurityContextHolder.getContext().setAuthentication(authentication); &#125; else &#123; log.debug("username:&#123;&#125;, 数据库获取userName失败:&#123;&#125;", username, tokenHeader); SecurityContextHolder.getContext().setAuthentication(null); &#125; &#125; else &#123; if (username != null) &#123; log.debug("username:&#123;&#125;, token过期:&#123;&#125;", username, tokenHeader); &#125; SecurityContextHolder.getContext().setAuthentication(null); &#125; &#125; else &#123; SecurityContextHolder.getContext().setAuthentication(null); &#125; // 防止filter在容器内多执行一遍 request.setAttribute(FILTER_APPLIED, true); chain.doFilter(request, response); &#125;&#125; JwtAuthenticationEntryPoint123456789101112131415/** * 拦截请求没有走凭证 **/@Componentpublic class JwtAuthenticationEntryPoint implements AuthenticationEntryPoint &#123; @Override public void commence(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException &#123; // 这个异常在未授权用户访问安全资源时会触发,我们会发出一个50未授权的response ApiResult&lt;String&gt; result = new ApiResult&lt;&gt;(); result.setCode(NetConstants.RTN_TOKEN_EXPIRE); result.setMessage("Unauthorized: " + e.getMessage()); httpServletResponse.getWriter().print(JSONObject.toJSONString(result)); &#125;&#125; WebSecurityConfig(配置spring security全局拦截)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)@Slf4jpublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Value("$&#123;security.postPath&#125;") private String[] postPath; @Value("$&#123;security.getPath&#125;") private String[] getPath; @Resource private JwtAuthenticationEntryPoint unauthorizedHandler; @Resource private UserDetailsService userDetailsService; // 配置spring security验证管理器 @Autowired public void configureAuthentication(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception &#123; authenticationManagerBuilder .userDetailsService(this.userDetailsService) .passwordEncoder(passwordEncoder()); &#125; @Bean public PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder(); &#125; @Bean public JwtAuthenticationTokenFilter authenticationTokenFilterBean() throws Exception &#123; return new JwtAuthenticationTokenFilter(); &#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Override protected void configure(HttpSecurity httpSecurity) throws Exception &#123; log.info("postPath: &#123;&#125;,getPath: &#123;&#125;", postPath, getPath); httpSecurity // 由于使用的是JWT，我们这里不需要csrf .csrf().disable() //因为使用JWT,所以不需要HttpSession .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and().exceptionHandling().authenticationEntryPoint(unauthorizedHandler) // 基于token，所以不需要session .and().sessionManagement().sessionCreationPolicy(SessionCreationPolicy.ALWAYS) .and().authorizeRequests() .antMatchers(HttpMethod.OPTIONS, "/**").permitAll() .requestMatchers(CorsUtils::isPreFlightRequest).permitAll() // 对于获取token的rest api要允许匿名访问 .antMatchers(HttpMethod.POST, postPath).permitAll() .antMatchers(HttpMethod.GET, getPath).permitAll() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated() .and().addFilterBefore(authenticationTokenFilterBean(), UsernamePasswordAuthenticationFilter.class); // 禁用缓存 httpSecurity.headers().cacheControl(); &#125;&#125; 登录代码123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping("/api/business/users")@Slf4jpublic class LoginController &#123; @Resource private JwtTokenUtils jwtTokenUtils; @Value("$&#123;jwt.secret&#125;") private String secret; @Value("$&#123;jwt.expiration&#125;") private Long expiration; @Resource private AuthenticationManager authenticationManager; // 登录请求不做拦截 @PostMapping("/login") public ApiResult&lt;String&gt; login(@RequestBody User user, HttpServletResponse response) &#123; ApiResult&lt;String&gt; apiResult = new ApiResult&lt;&gt;(); try &#123; Authentication authentication = authenticationManager.authenticate(new UsernamePasswordAuthenticationToken( user.getUserName(), user.getUserPassword())); SecurityContextHolder.getContext().setAuthentication(authentication); // Reload password post-security so we can generate token String token = TOKEN_PREFIX + jwtTokenUtils.generateToken(user.getUserName(), secret, expiration); response.addCookie(new Cookie("userToken", token)); apiResult.success(token); &#125; catch (BadCredentialsException exception) &#123; log.error("验证出错: &#123;&#125;", exception.getMessage()); apiResult.fail("密码不正确或者用户不存在."); &#125; return apiResult; &#125; @GetMapping("/index") public String index() &#123; UserDetails userDetails = (UserDetails) org.springframework.security.core.context.SecurityContextHolder.getContext().getAuthentication().getPrincipal(); return "欢迎光临: " + userDetails.getUsername() + "," + userDetails.getPassword(); &#125;&#125; 详细项目地址：SpringBoot整合JWT]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>JSON Web Token认证</tag>
        <tag>SpringBoot</tag>
        <tag>Spring Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch安装部署(Windows)]]></title>
    <url>%2F2019%2F09%2F08%2FElasticSearch%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-Windows%2F</url>
    <content type="text"><![CDATA[测试版本：elasticsearch-5.1.1 解压elasticsearch-5.1.1.zip。 执行elasticsearch.bat启动服务，启动画面如下： 访问elasticsearch,访问地址：http://127.0.0.1:9200/。 安装elasticsearch head插件(不做说明) 配置JDK环境变量JAVA_HOME,PATH,CLASS_PATH。 注意：环境变量必须配置在系统变量下，否则后面服务启动不了，会报Failed creating java %JAVA_HOME%\jre\bin\server\jvm.dll错误。 安装elasticsearch成为win服务在cmd命令下执行： elasticsearch-service.bat install 在服务里面可以查看到安装的elasticsearch服务。 elasticsearch-service.bat后面还可以执行以下命令 install: 安装Elasticsearch服务 remove: 删除已安装的Elasticsearch服务（如果启动则停止服务） start: 启动Elasticsearch服务（如果已安装） stop: 停止服务（如果启动） manager:启动GUI来管理已安装的服务]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7自定义服务]]></title>
    <url>%2F2019%2F09%2F07%2FCentos7%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch查询种类]]></title>
    <url>%2F2019%2F09%2F07%2FElasticSearch%E6%9F%A5%E8%AF%A2%E7%A7%8D%E7%B1%BB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Data Commons抽象]]></title>
    <url>%2F2019%2F09%2F07%2FSpring-Data-Commons%E6%8A%BD%E8%B1%A1%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[JUC并发容器和框架]]></title>
    <url>%2F2019%2F09%2F07%2FJUC%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E5%92%8C%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程基础]]></title>
    <url>%2F2019%2F09%2F07%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[JUC中锁组件]]></title>
    <url>%2F2019%2F09%2F07%2FJUC%E4%B8%AD%E9%94%81%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[JUC并发工具类总结]]></title>
    <url>%2F2019%2F09%2F07%2FJUC%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[JUC原子操作类总结]]></title>
    <url>%2F2019%2F09%2F07%2FJUC%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%B1%BB%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[前言 当程序更新一个变量时，如果多线程同时更新这个变量，可能得到期望之外的值，比如变量i=1,A线程更新i+1， B线程也更新i+1，经过两个线程操作之后可能i不等于3，因为A和B线程在更新变量i的时候拿到的i都是1，这就是线程不安全的更新操作，通常我们会使用synchronized来解决这个问题，synchronized会保证多线程不会同时更新变量i。 而从JDK1.5开始提供了java.util.concurrent.atomic包（以下简称Atomic包），这个包中的原子操作类提供了一种用法简单、性能高效、线程安全地更新一个变量的方式。 因为变量的类型有很多种，所以在Atomic包里一共提供了13个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用和原子更新属性（字段）。 Atomic包里的类基本都是使用Unsafe实现的包装类。 原子更新基本类型 :类介绍 AtomicBoolean：原子更新布尔类型。 AtomicInteger：原子更新整型。 AtomicLong：原子更新长整型。 常用方法(AotmicInteger为例) int addAndGet（int delta）：以原子方式将输入的数值与实例中的值（AtomicInteger里的 value）相加，并返回结果。 boolean compareAndSet（int expect，int update）：如果输入的数值等于预期值，则以原子方 式将该值设置为输入的值。 int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。 int getAndSet（int newValue）：以原子方式设置为newValue的值，并返回旧值。 getAndIncrement实现原子操作原理 1234567891011121314public final int getAndIncrement () &#123; for (; ; ) &#123; // 先取出旧值 int current = get(); int next = current + 1; // 原子更新操作 if (compareAndSet(current, next)) return current; &#125;&#125;public final boolean compareAndSet ( int expect, int update)&#123; // 当前值,偏移量,内存预期值,更新值 return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 123456789/**如果当前数值是expected，则原子的将Java变量更新成x * @return 如果更新成功则返回true**/public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x);public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);public final native boolean compareAndSwapLong(Object o, long offset, long expected, long x); 其他实现 通过看AtomicBoolean源码，发现它是先把Boolean转换成整 型，再使用compareAndSwapInt进行CAS，所以原子更新char、float和double变量也可以用类似 的思路来实现。 原子更新Boolean 123456789101112131415161718192021 // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicBoolean.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value;/** * Creates a new &#123;@code AtomicBoolean&#125; with the given initial value. * * @param initialValue the initial value */ public AtomicBoolean(boolean initialValue) &#123; value = initialValue ? 1 : 0; &#125; 原子更新Double 123456789101112131415161718192021222324private transient volatile long value; private static final AtomicLongFieldUpdater&lt;AtomicDouble&gt; updater = AtomicLongFieldUpdater.newUpdater(AtomicDouble.class, "value"); /** * Creates a new &#123;@code AtomicDouble&#125; with the given initial value. * * @param initialValue the initial value */public AtomicDouble(double initialValue) &#123; value = doubleToRawLongBits(initialValue);&#125; /** * Atomically sets to the given value and returns the old value. * * @param newValue the new value * @return the previous value */public final double getAndSet(double newValue) &#123; long next = doubleToRawLongBits(newValue); return longBitsToDouble(updater.getAndSet(this, next));&#125; 原子更新数组通过原子的方式更新数组里某个元素。 类介绍 AtomicIntegerArray：原子更新整型数组里的元素。 AtomicLongArray：原子更新长整型数组里的元素。 AtomicReferenceArray：原子更新引用类型数组里的元素。 常用方法 int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引i的元素相加。 boolean compareAndSet（int i，int expect，int update）：如果当前值等于预期值，则以原子 方式将数组位置i的元素设置成update值。 注意：数组value通过构造方法传递进去，然后AtomicIntegerArray会将当前数组复制一份，所以当AtomicIntegerArray对内部的数组元素进行修改时，不会影响传入的数组。 示例 123456789 public class AtomicIntegerArrayTest &#123; static int[] value = new int[]&#123;1,2&#125;; static AtomicIntegerArray ai = new AtomicIntegerArray(value); public static void main(String[] args) &#123; ai.getAndSet(0， 3); System.out.println(ai.get(0)); System.out.println(value[0]); &#125;&#125; 原子更新引用类型原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。 类介绍 AtomicReference：原子更新引用类型。 AtomicReferenceFieldUpdater：原子更新引用类型里的字段。 AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子更新一个布尔类 型的标记位和引用类型。AtomicMarkableReference（V initialRef，boolean initialMark）。 示例 12345678910111213141516171819202122232425262728public class AtomicReferenceTest &#123; public static AtomicReference&lt;User&gt; atomicUserRef = new AtomicReference&lt;user&gt;(); public static void main(String[] args) &#123; User user = new User("conan",15); atomicUserRef.set(user); User updateUser = new User("Shinichi",17); atomicUserRef.compareAndSet(user,updateUser); System.out.println(atomicUserRef.get().getName()); System.out.println(atomicUserRef.get().getOld()); &#125; static class User &#123; private String name; private int old; public User(String name,int old) &#123; this.name = name; this.old = old; &#125; public String getName() &#123; return name; &#125; public int getOld() &#123; return old; &#125; &#125;&#125; 原子更新字段如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。 类介绍 AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。 AtomicLongFieldUpdater：原子更新长整型字段的更新器。 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的 ABA问题。 原子更新字段步骤 因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。 更新类的字段（属性）必须使用public volatile修饰符。 示例 12345678910111213141516171819202122232425262728293031public class AtomicIntegerFieldUpdaterTest &#123; // 创建原子更新器，并设置需要更新的对象类和对象的属性 private static AtomicIntegerFieldUpdater&lt;User&gt; a = AtomicIntegerFieldUpdater.newUpdater(User.class, "old"); public static void main(String[] args) &#123; // 设置柯南的年龄是10岁 User conan = new User("conan", 10); // 柯南长了一岁，但是仍然会输出旧的年龄 System.out.println(a.getAndIncrement(conan)); // 输出柯南现在的年龄 System.out.println(a.get(conan)); &#125; public static class User &#123; private String name; public volatile int old; public User(String name, int old) &#123; this.name = name; this.old = old; &#125; public String getName() &#123; return name; &#125; public int getOld() &#123; return old; &#125; &#125;&#125;]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>JUC</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis分页插件PageHelper使用]]></title>
    <url>%2F2019%2F09%2F07%2FMybatis%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6PageHelper%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[分页插件参数 reasonable：分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum&lt;=0 时会查询第一页，pageNum&gt;pages（超过总数时），会查询最后一页。默认false 时，直接根据参数进行查询 params：为了支持startPage(Object params)方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为: 12345pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero helperDialect：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置helperDialect属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值：oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby特别注意：使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012，否则会使用 SqlServer2005 的方式进行分页。你也可以实现 AbstractHelperDialect，然后配置该属性为实现类的全限定名称即可使用自定义的实现方法。 推荐使用12345678910111213141516//第二种，Mapper接口方式的调用，推荐这种使用方式。PageHelper.startPage(1, 10);List&lt;Country&gt; list = countryMapper.selectIf(1);//第三种，Mapper接口方式的调用，推荐这种使用方式。PageHelper.offsetPage(1, 10);List&lt;Country&gt; list = countryMapper.selectIf(1);//第四种，参数方法调用//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数public interface CountryMapper &#123; List&lt;Country&gt; selectByPageNumSize( @Param("user") User user, @Param("pageNum") int pageNum, @Param("pageSize") int pageSize);&#125; 注意点：(1)：PageHelper.startPage 静态方法调用在你需要进行分页的 MyBatis 查询方法前调用 PageHelper.startPage 静态方法即可，紧跟在这个方法后的第一个MyBatis 查询方法会被进行分页。 例如： 例一： 1234//获取第1页，10条内容，默认查询总数countPageHelper.startPage(1, 10);//紧跟着的第一个select方法会被分页List&lt;Country&gt; list = countryMapper.selectIf(1); 例二： 123456PageHelper.startPage(request);//紧跟着的第一个select方法会被分页List&lt;Country&gt; list = countryMapper.selectIf(1);//后面的不会被分页，除非再次调用PageHelper.startPageList&lt;Country&gt; list2 = countryMapper.selectIf(null); (2)：PageInfo的用法12345678910111213141516171819//获取第1页，10条内容，默认查询总数countPageHelper.startPage(1, 10);List&lt;Country&gt; list = countryMapper.selectAll();//用PageInfo对结果进行包装PageInfo page = new PageInfo(list);//测试PageInfo全部属性//PageInfo包含了非常全面的分页属性assertEquals(1, page.getPageNum());assertEquals(10, page.getPageSize());assertEquals(1, page.getStartRow());assertEquals(10, page.getEndRow());assertEquals(183, page.getTotal());assertEquals(19, page.getPages());assertEquals(1, page.getFirstPage());assertEquals(8, page.getLastPage());assertEquals(true, page.isFirstPage());assertEquals(false, page.isLastPage());assertEquals(false, page.isHasPreviousPage());assertEquals(true, page.isHasNextPage()); (3)：改变默认分页参数想要使用参数方式，需要配置 supportMethodsArguments 参数为 true，同时要配置 params 参数。 例如下面的配置： 12345678&lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor="com.github.pagehelper.PageInterceptor"&gt; &lt;!-- 使用下面的方式配置参数，后面会有所有的参数介绍 --&gt; &lt;property name="supportMethodsArguments" value="true"/&gt; &lt;property name="params" value="pageNum=pageNumKey;pageSize=pageSizeKey;"/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 在Mybatis方法中： 1234List&lt;Country&gt; selectByPageNumSize( @Param("user") User user, @Param("pageNumKey") int pageNum, @Param("pageSizeKey") int pageSize); 当调用这个方法时，由于同时发现了 pageNumKey 和 pageSizeKey 参数，这个方法就会被分页。params 提供的几个参数都可以这样使用。 (4)：PageHelper安全调用 什么时候会导致不安全的分页？ PageHelper 方法使用了静态的 ThreadLocal 参数，分页参数和线程是绑定的。 只要你可以保证在 PageHelper 方法调用后紧跟 MyBatis 查询方法，这就是安全的。因为 PageHelper 在 finally 代码段中自动清除了 ThreadLocal 存储的对象。 如果代码在进入 Executor 前发生异常，就会导致线程不可用，这属于人为的 Bug（例如接口方法和 XML 中的不匹配，导致找不到 MappedStatement 时）， 这种情况由于线程不可用，也不会导致 ThreadLocal 参数被错误的使用。 如下： 1234567PageHelper.startPage(1, 10);List&lt;Country&gt; list;if(param1 != null)&#123; list = countryMapper.selectIf(param1);&#125; else &#123; list = new ArrayList&lt;Country&gt;();&#125; 这种情况下由于 param1 存在 null 的情况，就会导致 PageHelper 生产了一个分页参数，但是没有被消费，这个参数就会一直保留在这个线程上。当这个线程再次被使用时，就可能导致不该分页的方法去消费这个分页参数，这就产生了莫名其妙的分页。 正确如下： 1234567List&lt;Country&gt; list;if(param1 != null)&#123; PageHelper.startPage(1, 10); list = countryMapper.selectIf(param1);&#125; else &#123; list = new ArrayList&lt;Country&gt;();&#125; (5)：请不要配置多个分页插件请不要在系统中配置多个分页插件(使用Spring时,mybatis-config.xml和Spring&lt;bean&gt;配置方式，请选择其中一种，不要同时配置多个分页插件)！ (6)：分页插件不支持嵌套结果映射由于嵌套结果方式会导致结果集被折叠，因此分页查询的结果在折叠后总数会减少，所以无法保证分页结果数量正确。 (7)：分页插件不支持带有for update语句的分页对于带有for update的sql，会抛出运行时异常，对于这样的sql建议手动分页，毕竟这样的sql需要重视。 (8)：SpringBoot使用Mybatis,分页插件PageHelperapplication.properties配置 123456789pagehelper: helperDialect: mysql reasonable: true supportMethodsArguments: true params: count=countSql mybatis: type-aliases-package: tk.mybatis.springboot.model mapper-locations: classpath:mapper/*.xml]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>PageHelper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Config 规范]]></title>
    <url>%2F2019%2F09%2F04%2FSpring-Cloud-Config-%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[Spring Cloud Config规范转载 : Spring Cloud Config规范 首先Spring Cloud 是基于 Spring 来扩展的，Spring 本身就提供当创建一个Bean时可从Environment 中将一些属性值通过@Value的形式注入到业务代码中的能力。那Spring Cloud Config 要解决的问题就是： 如何将配置加载到 Environment 。 配置变更时，如何控制 Bean 是否需要 create,重新触发一次 Bean 的初始化，才能将 @Value 注解指定的字段从 Environment 中重新注入。 配置变更时，如何控制新的配置会更新到 Environment 中，才能保证配置变更时可注入最新的值。 要解决以上三个问题：Spring Cloud Config 规范中刚好定义了核心的三个接口： PropertySourceLocator：抽象出这个接口，就是让用户可定制化的将一些配置加载到 Environment。这部分的配置获取遵循了 Spring Cloud Config 的理念，即希望能从外部储存介质中来 loacte。 RefreshScope: Spring Cloud 定义这个注解，是扩展了 Spring 原有的 Scope 类型。用来标识当前这个 Bean 是一个refresh 类型的 Scope。其主要作用就是可以控制 Bean 的整个生命周期。 ContextRefresher：抽象出这个 Class，是让用户自己按需来刷新上下文(比如当有配置刷新时，希望可以刷新上下文，将最新的配置更新到 Environment，重新创建 Bean 时，就可以从 Environment 中注入最新的配置)。 Spring Cloud Config 原理1、如何将配置加载到Environment：PropertySourceLocator在整个 Spring Boot 启动的生命周期过程中，有一个阶段是 prepare environment。在这个阶段，会publish 一个 ApplicationEnvironmentPreparedEvent，通知所有对这个事件感兴趣的 Listener,提供对 Environment 做更多的定制化的操作。Spring Cloud 定义了一个BootstrapApplicationListener，在 BootstrapApplicationListener 的处理过程中有一步非常关键的操作如下所示： 12345678910private ConfigurableApplicationContext bootstrapServiceContext( ConfigurableEnvironment environment, final SpringApplication application, String configName) &#123; //省略 ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // Use names and ensure unique to protect against duplicates List&lt;String&gt; names = new ArrayList&lt;&gt;(SpringFactoriesLoader .loadFactoryNames(BootstrapConfiguration.class, classLoader)); //省略 &#125; 这是 Spring 的工厂加载机制，可通过在 META-INF/spring.factories 文件中配置一些程序中预定义的一些扩展点。比如 Spring Cloud 这里的实现，可以看到 BootstrapConfiguration 不是一个具体的接口，而是一个注解。通过这种方式配置的扩展点好处是不局限于某一种接口的实现，而是同一类别的实现。可以查看 spring-cloud-context 包中的 spring.factories 文件关于BootstrapConfiguration的配置，有一个比较核心入口的配置就是： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration 可以发现 PropertySourceBootstrapConfiguration 实现了 ApplicationContextInitializer 接口，其目的就是在应用程序上下文初始化的时候做一些额外的操作。在 Bootstrap 阶段，会通过 Spring IOC 的整个生命周期来初始化所有通过key为org.springframework.cloud.bootstrap.BootstrapConfiguration 在 spring.factories 中配置的 Bean。Spring Cloud Alibaba Nacos Config 的实现就是通过该key来自定义一些在Bootstrap 阶段需要初始化的一些Bean。在该模块的 spring.factories 配置文件中可以看到如下配置： 在 Bootstrap 阶段初始化的过程中，会获取所有 ApplicationContextInitializer 类型的 Bean，并设置回SpringApplication主流程当中。如下 BootstrapApplicationListener 类中的部分代码所示： 12345678910111213private void apply(ConfigurableApplicationContext context, SpringApplication application, ConfigurableEnvironment environment) &#123; @SuppressWarnings("rawtypes") //这里的 context 是一个 bootstrap 级别的 ApplicationContext，这里已经含有了在 bootstrap阶段所有需要初始化的 Bean。 //因此可以获取 ApplicationContextInitializer.class 类型的所有实例 List&lt;ApplicationContextInitializer&gt; initializers = getOrderedBeansOfType(context, ApplicationContextInitializer.class); //设置回 SpringApplication 主流程当中 application.addInitializers(initializers .toArray(new ApplicationContextInitializer[initializers.size()])); //省略...&#125; 这样一来，就可以通过在 SpringApplication 的主流程中来回调这些ApplicationContextInitializer 的实例，做一些初始化的操作。如下 SpringApplication 类中的部分代码所示： 12345678910111213141516171819private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); //回调在BootstrapApplicationListener中设置的ApplicationContextInitializer实例 applyInitializers(context); listeners.contextPrepared(context); //省略...&#125;protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument( initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, "Unable to call initializer."); initializer.initialize(context); &#125;&#125; 在 applyInitializers 方法中，会触发 PropertySourceBootstrapConfiguration 中的 initialize 方法。如下所示： 123456789101112131415161718192021222324252627@Overridepublic void initialize(ConfigurableApplicationContext applicationContext) &#123; CompositePropertySource composite = new CompositePropertySource( BOOTSTRAP_PROPERTY_SOURCE_NAME); AnnotationAwareOrderComparator.sort(this.propertySourceLocators); boolean empty = true; ConfigurableEnvironment environment = applicationContext.getEnvironment(); for (PropertySourceLocator locator : this.propertySourceLocators) &#123; PropertySource&lt;?&gt; source = null; //回调所有实现PropertySourceLocator接口实例的locate方法， source = locator.locate(environment); if (source == null) &#123; continue; &#125; composite.addPropertySource(source); empty = false; &#125; if (!empty) &#123; //从当前Enviroment中获取 propertySources MutablePropertySources propertySources = environment.getPropertySources(); //省略... //将composite中的PropertySource添加到当前应用上下文的propertySources中 insertPropertySources(propertySources, composite); //省略... &#125;&#125; 在这个方法中会回调所有实现 PropertySourceLocator 接口实例的locate方法，locate 方法返回一个 PropertySource 的实例，统一add到CompositePropertySource实例中。如果 composite 中有新加的PropertySource,最后将composite中的PropertySource添加到当前应用上下文的propertySources中。Spring Cloud Alibaba Nacos Config 在 Bootstrap 阶段通过Java配置的方式初始化了一个 NacosPropertySourceLocator 类型的Bean。从而在 locate 方法中将存放在Nacos中的配置信息读取出来，将读取结果存放到 PropertySource 的实例中返回。具体如何从Nacos中读取配置信息可参考 NacosPropertySourceLocator 类的实现。 Spring Cloud Config 正是提供了PropertySourceLocator接口，来提供应用外部化配置可动态加载的能力。Spring Ioc 容器在初始化 Bean 的时候，如果发现 Bean 的字段上含有 @Value 的注解，就会从 Enviroment 中的PropertySources 来获取其值，完成属性的注入。 Spring Cloud Config 外部化配置可动态刷新感知到外部化配置的变更这部分代码的操作是需要用户来完成的。Spring Cloud Config 只提供了具备外部化配置可动态刷新的能力，并不具备自动感知外部化配置发生变更的能力。比如如果你的配置是基于Mysql来实现的，那么在代码里面肯定要有能力感知到配置发生变化了，然后再显示的调用 ContextRefresher 的 refresh方法，从而完成外部化配置的动态刷新(只会刷新使用RefreshScope注解的Bean)。 例如在 Spring Cloud Alibaba Nacos Config 的实现过程中，Nacos 提供了对dataid 变更的Listener 回调。在对每个dataid 注册好了相应的Listener之后，如果Nacos内部通过长轮询的方式感知到数据的变更，就会回调相应的Listener,在 Listener 的实现过程中，就是通过调用 ContextRefresher 的 refresh方法完成配置的动态刷新。具体可参考 NacosContextRefresher 类的实现。 Spring Cloud Config的动态配置刷新原理图如下所示： ContextRefresher的refresh的方法主要做了两件事： 触发PropertySourceLocator的locator方法，需要加载最新的值，并替换 Environment 中旧值 Bean中的引用配置值需要重新注入一遍。重新注入的流程是在Bean初始化时做的操作，那也就是需要将refresh scope中的Bean 缓存失效，当再次从refresh scope中获取这个Bean时，发现取不到，就会重新触发一次Bean的初始化过程。 这两个操作所对应的代码如下所示： 123456789101112public synchronized Set refresh() &#123; Map&lt;String, Object&gt; before = extract( this.context.getEnvironment().getPropertySources()); //1、加载最新的值，并替换Envrioment中旧值 addConfigFilesToEnvironment(); Set&lt;String&gt; keys = changes(before, extract(this.context.getEnvironment().getPropertySources())).keySet(); this.context.publishEvent(new EnvironmentChangeEvent(context, keys)); //2、将refresh scope中的Bean 缓存失效: 清空 this.scope.refreshAll(); return keys;&#125; addConfigFilesToEnvironment 方法中发生替换的代码如下所示： 123456789101112131415161718192021222324252627ConfigurableApplicationContext addConfigFilesToEnvironment() &#123; ConfigurableApplicationContext capture = null; try &#123; //省略... //1、这里会重新触发PropertySourceLoactor的locate的方法,获取最新的外部化配置 capture = (SpringApplicationBuilder)builder.run(); MutablePropertySources target = this.context.getEnvironment() .getPropertySources(); String targetName = null; for (PropertySource&lt;?&gt; source : environment.getPropertySources()) &#123; String name = source.getName(); //省略.. //只有不是标准的 Source 才可替换 if (!this.standardSources.contains(name)) &#123; if (target.contains(name)) &#123; //开始用新的PropertySource替换旧值 target.replace(name, source); &#125; // &#125; &#125; &#125; // return capture;&#125; this.scope.refreshAll() 清空缓存的操作代码如下所示： 1234567@Overridepublic void destroy() &#123; List&lt;Throwable&gt; errors = new ArrayList&lt;Throwable&gt;(); //清空Refresh Scope 中的缓存 Collection&lt;BeanLifecycleWrapper&gt; wrappers = this.cache.clear(); //省略...&#125; 为了验证每次配置刷新时，Bean 是新创建的，特意写了一个Demo 验证了下，如下所示： 123456Acm Properties: beijing-region//刷新前Object Instance is :com.alibaba.demo.normal.ConfigProperties@1be96342018-11-01 19:16:32.535 INFO 27254 --- [gPullingdefault] startup date [Thu Nov 01 19:16:32 CST 2018]; root of context hierarchyAcm Properties: qingdao-region//刷新后Object Instance is :com.alibaba.demo.normal.ConfigProperties@2c6965e0 Spring Cloud Config 扩展Scope的核心类:RefreshScope可以看到上面的代码中有 this.scope.refreshAll()，其中的scope就是RefreshScope。是用来存放scope类型为refresh类型的Bean（即使用RefreshScope注解标识的Bean），也就是说当一个Bean既不是singleton也不是prototype时，就会从自定义的Scope中去获取(Spring 允许自定义Scope)，然后调用Scope的get方法来获取一个实例，Spring Cloud 正是扩展了Scope，从而控制了整个 Bean 的生命周期。当配置需要动态刷新的时候， 调用this.scope.refreshAll()这个方法，就会将整个RefreshScope的缓存清空，完成配置可动态刷新的可能。 后续关于ContextRefresh 和 RefreshScope的初始化配置是在RefreshAutoConfiguration类中完成的。而RefreshAutoConfiguration类初始化的入口是在spring-cloud-context中的META-INF/spring.factories中配置的。从而完成整个和动态刷新相关的Bean的初始化操作。]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Spring Cloud Config</tag>
        <tag>外部化自动刷新配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 事件]]></title>
    <url>%2F2019%2F09%2F03%2FSpringBoot-%E4%BA%8B%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[SpringBoot事件尽管SpringApplicationRunListener和SpringBoot事件(SpringApplicationEvent)从SpringBoot 1.0开始引入，然而纵观SpringBoot 1.x~2.0的发展，监听方法与SpringBoot事件的对应关系发生了变化。事件如下表所示： 监听方法 SpringBoot事件 SpringBoot起始版本 starting() ApplicationStartingEvent 1.5 environmentPrepared(ConfigurableEnvironment ) ApplicationEnvironmentPreparedEvent 1.0 contextPrepared(ConfigurableApplicationContext ); 1.0 contextLoaded(ConfigurableApplicationContext context); ApplicationPreparedEvent 1.0 started(ConfigurableApplicationContext ) ApplicationStartedEvent 1.0 running(ConfigurableApplicationContext ) ApplicationReadyEvent 1.3 failed(ConfigurableApplicationContext ,Throwable ) ApplicationFailedEvent 1.0 值得注意的是，SpringApplicationRunListener是SpringBoot应用运行时监听器，并非SpringBoot事件监听器。不过SpringBoot官方文档对这部分只字未提，开发人员只要遵照SpringApplicationListener构造器参数约定，以及结合SpringFactoriesLoader机制,完全能够将该接口进行扩展。 换言之，以上SpringBoot事件所对应的ApplicationListener实现由SpringApplication构造器参数关联并添加属性SimpleApplicationEventMulticaster#initialMulticaster属性中。 官方进一步解释了这些事件的顺序和时机： ApplicationStartingEvent：在应用开始运行但还没有进行任何处理时(除了注册监听器[listeners ]和初始化器[initializers])。 ApplicationEnvironmentPreparedEvent ：当Environment被上下文使用，但是在上下文创建之前。可以修改和检查Environment。 ApplicationPreparedEvent：在开始刷新之前，bean的定义均被加载，Environment可以投入使用。 ApplicationStartedEvent：上下文刷新之后，但是在所有应用和命令行运行期(command line runner)被调用之前。 ApplicationReadyEvent：在应用程序和命令行运行器(command line runner)被调用之后，该事件用于通知应用已经准备处理请求。 ApplicationFailedEvent：启动时发送异常将发送 SpringApplicationRunListener1234567891011121314151617181920212223public interface SpringApplicationRunListener &#123; // ApplicationStartingEvent void starting(); // ApplicationEnvironmentPreparedEvent void environmentPrepared(ConfigurableEnvironment environment); // ApplicationPreparedEvent void contextPrepared(ConfigurableApplicationContext context); void contextLoaded(ConfigurableApplicationContext context); // ApplicationStartedEvent void started(ConfigurableApplicationContext context); // ApplicationReadyEvent void running(ConfigurableApplicationContext context); // ApplicationFailedEvent void failed(ConfigurableApplicationContext context, Throwable exception);&#125; SpringBoot1.4事件处理之后变动SpringBoot 1.4开始,框架层面采用的是Spring Boot事件和Spring事件&quot;各自为政，互不干涉&quot;的设计原则。在实现上，前后设计差异主要体现在EventPublishingRunListener关联的SimpleApplicationEventMulticaster注册为Spring Bean。 SpringBoot 1.4以前，由于SpringApplication和ApplicationContext共用SimpleApplicationEventMulticaster对象的原因，Spring应用上下文中ApplicationListener Bean和@EventListener方法均能监听Spring Boot ApplicationReadyEvent和ApplicationFailedEvent事件。 123456789101112131415161718192021222324252627public class EventPublishingRunListener implements SpringApplicationRunListener, Ordered &#123; // SpringBoot 1.4 以后 ... @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; &#125; ... // SpringBoot 1.4以前 @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; registerApplicationEventMulticaster(context); &#125; private void registerApplicationEventMulticaster( ConfigurableApplicationContext context) &#123; context.getBeanFactory().registerSingleton( AbstractApplicationContext.APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.multicaster); if (this.multicaster instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) this.multicaster) .setBeanFactory(context.getBeanFactory()); &#125; &#125;&#125; 如此实现就杜绝了Spring应用上下文所关联的ApplicationListener接受SpringBoot事件的广播，从而各自监听所在环境的事件。值得注意的事，EventPublishingRunListener仍在调用其contextLoaded()方法时，将SpringApplication所关联的ApplicationListener添加至ConfigurableApplicationContext中： 123456789101112@Overridepublic void contextLoaded(ConfigurableApplicationContext context) &#123; for (ApplicationListener&lt;?&gt; listener : this.application.getListeners()) &#123; if (listener instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) listener).setApplicationContext(context); &#125; context.addApplicationListener(listener); &#125; this.initialMulticaster.multicastEvent( new ApplicationPreparedEvent(this.application, this.args, context));&#125; 根据EventPublishingRunListener生命周期回调的特性，此时Spring应用上下文尚未初始化。因此，以上添加操作最终会追加到AbstractApplicationContext所关联的SimpleApplicationEventMulticaster属性中，当前Spring应用上下文发布完Spring事件后，这些被contextLoaded方法监听的ApplicationListener集合能够被它们监听。示例验证： 12345678public class SpringEventListenerBootStrap&#123; public static void main(String[] args)&#123; new SpringApplicationBuidler(Object.class) listeners(event-&gt;System.out.println("SpringApplication事件监听器: "+ event.getClass().getSimpleName())) .web(false).run(args).close(); &#125;&#125; 总结 SpringBoot事件/监听机制继承与Spring事件/监听机制，同样涵盖SpringBoot事件，SpringBoot事件监听手段，SpringBoot事件广播器等。 (1)：总结SpringBoot事件​ SpringBoot事件类型继承Spring事件类型ApplicationEvent，并且也是SpringApplicationEvent子类。 大多数Spring内建事件为Spring应用上下文事件,即ApplicationContextEvent，其事件源为ApplicationContext。而SpringBoot事件源则是SpringApplication，其内建事件根据EventPublishingRunListener生命周期回调方法依次发布。其中,ApplicationReadyEvent和ApplicationFailedEvent在Spring应用上下文初始化发布，即在 ContextRefreshedEvent之后发布。 (2)：SpringBoot事件监听手段​ 尽管SpringBoot事件监听器仍然继承于Spring，不过由于SpringBoot 1.4版本前后采取了不同的设计，因此其监听手段需要区别对待。 ​ 在早期SpringBoot事件监听机制(SpringBoot 1.0~1.3版本)中，由于SpringApplication与Spring应用上下文 ConfigurableApplicationContext采用相同的SimpleApplicationEventMulticaster实例，因此Spring关联的 ApplicationListener和@EventListener方法能够监听Spring Boot事件ApplicationReadyEvent和 ApplicationFailedEvent。随着SpringBoot 1.4开始采用SpringApplication与ConfigurableApplicationContext 隔离SimpleApplicationEventMulticaster实例的设计，这种监听手段不在奏效。换言之，从此时开始，SpringBoot事件监听手段仅为SpringApplication关联的ApplicationListener对象集合。其关联路径有二，一为SpringApplication构造阶段在Class Path下所在加载的META-INF/spring.factories资源中的ApplicationListener对象集合；二是通过方法SpringApplication#addListeners(ApplicationListener…)或者 SpringApplicationBuilder#listeners(ApplicationListener)显示地装配。 (3)：SpringBoot事件广播器​ SpringBoot事件广播器同样来源Spring的实现类SimpleApplicationEventMulticaster，其广播行为与Spring事件广播毫无差别，只不过SpringBoot发布事件类型是特定的。因此可以完整的做出以下结论，SpringBoot事件机制继承与Spring事件监听机制，其事件类型继承与Spring ApplicationEvent，事件监听器仍通过ApplicationListener实现，而广播器实现SimpleApplicationEventMulticaster将它们关联起来。 ​ EventPublishingRunListener作为SpringBoot事件发布的执行者，也是SpringBoot框架内部的唯一的 SpringApplicationRunListener实现类。]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Spring Boot事件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot ApplicationRunner接口]]></title>
    <url>%2F2019%2F09%2F03%2FSpringBoot-ApplicationRunner%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>ApplicationRunnber</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synchronized关键字的使用和原理解析]]></title>
    <url>%2F2019%2F09%2F03%2FSynchronized%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Volatile关键字的使用和原理解析]]></title>
    <url>%2F2019%2F09%2F03%2FVolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Netty编程三步走]]></title>
    <url>%2F2019%2F09%2F03%2FNetty%E7%BC%96%E7%A8%8B%E4%B8%89%E6%AD%A5%E8%B5%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Netty]]></title>
    <url>%2F2019%2F09%2F03%2FSpringBoot%E6%95%B4%E5%90%88Netty%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring上下文多次刷新的问题]]></title>
    <url>%2F2019%2F08%2F30%2FSpring%E4%B8%8A%E4%B8%8B%E6%96%87%E5%A4%9A%E6%AC%A1%E5%88%B7%E6%96%B0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1: GenericApplicationContext上下文的实现类多次刷新由于该类refreshBeanFactory()方法限制了上下文只能被刷新一次。例如实现类AnnotationConfigApplicatioContext注解上下文，上下文不能多次刷新。 AnnotationConfigApplicatioContext ReactiveWebServerApplicationContext AnnotationConfigServletWebServerApplicationContext ServletWebServerApplicationContext XmlServletWebServerApplicationContext 123456789@Componentpublic class MultiApplicationContextRefresh &#123; public static void main(String[] args) throws InterruptedException &#123; AnnotationConfigApplicationContext context=new AnnotationConfigApplicationContext(MultiApplicationContextRefresh.class); context.refresh(); context.refresh(); &#125;&#125; 12345Exception in thread "main" java.lang.IllegalStateException: GenericApplicationContext does not support multiple refresh attempts: just call 'refresh' once at org.springframework.context.support.GenericApplicationContext.refreshBeanFactory(GenericApplicationContext.java:264) at org.springframework.context.support.AbstractApplicationContext.obtainFreshBeanFactory(AbstractApplicationContext.java:619) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:520) at com.ley.spring.refresh.MultiApplicationContextRefresh.main(MultiApplicationContextRefresh.java:12) 2: AbstractXmlApplicationContext实现类多次刷新由于该类并没有对refresh()函数做限制，可以进行多次刷新。 12345678910public class MultiApplicationContextRefresh &#123; public static void main(String[] args) throws InterruptedException &#123; ClassPathXmlApplicationContext context1=new ClassPathXmlApplicationContext("classpath:applicationContext.xml"); context1.refresh(); System.out.println(context1.getBean("user")); context1.refresh(); System.out.println(context1.getBean("user")); &#125;&#125; 123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd" default-lazy-init="false"&gt; &lt;bean id="user" class="com.ley.spring.refresh.User"&gt; &lt;property name="age" value="20"/&gt; &lt;/bean&gt;&lt;/beans&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>ApplicatioContext</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL5.7中JSON系列部分操作函数]]></title>
    <url>%2F2019%2F08%2F30%2FMySQL5-7%E4%B8%ADJSON%E7%B3%BB%E5%88%97%E9%83%A8%E5%88%86%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[创建JSON值函数 JSON_ARRAY([*val*[, *val*\] ...]) 123456mysql&gt; SELECT JSON_ARRAY(1, "abc", NULL, TRUE, CURTIME());+---------------------------------------------+| JSON_ARRAY(1, "abc", NULL, TRUE, CURTIME()) |+---------------------------------------------+| [1, "abc", null, true, "11:30:24.000000"] |+---------------------------------------------+ 查找JSON值函数 JSON_CONTAINS(target, candidate[, path])：查看候选的JSON文档是否包含在目标JSON文档。path为目标JSON文档路径名。 12345SET @j = '&#123;"a": 1, "b": 2, "c": &#123;"d": 4&#125;&#125;';SET @j2 = '1';-- $.a:代表意思是取目标JSON文档的路径下的值-- trueSELECT JSON_CONTAINS(@j, @j2, '$.a'); JSON_CONTAINS_PATH(json_doc, one_or_all, path[, path] ...):查找候选的JSON文档是否包含在目标JSON文档。支持OGNL表达式 ‘one’：至少一个JSON路径含有候选文档 ‘all’：所有JSON路径含有候选文档。 123456789101112SET @j = '&#123;"a": 1, "b": 2, "c": &#123;"d": 4&#125;&#125;';-- trueSELECT JSON_CONTAINS_PATH(@j, 'one', '$.a', '$.e');-- falseSELECT JSON_CONTAINS_PATH(@j, 'all', '$.a', '$.e');-- trueSELECT JSON_CONTAINS_PATH(@j, 'one', '$.c.d');-- falseSELECT JSON_CONTAINS_PATH(@j, 'one', '$.a.d'); JSON_EXTRACT(json_doc, path[, path] ...)：从JSON文档返回指定下path的JSON数据。*代表所有 123456789-- $[1]:代表取数组下标为1的数据-- 20SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]');-- [20,10]SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]', '$[0]');-- [30,40]SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[2][*]');]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 Stream之list转map问题及解决]]></title>
    <url>%2F2019%2F08%2F28%2FJava8-Stream%E4%B9%8Blist%E8%BD%ACmap%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[前言:List集合转Map,用到的是Stream中Collectors.toMap方法。示例如下： 123456789//声明一个List集合List&lt;Person&gt; list = new ArrayList(); list.add(new Person("1001", "小A")); list.add(new Person("1002", "小B")); list.add(new Person("1003", "小C"));System.out.println(list);//将list转换mapMap&lt;String, String&gt; map = list.stream().collect(Collectors.toMap(Person::getId, Person::getName));System.out.println(map); 输出结果为： 问题(1)：Duplicate key xxx原因是声明的List集合时,有的值重复。 重复时用后面value覆盖前面的value 12345678910@Testpublic void test2() &#123; List&lt;Person&gt; list = new ArrayList&lt;&gt;(); list.add(new Person("1001", "小A")); list.add(new Person("1001", "小B")); list.add(new Person("1003", "小C")); Map&lt;String, String&gt; map = list.stream() .collect(Collectors.toMap(Person::getId, Person::getName, (key1, key2) -&gt; key2)); System.out.println(map);&#125; 重复时将前面的value和后面的value拼接起来 12345678910@Testpublic void test2() &#123; List&lt;Person&gt; list = new ArrayList&lt;&gt;(); list.add(new Person("1001", "小A")); list.add(new Person("1001", "小B")); list.add(new Person("1003", "小C")); Map&lt;String, String&gt; map = list.stream() .collect(Collectors.toMap(Person::getId, Person::getName, (key1, key2) -&gt; key1 + "," + key2)); System.out.println(map);&#125; 重复时将重复的key的数据组成集合 12345678910111213141516@Testpublic void test2() &#123; List&lt;Person&gt; list = new ArrayList&lt;&gt;(); list.add(new Person("1001", "小A")); list.add(new Person("1001", "小B")); list.add(new Person("1003", "小C")); Map&lt;String, List&lt;String&gt;&gt; map = list.stream().collect(Collectors.toMap(Person::getId, p -&gt; &#123; List&lt;String&gt; getNameList = new ArrayList&lt;&gt;(); getNameList.add(p.getName()); return getNameList; &#125;, (List&lt;String&gt; value1, List&lt;String&gt; value2) -&gt; &#123; value1.addAll(value2); return value1; &#125;)); System.out.println(map);&#125; (2)：第二种问题报错误：NullPointerException原因：声明List集合时有的值为空，但是HashMap中k,v是可以存null值的 1234567891011121314151617@Testpublic void test2() &#123; // 声明一个List集合 List&lt;Person&gt; list = new ArrayList&lt;&gt;(); list.add(new Person(&quot;1001&quot;, &quot;小A&quot;)); list.add(new Person(&quot;1002&quot;, &quot;小B&quot;)); list.add(new Person(&quot;1003&quot;, null)); Map&lt;String, List&lt;String&gt;&gt; map = list.stream().collect(Collectors.toMap(Person::getId, p -&gt; &#123; List&lt;String&gt; getNameList = new ArrayList&lt;&gt;(); getNameList.add(p.getName()); return getNameList; &#125;, (List&lt;String&gt; value1, List&lt;String&gt; value2) -&gt; &#123; value1.addAll(value2); return value1; &#125;)); System.out.println(map);&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决idea控制台输出中文乱码问题]]></title>
    <url>%2F2019%2F08%2F27%2F%E8%A7%A3%E5%86%B3idea%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题情况Idea控制台输出中文乱码部分如图所示： 解决方案 如果是tomcat启动显示中文乱码，打开tomcat配置页面，Edit Congiurations。 选择项目部署的tomcat，在配置项VM options文本输入-Dfile.encoding=UTF-8，点击Apply或者OK即可。 重启tomcat，tomcat乱码问题解决。 若乱码问题依然存在，请尝试继续按以下步骤解决： File-&gt;Settings-&gt;Editor-&gt;File Encodings 设置文件编码为UTF-8，*.properties勾上Transparent native-to-ascii conversion。 ​ File-&gt;Settings-&gt;Build,Execution,Deployment-&gt;Compiler-&gt;Java Complier 设置 Additional command line parameters选项为 -encoding utf-8 打卡Idea本地安装目录的bin文件夹下idea.exe.vmoptions和idea64.exe.vmoptions这两个文件。在文件末尾追加-Dfile.encoding=UTF-8。 然后重启Idea即可解决乱码问题。]]></content>
      <categories>
        <category>Idea</category>
      </categories>
      <tags>
        <tag>Idea</tag>
        <tag>中文乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 扩展接口(SPI)]]></title>
    <url>%2F2019%2F08%2F27%2FSpring-%E6%89%A9%E5%B1%95%E6%8E%A5%E5%8F%A3-SPI%2F</url>
    <content type="text"></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 yum方式安装MySQL5.7]]></title>
    <url>%2F2019%2F08%2F25%2FCentos7-yum%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85MySQL5-7%2F</url>
    <content type="text"></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud整合Nacos篇之服务提供者]]></title>
    <url>%2F2019%2F08%2F25%2FSpringCloud%E6%95%B4%E5%90%88Nacos%E7%AF%87%E4%B9%8B%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E8%80%85%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库SQL性能分析]]></title>
    <url>%2F2019%2F08%2F25%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93SQL%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1:查询性能优化一般来说在编写SQL时，需要注意以下问题： 是否能使用到索引。 是否在大表中或者高频率查询中引起全表查询。 主要通过经验分析配合 explain 关键字来进行分析。 2:查询基础了解查询过程，才能知道哪些步骤可能出现瓶颈，execution plain 结果也会有限体现： Client往服务器发送查询指令 服务器查询缓存，如果存在则直接返回，否则下一步 服务器解析，预处理，优化查询，生成执行计划 执行引擎调用存储引擎API执行查询 服务器将结果返回给客户端 (2-1):优化数据访问 应用程序是否获取超过需要的数据量？(多次遇到过查询表所有数据然后在程序中只读取10行之类的代码。) MySQL服务器是否分析了超过需要的行？ 数据是否没有存储引擎层被过来掉？(Using index,Using where) (2-2):访问类型Full Table Scan &gt; Index Scan &gt; Range Scan &gt; Unique Index LookUp &gt; Constant 访问速度依次递增。 对于使用where语句来过滤数据的话,最好到最坏的情况是： 对索引查询用where来消除不匹配的数据行，在存储引擎层。 使用覆盖索引(Extra为Using Index)来避免访问行，取得索引数据后过滤行，发送在MySQL服务层。 从表中查询数据，然后过滤(Using Where)，发送在服务端并且要读取行数据。 (2-3):关于执行计划执行计划结果样例如下图： id,type,key,rows,extra是衡量指标。 (2-3-1): id: select查询序列号，表示查询中执行select子句或操作表顺序 id相同，执行顺序由上至下 id不同，如果是子查询，id序号会递增，id值越大优先级越高，越先被执行。 id相同不同，id如果相同，可以被认为是一组，由上至下执行；在所有组中id值越大，优先级越高，越先被执行。 (2-3-2)：select_type：查询类型，主要用于区别普通查询，联合查询，子查询等复杂查询 simple：简单的select查询，查询不包含子查询。 primary：查询中若包含任何复杂的子部分，最外层查询则被标记为primary。 subquery：在select或者where列表中包含了子查询 derived：在from列表中包含的子查询被标记为derived(衍生)，MySQL会递归执行这些子查询，把结果存到临时表中。 union：在第二个select出现在union之后，则被标记为union。 union result：从union表获取结果的select (2-3-3): table：显示这一行数据是关于哪张表 (2-3-4)：type：访问类型排列，显示了查询使用何种类型，结果值从最好到最坏。 system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL system：表只有一行记录（等于系统表），这是const类型的特列，平时不会出现，这个也可以忽略不计 const：表示通过索引一次就找到了,const**用于比较primary key或者unique索引。** eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描 ref：非唯一性索引扫描，返回匹配某个单独值的所有行。属于查找和扫描的混合体 range：只检索给定范围的行,使用一个索引来选择行。key 列显示使用了哪个索引一般就是在你的where。例如 语句中出现了between，&lt;，&gt;，in等查询这种范围扫描索引比全表扫描要好。 index：index和ALL区别为Index类型只遍历索引树。index从索引读，ALL从磁盘读。 all：全表扫描，将遍历全表找到匹配行。 一般来说，得保证查询至少达到range级别,最好能达到ref。 举例： const：where id = 1 id是写死的常量id只有1条，性能好。 eq_ref：where t1.id = t2.id t2.id只有1条记录，t2表只有1条记录,t2是全表扫描。 ref: where col1 = ‘ac’ ac是常量,但是col1是非唯一性索引。 rang：where id between 30 and 60,。 index: select id from t1 all: where条件字段没建立索引,或者索引失效。 (2-3-5)：possible_keys：显示可能应用在这张表的索引。 (2-3-6)：key：实际使用到的索引。如果为NULL，则没有使用索引。 ​ 查询中若使用了**覆盖索引**，则该索引仅出现在key列表中：select 查询的字段个数、顺序和复合索引的字段的个数、顺序一一符合。 (2-3-7)：key_len：表示索引使用的字节数。在不损失性能的情况下，长度越短越好。 (2-3-8)：ref：显示索引的哪一列使用了。 (2-3-9)：rows：根据表统计信息及索引使用情况，大致估算出找到所需的几率需要读取的行数。 (2-3-10)：extra：包含不合适在其他列中显示但十分重要的额外信息。 （前三个最重要：Using filesort、Using temporary表明语句烂需要优化，Using index表明语句还不错） using where：表名使用了where过滤 using index：select操作使用了覆盖索引(covering index)。表明效率不错 using filesort：说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。 using tempory：使用了临时表保存中间结果，MySQL对查询结果排序使用了临时表。常见的order by,group by。 using join buffer：使用了连接缓存 impossible where：where子句的值总是false distinct：优化distinct操作，在找到第一匹配的元组后即停止找同样值动作。 3：常见优化 IN查询能避免则避免，如果避免不了，IN查询的数量不要超过1000。如果是连续的值，应该使用**between … and …** 。或者使用连接进行替换。 SELECT语句务必指明字段名称。 当只需要1条数据时候，使用limit 1。 如果排序字段没有用到索引，就尽量少排序。 如果限制条件其他字段没有索引，尽量少用or。 尽量使用union all代替union：union比后者再进行唯一性过滤操作。 不使用ORDER BY RAND()。 区分IN和EXISTS，not in和not exists**。** 12345select * from table1 where id in (select id from tableb) ==&gt;select * from tabla where exists (select id from tableb where tableb.id = table1.id)select col from table1 where table1.id not in (select table2.id from table2) ==&gt;select col from table1,table2 where table1.id = table2.id and table2.id is null 区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况。 EXISTS适合于外表小而内表大的情况 12345678910111213#in 子查询优化#仍然in子查询,多查询一次select * from table1 where id in(select id from table2 where 条件)select * from table2 where id in(select id from (select id from table2 where 条件) as tbt)#使用left joinSELECT * FROM basic_zdjbxx WHERE suiji IN ( SELECT zdcode FROM basic_h WHERE zdcode != "" )SELECT zd.* FROM ( SELECT DISTINCT zdcode FROM basic_h WHERE zdcode != "" ) AS h LEFT JOIN basic_zdjbxx zd ON zd.suiji = h.zdcode#使用exists(适用于外表小而内表达的情况)select * from film where film_id in ( select film_id from film.actor where actor_id = 1);select * from film where exists (select * from film_actor where actor_id = 1 and film_actor.film_id = film.film_id); 使用合理的分页方式以提高分页的效率。 分段查询：如果选择时间的范围过大，造成查询缓慢。主要是扫描条数过多。可以通过程序，分段进行查询，循环遍历，将结果合并处理。 避免在where子句对字段进行null值判断。对于null的判断会导致引擎放弃使用索引而进行全表扫描。 不建议使用%前缀模糊查询。建议走全文索引(solr,elasticsearch)。 ​ 在需要创建全文索引之前，请联系DBA确定能否创建。同时需要注意的是查询语句的写法与普通索引的区别 避免在where子句中对字段进行表达式操作。 避免隐式转换。**建议先确定where中的参数类型** 联合索引遵守最左前缀法则。例如索引含有字段id,name,school,不应该使用name;school无法使用这个索引。常用查询放前面。 必要时可以使用force index来强制查询走某个索引。 注意范围查询语句。**对于联合索引来说，如果存在范围查询，比如between,&gt;,&lt;等条件时，会造成后面的索引字段失效。** 关于JOIN优化：尽量使用inner join,避免使用left join。inner join会自动找出数据表作用驱动表。利用小表驱动大表(**减少嵌套循环次数，以减少IO总量及CPU运算次数)。合理利用索引：被驱动表的索引字段作为on限制字段。** 参与联合查询的表至少为2张表，一般都存在大小之分。如果连接方式是inner join，在没有其他过滤条件的情况下MySQL会自动选择小表作为驱动表，但是left join在驱动表的选择上遵循的是左边驱动右边的原则，即left join左边的表名为驱动表。 4：一些SQL优化建议 SQL语句不要写太复杂：一个SQL语句要尽量简单，不要嵌套太多层。 使用临时表缓存中间结果。 使用LIKE要注意是否全表扫描。==&gt;在where子句使用!=,&lt;,&gt;,引擎会放弃使用索引,进行全表扫描。 尽量避免使用or来连接条件。 123select id from t where num = 11 or num = 20 ==&gt;select id from t where num = 10 union all select id from t where num = 20select id from t where num in (10,20) ​ union使用注意事项：**所有select语句中字段数目要相同。** 尽量避免使用in和not in：当字段是连续值且数字，可以使用between … and … 可以考虑强制查询使用索引 1234567#强制使用主键select * from table force index(PRI) limit 2; #强制使用索引hollis_indexselect * from table force index(hollis_index) limit 2;select * from table force index(PRI,hollis_index) limit 2; 避免使用表达式，函数等操作作为查询条件。 尽量避免大事务操作，提高系统并发能力。 任何地方不要使用select * from t 代替具体字段。 尽可能使用varchar/nvarchar代替char/nchar 尽量使用数字型字段。 索引并不是越多越好。索引会降低insert和update效率 并不是索引对查询有效，SQL根据表中数据进行优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引。 5: SQL执行顺序 写一条SQL查询应当遵循以下顺序。 1SELECT XXX FROM XXX WHERE XXX GROUP BY XXX HAVING XXX ORDER BY XXX LIMIT XXX;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeanPostProcessor加载次序及其对Bean造成的影响]]></title>
    <url>%2F2019%2F08%2F24%2FBeanPostProcessor%E5%8A%A0%E8%BD%BD%E6%AC%A1%E5%BA%8F%E5%8F%8A%E5%85%B6%E5%AF%B9Bean%E9%80%A0%E6%88%90%E7%9A%84%E5%BD%B1%E5%93%8D%2F</url>
    <content type="text"><![CDATA[1：前言BeanPostProcessor是一个工厂钩子，允许Spring框架在新创建Bean实例时对其进行定制化修改。例如：通过检查其标注的接口或者使用代理对其进行包裹。应用上下文会从Bean定义中自动检测出BeanPostProcessor并将它们应用到随后创建的任何Bean上。 普通Bean对象的工厂允许在程序中注册post-processors，应用到随后在本工厂中创建的所有Bean上。典型的场景如： 通过标记接口等填充bean后置处理器通常会实现postProcessBeforeInitialization 而使用代理包装bean的后置处理器通常会实现则一般使用postProcessAfterInitialization BeanPostProcessor本身也是一个Bean，一般而言其实例化时机要早过普通的Bean，但是BeanPostProcessor也会依赖一些Bean，这就导致了一些Bean的实例化早于BeanPostProcessor，由此会导致一些问题。最近在处理shiro和spring cache整合时就碰到了，导致的结果就是spring cache不起作用。现将问题场景、查找历程及解决方法展现一下。 2：问题场景打算在项目中将shiro与spring cache整合，使用spring cache统一管理缓存，也包括shiro认证时的用户信息查询。项目中将service分层，outter层负责权限和session，inner层主打事务和缓存并与DAO交互，两层之间也可以较容易的扩展为RPC或微服务模式。因此在shiro的authRealm中依赖了innerUserService，并在innerUserService中配置了spring cache的标注，使用cache进行缓存。配置如下（摘录重要部分）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class ShiroConfig &#123; // 配置shiro secuirty manager @Bean(name = "securityManager") public SecurityManager securityManager(@Qualifier("authRealm") TourismAuthorizingRealm authRealm, @Qualifier("cookieRememberMeManager") CookieRememberMeManager cookieRememberMeManager) &#123; log.info("securityManager()"); DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); // 设置rememberMe管理器 securityManager.setRememberMeManager(cookieRememberMeManager); // 设置realm,解决doGetAuthorizationInfo方法没有调用问题 securityManager.setRealm(authRealm); return securityManager; &#125; /** * 配置自定义权限登录器 * * @return */ @Bean(name = "authRealm") public TourismAuthorizingRealm tourismAuthorizingRealm(@Qualifier("hashedCredentialsMatcher") HashedCredentialsMatcher matcher) &#123; log.info("tourismAuthorizingRealm bean"); TourismAuthorizingRealm myAuthorizingRealm = new TourismAuthorizingRealm(); // 设置密码凭证匹配器 myAuthorizingRealm.setCredentialsMatcher(matcher); return myAuthorizingRealm; &#125; /** * 开启shiro aop注解支持. * &lt;p&gt; * 使用代理方式;所以需要开启代码支持; * Controller才能使用@RequiresPermissions * * @param securityManager * @return */ @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor( @Qualifier("securityManager") SecurityManager securityManager) &#123; AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor = new AuthorizationAttributeSourceAdvisor(); authorizationAttributeSourceAdvisor.setSecurityManager(securityManager); return authorizationAttributeSourceAdvisor; &#125; // 配置 shiro filter factory @Bean public ShiroFilterFactoryBean shiroFilter(@Qualifier("securityManager") SecurityManager securityManager) &#123; ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); // 必须设置 SecurityManager shiroFilterFactoryBean.setSecurityManager(securityManager); return shiroFilterFactoryBean; &#125; // 配置shiro生命周期 @Bean("lifecycleBeanPostProcessor") public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() &#123; log.info("lifecycleBeanPostProcessor bean"); return new LifecycleBeanPostProcessor(); &#125;&#125; 其中TourismAuthorizingRealm是自定义的shiro authorizingRealm，用于执行认证和授权。其实现依赖userService从库中查找用户信息，示例代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class TourismAuthorizingRealm extends AuthorizingRealm &#123; @Autowired @Qualifier("userService") private UserService userService; /** * shiro的权限配置方法 **/ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; logger.info("权限配置--&gt;doGetAuthorizationInfo"); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); logger.info("-----------------------------&gt;" + principals.getPrimaryPrincipal()); User user = (User) principals.getPrimaryPrincipal(); logger.info("doGetAuthorizationInfo() user: &#123;&#125;", user); List&lt;Role&gt; roles = userService.getRoles(user.getUserId()); for (Role role : roles) &#123; authorizationInfo.addRole(role.getRoleName()); // 如果有权限，应该增加所有角色对应的权限 // authorizationInfo.addStringPermission() &#125; logger.info("用户: &#123;&#125;,具有的角色: &#123;&#125;", user.getUserName(), authorizationInfo.getRoles()); logger.info("用户: &#123;&#125;,具有的权限: &#123;&#125;", user.getUserName(), authorizationInfo.getStringPermissions()); return authorizationInfo; &#125; /** * shiro的身份验证方法 **/ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; logger.info("正在验证身份..."); SimpleAuthenticationInfo info; //将token转换成UsernamePasswordToken UsernamePasswordToken upToken = (UsernamePasswordToken) token; //从转换后的token中获取用户名 String username = upToken.getUsername(); //查询数据库，得到用户 User user = userService.getOne(new QueryWrapper&lt;User&gt;().lambda().eq(User::getUserName, username)); if (user == null) &#123; logger.info("没有用户: &#123;&#125;", username); return null; &#125; //得到加密密码的盐值 ByteSource salt = ByteSource.Util.bytes(user.getUserSalt()); logger.info("加密密码的盐: &#123;&#125;", salt); //得到盐值加密后的密码: 只用于方便数据库测试,后期不会用到。 Object md = new SimpleHash(PasswordUtils.ALGORITHM_NAME, upToken.getPassword(), salt, PasswordUtils.HASH_ITERATIONS); logger.info("盐值加密后的密码: &#123;&#125;", md); //TODO: 用户名;用户密码;加密盐;realm name info = new SimpleAuthenticationInfo(user, user.getUserPassword(), salt, getName()); return info; &#125;&#125; 而在UserService中配置了spring cache标注,代码如下： 1234567891011121314@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserMapper userMapper; @Override @Cacheable(value = "user-cache", key = "#username") public User findByUsername(String username) &#123; User user = userMapper.findByUsername(username); logger.info("Real execute find from database, username:&#123;&#125;", username); return user; &#125;&#125; 并在配置文件上标注了@EnableCaching(mode=AdviceMode.PROXY)以启动spring cache。这里不过多解释具体shiro和spring cache的使用，有兴趣的同学请自行搜索相关资料。 按道理这样的配置在认证的时候可以直接使用userService中配置的spring cache缓存。但是，在具体的场景时，当authRealm依赖了userService以后,spring cache失效了。。而authRealm不依赖userService的时候，cache却正常运行。 3：问题查找3-1：Spring cache失效的表象原因首先,spring cache的实现是基于Spring AOP和拦截器的方式拦截定义的特定缓存注解，然后执行特定逻辑。因此其实现依赖于动态代理机制auto-proxy，而经过初步调试发现，当被authRealm依赖以后，userService就不会被代理了，因此无从进入AOP的pointcut，也就是说AOP切面失效了！ 3-2：Spring cache集成机制分析深层次原因 为何没有被代理呢，我们先来确认一下正常情况下什么时候进行代理封装，这时关于BeanPostProcessor的定义浮现脑海，据文档记载BeanPostProcessor允许在Bean实例化的前后对其做一些猥琐的事情，比如代理。我们在BeanPostProcessor的实现类有AbstractAutoProxyCreator,InfrastructureAdvisorAutoProxyCreator 这一脉。而反观@EnableCaching标注在启动的时候会导入 CachingConfigurationSelector，其selectImports方法会返回AutoProxyRegistrar和ProxyCachingConfiguration的全类名（我们定义了mode=AdviceMode.PROXY），也就是加载这两个类。第一个的作用就是注册InfrastructureAdvisorAutoProxyCreator到BeanDefinitionRegistry中。第二个的作用就是注册了BeanFactoryCacheOperationSourceAdvisor和CacheInterceptor。 因此，当正常情况下，一个添加了spring cache相关标注的bean会在创建后被InfrastructureAdvisorAutoProxyCreator基于advisor进行代理增强，代理后便可在拦截器CacheInterceptor中对其方法进行拦截，然后执行cache相关逻辑。 所以通过以上的分析，userSerivcce并没有经过Spring AOP代理增强。经测试发现，当被authRealm依赖的情况下在userSevice的Bean实例化时，用于处理该Bean的PostBeanProcessor明显比没被authRealm依赖时少，并且不含有InfrastructureAdvisorAutoProxyCreator。而且控制台会多打印出来一行信息： 123...................Bean 'UserServiceImpl' of type [shiro.web.inner.service.impl.UserServiceImpl] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)................... 据此可以推断，可能由于UserService实例化时机过早，导致后面那些BeanPostProcessor还未来得及实例化和注册。 4：BeanPostProcessor启动阶段对其依赖Bean造成影响首先确认了authRealm也是受害者，因为shiroFilter-&gt;SecurityManager-&gt;authRealm的依赖关系导致其不得不提前实例化。表面上的罪魁祸首是shiroFilter，但是到底是谁导致的shiroFilter预料之外的提前启动呢。shiroFilter与InfrastructureAdvisorAutoProxyCreator的具体启动时机到底是什么时候呢。经过调试后发现，了解到BeanPostProcessor的启动时机。在AbstractBeanFactory中维护了BeanPostProcessor的列表： 1private final List&lt;BeanPostProcessor&gt; beanPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); 并实现了ConfigurableBeanFactory定义的方法： 1void addBeanPostProcessor(BeanPostProcessor beanPostProcessor); 因此首先监控AbstractBeanFactory.addBeanPostProcessor()，看看启动过程中谁调用了该方法来注册BeanPostProcessor。发现实例化及注册PostBeanFactory的阶段分为四个： 第一个阶段是在启动时由AbstractApplicationContext.refresh()，其中的prepareBeanFactory方法中注册了ApplicationContextAwareProcessor、ApplicationListenerDetector： 123456protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; ... // Register early post-processor for detecting inner beans as ApplicationListeners. beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); ...&#125; 然后是ServletWebServerApplicationContext中postProcessBeanFactory注册WebApplicationContextServletContextAwareProcessor： 1234567891011/** * Register ServletContextAwareProcessor. * @see ServletContextAwareProcessor */@Overrideprotected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; beanFactory.addBeanPostProcessor( new WebApplicationContextServletContextAwareProcessor(this)); beanFactory.ignoreDependencyInterface(ServletContextAware.class); registerWebApplicationScopes();&#125; 然后在AbstractApplicationContext#refresh#invokeBeanFactoryPostProcessors方法调用： 1234567891011/** * Instantiate and invoke all registered BeanFactoryPostProcessor beans, * respecting explicit order if given. * &lt;p&gt;Must be called before singleton instantiation. */protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; // 其中PostProcessorRegistrationDelegate是处理BeanPostProcessor的代理类 PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); ... &#125;&#125; 然后是处理@Configuration注解的ConfigurationClassPostProcessor,实现BeanFactoryPostProcessorr 1beanFactory.addBeanPostProcessor(new ImportAwareBeanPostProcessor(beanFactory)); 最后在AbstractApplicationContext#refresh#registerBeanPostProcessors方法调用： 12345678/** * Instantiate and register all BeanPostProcessor beans, * respecting explicit order if given. * &lt;p&gt;Must be called before any instantiation of application beans. */protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);&#125; 在PostProcessorRegistrationDelegate.registerBeanPostProcessors，首选注册了BeanPostProcessorChecker： 1beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); 其中BeanPostProcessorChecker类在Bean创建完，它会在Bean创建完后检查可在当前Bean上起作用的BeanPostProcessor个数与总的BeanPostProcessor个数，如果起作用的个数少于总数，则报出上面那句info信息。 在PostProcessorRegistrationDelegate.registerBeanPostProcessors分为四个阶段依次实例化并注册实现了PriorityOrdered的BeanPostProcessor、实现了Ordered的BeanPostProcessor、没实现Ordered的BeanPostProcessor，内部的BeanPostProcessors，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; // 从bean工厂获取postProcessorNames String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. ... beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); ... // First, register the BeanPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : orderedPostProcessorNames) &#123; // BeanPostProcessor早于一般bean实例化 BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // Re-register post-processor for detecting inner beans as ApplicationListeners, // moving it to the end of the processor chain (for picking up proxies etc). beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125; 需要注意的是，除了第一个阶段，其他阶段同一个阶段的BeanPostProcessor是在全部实例化完成以后才会统一注册到beanFactory的，因此，同一个阶段的BeanPostProcessor及其依赖的Bean在实例化的时候是无法享受到相同阶段先实例化的BeanPostProcessor的“服务”的，因为它们还没有注册。 从上面调试与源代码分析，BeanPostProcessor的实例化与注册分为四个阶段，第一阶段applicationContext内置阶段、第二阶段priorityOrdered阶段、第三阶段Ordered阶段、第四阶段nonOrdered阶段。而BeanPostProcessor同时也是Bean，其注册之前一定先实例化。而且是分批实例化和注册，也就是属于同一批的BeanPostProcesser全部实例化完成后，再全部注册，不存在先实例化先注册的问题。而在实例化的时候其依赖的Bean同样要先实例化。因此导致一个结果就是，被PriorityOrdered BeanPostProcessor所依赖的Bean其初始化时无法享受到PriorityOrdered、Ordered、和nonOrdered BeanPostProcessor的服务。而被Ordered BeanPostProcessor所依赖的Bean无法享受Ordered、和nonOrdered的BeanPostProcessor的服务。最后被nonOrdered BeanPostProcessor所依赖的Bean无法享受到nonOrdered BeanPostProcessor的服务。 由于InfrastructureAdvisorAutoProxyCreator的启动阶段是Ordered，因此我们需要确保没有任何priorityOrdered和Ordered的BeanPostProcessor直接或间接的依赖到shiroFilter，也就是依赖到我们的userService。 同时在PriorityOrdered接口的注解中也提到了该情况： 注意：{@code PriorityOrdered}后处理器bean在特殊阶段初始化，优于其他后处理器bean。这种巧妙的*会影响它们的自动装配行为：它们只会针对 bean自动装配，这些bean不需要急切初始化类型匹配。 4-1： BeanPostProcessor在进行依赖的Bean注入时，根据Bean名称进行类型检查时导致的“误伤”问题貌似已查明，修改Configuration中所有PriorityOrdered和Ordered类型的PostBeanProcessor的Bean配置，使其不再依赖shiroFilter。再次启动，却发现仍然提前启动了shiroFilter-&gt;SecurityManager-&gt;authRealm-&gt;userService。 继续进行调试，查找shiroFilter具体的启动时机。发现在一个叫做dataSourceInitializerPostProcessor的BeanPostProcessor实例化的时候，在根据类型获得其依赖的参数时，对shiroFilter执行了初始化。导致后续SecurityManager-&gt;authRealm-&gt;userService统统提前初始化。但是在dataSourceInitializerPostProcessor之前的BeanPostProcessor却没有。经调试它们是否会导致shiroFilter初始化的区别在调用AbstractBeanFactory.isTypeMatch方法时出现： 1234567891011121314public boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException&#123; ..................... // Check bean class whether we're dealing with a FactoryBean. if (FactoryBean.class.isAssignableFrom(beanType)) &#123; //判断名称对应的Bean是否是一个FactoryBean,若是FactoryBean才执行本句 if (!BeanFactoryUtils.isFactoryDereference(name)) &#123; // If it's a FactoryBean, we want to look at what it creates, not the factory class. beanType = getTypeForFactoryBean(beanName, mbd); if (beanType == null) &#123; return false; &#125; &#125; &#125; .....................&#125; 然后进入AbstractAutowireCapableBeanFactory.getTypeForFactoryBean方法： 123456789101112@Overrideprotected Class&lt;?&gt; getTypeForFactoryBean(String beanName, RootBeanDefinition mbd) &#123; ... // If not resolvable above and the referenced factory bean doesn't exist yet, // exit here - we don't want to force the creation of another bean just to // obtain a FactoryBean's object type... if (!isBeanEligibleForMetadataCaching(factoryBeanName)) &#123; //判断该bean对应的factoryBeanName是否已经初始化了,如果没有,就返回.如果有,则继续 return null; &#125; &#125; ...&#125; 注解说的很明确，如果名字对应的factoryBean所在的factoryBean工厂尚未解析并实例化，那就直接退出，不会强制创建该facotryBean工厂，也就是Configuration对应的Bean。再次调试，果然发现，在先前的BeanPostProcessor和DataSourceInitializerPostProcessor之间，存在一个lifecycleBeanPostProcessor，而LifecycleBeanPostProcessor是在我们的Configuration中显示定义的，因此，当lifecycleBeanPostProcessor启动时会导致Configuration实例化。 最终隐藏大BOSS查明，解决方案就简单了，将lifecycleBeanPostProcessor移出到一个单独的Configuration就好了。 5：总结5-1：BeanPostProcessor启动顺序，以及其对于依赖的Bean的影响BeanPostProcessor的启动时机。分为四个阶段，第一阶段ApplicationContext内置阶段、第二阶段priorityOrdered阶段、第三阶段Ordered阶段、第四阶段nonOrdered阶段。 而BeanPostProcessor同时也是Bean，其注册之前一定先实例化。而且是分批实例化和注册，也就是属于同一批的BeanPostProcesser全部实例化完成后，再全部注册，不存在先实例化先注册的问题。而在实例化的时候其依赖的Bean同样要先实例化。 因此导致一个结果就是，被PriorityOrderedBeanPostProcessor所依赖的Bean其初始化以后无法享受到PriorityOrdered、Ordered、和nonOrdered的BeanPostProcessor的服务。而被OrderedBeanPostProcessor所依赖的Bean无法享受Ordered、和nonOrdered的BeanPostProcessor的服务。最后被nonOrderedBeanPostProcessor所依赖的Bean无法享受到nonOrderedBeanPostProcessor的服务。 5-2：注意避免BeanPostProcessor启动时的“误伤”陷阱BeanPostProcessor实例化时，自动依赖注入根据类型获得需要注入的Bean时，会将某些符合条件的Bean（FactoryBean并且其FactoryBeanFactory已经实例化的）先实例化，如果此FacotryBean又依赖其他普通Bean，会导致该Bean提前启动，造成误伤（无法享受部分BeanPostProcessor的后处理，例如典型的auto-proxy）。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>BeanPostProcessor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jackson常用注解学习]]></title>
    <url>%2F2019%2F08%2F22%2FJackson%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Jackson常用注解学习1:返回json去掉空值()(@JsonSerialize)1@JsonSerialize(include = Inclusion.NON_NULL) 2:去掉指定属性(@JsonIgnore )1@JsonIgnore 3:格式化(@JsonFormat) 时间格式化 1@JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss") 注意时间地域差异，根据地区差异进行调整，timezone参数调整。默认中国时间使用东8区，即配置timezone=&quot;GMT+8&quot;。 1@JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss",timezone="GMT+8") 4:初级(1)：属性重命名(@JsonProperty)12@JsonProperty("userName") public String name; 返回如下： 123&#123; "userName" : "Bob" &#125; 不加注解返回如下： 123&#123; "name" : "Bob" &#125; (2)：忽略属性@JsonIgnore：POJO忽略指定属性12345public class User &#123; public int value; @JsonIgnore public int internalValue; &#125; 输出如下： 123&#123; "value" : 42 &#125; @JsonIgnoreProperties：实体类使用注解，用来序列化时候忽略指定的一系列属性，或者反序列化时候忽略未知属性(没有getter/setter属性)。 序列化的时候，@JsonIgnoreProperties({&quot;prop1&quot;, &quot;prop2&quot;})，忽略列表中的属性。 反序列化的时候，@JsonIgnoreProperties(ignoreUnknown=true)，忽略没有get/set的属性。 1234@JsonIgnoreProperties(&#123; "extra", "uselessValue" &#125;) public class Value &#123; public int value; &#125; 输出如下： 12345&#123; "value" : 42, "extra" : "fluffy", "uselessValue" : -13&#125; 忽略掉从JSON(由于在应用中没有完全匹配的POJO)中获取的所有“多余”属性。 1234@JsonIgnoreProperties(ignoreUnknown=true) public class PojoWithAny &#123; public int value; &#125; (3)：序列化(输出)(@JsonSerialize)虽然运行时的类型（type）可能是’AdvancedType’（高级类型）, 但是我们确实想序列化 成为’BasicType’（基础类型）; 有两种处理方式: 1234 @JsonSerialize(as=BasicType.class) //@JsonSerialize(typing=Typing.STATIC) public BasicType another; &#125; (4)：反序列化(输入)(@JsonDeserialize)1234public class ValueContainer &#123; // 虽然代码中使用的类型（type）是'Value', 但我们希望读取到的JSON之后得到的对象 的类型是'ValueImpl' @JsonDeserialize(as=ValueImpl.class) public Value value; (5)：原始值输出(@JsonRawValue)作用在方法或者字段上，声明按原始值输出，Jackson不做任何处理。 使用场景：用在String类型字段，比如前端用的是JSON，数据库存储的是String类型。 (6)：只序列化字段的值或者方法返回值(@JsonValue)一个类最多使用一个@JsonValue注解。 (7)：@JsonInclude实体类/属性使用注解，用来忽略NULL属性，空的属性或者NULL的类。 12345//场景2：(有些值为NULL不想传过去，往往还得在SQL或者代码做循环判断，损耗性能)，//为null的字段将不显示。@JsonInclude(Include.NON_NULL)//场景1：(实体类中某些属性只在代码中有用，序列化不想带出来，浪费流量)，这里是不让person属性序列化@JsonIgnoreProperties(value=&#123;"person"&#125;) 5：中级(1)：处理多态类型序列化和反序列化(JsonTypeInfo)JsonTypeInfo注解使用，详细查考官方文档。 简单使用示例：按照类示例： 12345678910111213141516//将Java类的名称（“com.myempl.ImplClass”）存储到JSON的一个名称为“class”的属性中 @JsonTypeInfo(use=Id.CLASS, include=As.PROPERTY,property=”class”) public abstract class BaseClass &#123; &#125; public class Impl1 extends BaseClass &#123; public int x; &#125; public class Impl2 extends BaseClass &#123; public String name; &#125; public class PojoWithTypedObjects &#123; public List&lt;BaseClass&gt; items; &#125; json如下： 1234567&#123; “items” : [ &#123;“class”:”Impl2”, “name”: “Bob”&#125;, &#123;“class”:”Impl1”, :”x” : 13&#125; ]&#125; 按照类型示例： 123456789101112131415161718192021222324252627282930313233343536373839public class Zoo &#123; public Animal animal; @JsonTypeInfo( use = JsonTypeInfo.Id.NAME, include = As.PROPERTY, property = "type") @JsonSubTypes(&#123; @JsonSubTypes.Type(value = Dog.class, name = "dog"), @JsonSubTypes.Type(value = Cat.class, name = "cat") &#125;) public static class Animal &#123; public String name; &#125; @JsonTypeName("dog") public static class Dog extends Animal &#123; public double barkVolume; &#125; @JsonTypeName("cat") public static class Cat extends Animal &#123; boolean likesCream; public int lives; &#125;&#125;@Testpublic void whenSerializingPolymorphic_thenCorrect() throws JsonProcessingException &#123; Zoo.Dog dog = new Zoo.Dog("lacy"); Zoo zoo = new Zoo(dog); String result = new ObjectMapper() .writeValueAsString(zoo); assertThat(result, containsString("type")); assertThat(result, containsString("dog"));&#125; 1234567&#123; "animal": &#123; "type": "dog", "name": "lacy", "barkVolume": 0 &#125;&#125; (2)：重新设置属性自动发现(JsonAutoDetect)属性/实体能否被序列化/反序列化 Jackson默认属性发现规则： 所有被public修饰的字段（成员变量） 所有被public修饰的getter（即形如“getXxx()”的方法） 所有被public修饰的setter（即形如“setXxx(value)”的方法），不管可见或不可见 发现机制属性 fieldVisibility=JsonAutoDetect.Visibility.ANY: 指自动发现所有修饰符的属性 fieldVisibility=JsonAutoDetect.Visibility.NONE：禁止发现所有属性，但是getter/setter方法无效 fieldVisibility=JsonAutoDetect.Visibility.NON_PRIVATE: 指自动发现除被private修饰以外的属性 如果你想自动发现所有字段： 1234@JsonAutoDetect(fieldVisibility=JsonAutoDetect.Visibility.ANY) public class POJOWithFields &#123; private int value; &#125; 禁用对所有字段的自动发现 12345@JsonAutoDetect(fieldVisibility=JsonAutoDetect.Visibility.NONE) public class POJOWithNoFields &#123; //不会被序列化，除非再有一个可以访问的“getValue”方法 public int value; &#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>JSON</tag>
        <tag>Jackson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AopContext 在多线程运用]]></title>
    <url>%2F2019%2F08%2F19%2FSpring-AopContext-%E5%9C%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Spring AopContext 在多线程运用前言众所周知,Spring AOP无法对同一个类中自身方法相互调用进行拦截。由于Spring AOP是针对方法级别的和属性级别(引介增强)。所以，无法对方法的嵌套调用实现AOP的增强。你可以通过调用AopContext.currentProxy()来获取当前AOP增强的对象，然后进行强转成功目标对象类型，内部通过ThreadLocal静态final对象来维护当前线程的代理对象。 12345678910111213141516171819202122232425262728293031@Service@Slf4jpublic class PersonService &#123; private final ExecutorService threadPool = Executors.newFixedThreadPool(2); public void nestAop() &#123; hello2(); System.out.println("nestAop"); &#125; protected void hello2() &#123; System.out.println("Hello2"); &#125;&#125;@Aspect@Component@Slf4jpublic class LogAspect &#123; @Pointcut("execution(* com.ley.spring.learn.nest.aop.*.*(..))") protected void poincut() &#123; &#125; @Before("poincut()") public void before(JoinPoint joinPoint) &#123; log.info("enter method: &#123;&#125;", joinPoint.getSignature().getName()); &#125;&#125; 解决方案使用AopContext.currentProxy())来操作。详细实现代码可以查看源码CglibAopProxy和JdkDynamicAopProxy。Spring AOP原理两个重要实现类。示例代码如下： 12345public void nestAopHandle() &#123; PersonService personService = (PersonService) AopContext.currentProxy(); personService.hello2(); System.out.println("nest aop handle");&#125; 由于AopContext实现是使用ThreadLocal来保存代理对象，那么如果想在多线程中使用该怎么办呢？Spring AOP中的AopContext类又是包级私有的静态方法,而且还是抽象类，你无法通过反射来进行操作。那么转换一种思想，通过继承的方式，先继承AopContext类，提供默认构造函数。那么此时，你可以通过反射来进行操作了。实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 通过继承public class MyAopContext extends AopContext &#123; &#125;@Service@Slf4jpublic class PersonService &#123; private final ExecutorService threadPool = Executors.newFixedThreadPool(2); public void nestAop() &#123; hello2(); System.out.println("nestAop"); &#125; public void aopInThread() &#123; PersonService personService = (PersonService) AopContext.currentProxy(); Object currentProxy = AopContext.currentProxy(); threadPool.submit(() -&gt; &#123; // 反射调用方法 Method method = ReflectionUtils.findMethod(MyAopContext.class, "setCurrentProxy", Object.class); ReflectionUtils.makeAccessible(method); try &#123; // 注意: 这儿你需要捕获异常,JUC多线程中执行失败不显示异常信息 // 需要手动捕获 ReflectionUtils.invokeMethod(method, BeanUtils.instantiateClass(MyAopContext.class), currentProxy); &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); &#125; personService.hello3(); &#125;); System.out.println("nest in multi thread"); &#125; // 该方法是在多线程环境,需要手动捕获异常 protected void hello3() &#123; try &#123; PersonService personService = (PersonService) AopContext.currentProxy(); personService.hello4(); System.out.println("hello3"); &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); &#125; &#125; public void hello4() &#123; System.out.println("hello4"); &#125;&#125; 如果你想要捕获多线程的异常，可以使用带有监听的Future-&gt;ListenableFuture。其中Guava和Spring都提供了带有监听机制的Future，可以方便用来捕获多线程中的异常，方便排除。如下代码是使用Guava提供的ListenableFuture进行实现： 1234567891011121314151617181920212223242526272829public void aopInThread() &#123; PersonService personService = (PersonService) AopContext.currentProxy(); Object currentProxy = AopContext.currentProxy(); // 使用Guava提供ListenableFuture ListeningExecutorService service = MoreExecutors.listeningDecorator(threadPool); ListenableFuture&lt;?&gt; listenableFuture = service.submit(() -&gt; &#123; Method method = ReflectionUtils.findMethod(MyAopContext.class, "setCurrentProxy", Object.class); ReflectionUtils.makeAccessible(method); try &#123; ReflectionUtils.invokeMethod(method, BeanUtils.instantiateClass(MyAopContext.class), currentProxy); &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); &#125; personService.hello3(); &#125;); Futures.addCallback(listenableFuture, new FutureCallback&lt;Object&gt;() &#123; @Override public void onSuccess(@Nullable Object o) &#123; log.info("执行成功"); &#125; @Override public void onFailure(Throwable throwable) &#123; log.error(throwable.getMessage(), throwable); &#125; &#125;, threadPool); System.out.println("nest in multi thread");&#125; 详细代码请看Github：嵌套方法AOP解决以及嵌套方法AOP在多线程运用]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Stream收集数据]]></title>
    <url>%2F2019%2F08%2F16%2F%E4%BD%BF%E7%94%A8Stream%E6%94%B6%E9%9B%86%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[使用流收集数据 终端操作collect方法用于收集流中的元素，并放到不同类型的结果中，比如List、Set或者Map。其实collect方法可以接受各种Collectors接口的静态方法作为参数来实现更为强大的规约操作，比如查找最大值最小值，汇总，分区和分组等等。 准备工作为了演示Collectors接口中的静态方法使用，这里创建一个Dish类（菜谱类）： 12345678910111213141516171819202122232425public class Dish &#123; public enum Type &#123;MEAT, FISH, OTHER&#125; /** 食物名称 */ private final String name; /** 是否是素食 */ private final boolean vegetarian; /** 卡路里 */ private final int calories; /** 类型：肉，海鲜，其他 */ private final Type type; public Dish(String name, boolean vegetarian, int calories, Type type) &#123; this.name = name; this.vegetarian = vegetarian; this.calories = calories; this.type = type; &#125; @Override public String toString() &#123; return this.getName(); &#125; // get,set略&#125; 然后创建一个List，包含各种食材： 12345678910List&lt;Dish&gt; list = Arrays.asList( new Dish("pork", false, 800, Dish.Type.MEAT), new Dish("beef", false, 700, Dish.Type.MEAT), new Dish("chicken", false, 400, Dish.Type.MEAT), new Dish("french fries", true, 530, Dish.Type.OTHER), new Dish("rice", true, 350, Dish.Type.OTHER), new Dish("season fruit", true, 120, Dish.Type.OTHER), new Dish("pizza", true, 550, Dish.Type.OTHER), new Dish("prawns", false, 300, Dish.Type.FISH), new Dish("salmon", false, 450, Dish.Type.FISH) ); 在测试类中导入所有Collectors接口的静态方法： 1import static java.util.stream.Collectors.*; 规约与汇总最大最小值Collectors.maxBy和Collectors.minBy用来计算流中的最大或最小值，比如按卡路里的大小来筛选出卡路里最高的食材： 1list.stream().collect(maxBy(Comparator.comparingInt(Dish::getCalories))) .ifPresent(System.out::println); 输出pork。 汇总Collectors.summingInt可以用于求和，参数类型为int类型。相应的基本类型对应的方法还有Collectors.summingLong和Collectors.summingDouble。比如求所有食材的卡路里： 12]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda表达式篇二]]></title>
    <url>%2F2019%2F08%2F16%2FLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%AF%87%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[Lambda表达式篇二 Java 8已经给我们提供了一套能够描述常见函数描述符的函数式接口。比如Predicate&lt;T&gt;、Consumer&lt;T&gt;、Function&lt;T,R&gt;、Supplier&lt;T&gt;等，这些函数式接口位于java.util.function包。这一节主要记录这些函数式接口的应用。 Java8中的函数式接口下表列出了Java8中常见的函数式接口： 函数式接口 函数描述符 原始类型特化 Predicate(过滤) T-&gt;boolean IntPredicate,LongPredicate, DoublePredicate Consumer(消费者) T-&gt;void IntConsumer,LongConsumer, DoubleConsumer Function&lt;T,R&gt; T-&gt;R IntFunction, IntToDoubleFunction, IntToLongFunction, LongFunction, LongToDoubleFunction, LongToIntFunction, DoubleFunction, ToIntFunction, ToDoubleFunction, ToLongFunction Supplier(生产者) ()-&gt;T BooleanSupplier,IntSupplier, LongSupplier, DoubleSupplier UnaryOperator T-&gt;T IntUnaryOperator, LongUnaryOperator, DoubleUnaryOperator BinaryOperator (T,T)-&gt;T IntBinaryOperator, LongBinaryOperator, DoubleBinaryOperator BiPredicate&lt;L,R&gt; (L,R)-&gt;boolean BiConsumer&lt;T,U&gt; (T,U)-&gt;void ObjIntConsumer, ObjLongConsumer, ObjDoubleConsumer BiFunction&lt;T,U,R&gt; (T,U)-&gt;R ToIntBiFunction&lt;T,U&gt;, ToLongBiFunction&lt;T,U&gt;, ToDoubleBiFunction&lt;T,U&gt; Predicatepredicate:断言。从接口的名称就可以推断出这个函数式接口的主要作用就是用于判断作用，Predicate源码如下所示： 123456789101112131415161718192021@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t); default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); &#125; default Predicate&lt;T&gt; negate() &#123; return (t) -&gt; !test(t); &#125; default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); &#125; static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) &#123; return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); &#125;&#125; 可看到java.util.function.Predicate&lt;T&gt;接口定义了一个名叫test的抽象方法，它接受泛型T对象，并返回一个boolean，函数描述符为(T) -&gt; boolean举几个例子： 1234567// 偶数判断Predicate&lt;Integer&gt; isEven = (in) -&gt; in % 2 == 0;isEven.test(17); // false// 判断字符串的长度是否为0Predicate&lt;String&gt; isEmptyString = String::isEmpty;isEmptyString.test(""); // true 除了抽象方法外，java.util.function.Predicate&lt;T&gt;接口还定义了三个默认方法：and，negate和or，对应“与”，“非”和“或”操作，这样我们便可以复合Lambda表达式了，比如： 12345678// 判断是偶数，并且大于30Predicate&lt;Integer&gt; isEven = (in) -&gt; in % 2 == 0;isEven.and((in) -&gt; in &gt; 30).test(40); // true// 奇数判断Predicate&lt;Integer&gt; isEven = (in) -&gt; in % 2 == 0;Predicate&lt;Integer&gt; isOdd = isEven.negate();isOdd.test(17); // true Consumer消费者。该函数式接口用于消费一个对象，即接收一个对象，对其执行某些操作，然后没有返回值。Consumer源码如下所示： 12345678@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; &#123; accept(t); after.accept(t); &#125;; &#125;&#125; 可看到java.util.function.Consumer&lt;T&gt;定义了一个名叫accept的抽象方法，它接受泛型T的对象，没有返回(void)，函数描述符为(T) -&gt; void。其还提供了一个默认方法andThen。举个例子： 1234Consumer&lt;Apple&gt; printAppleColor = (a)-&gt; System.out.println(a.getColor());printAppleColor.accept(new Apple("red",17)); // redprintAppleColor.andThen((a) -&gt; System.out.println(a.getWeight())).accept(new Apple("red", 17)); // red 17.0 Supplier供应商;供应者;供给者。其源码如下： 1234@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get();&#125; 可看到java.util.function.Supplier&lt;T&gt;定义了一个名叫get的抽象方法，它不接收参数，返回泛型T的对象，函数描述符为() -&gt; T。举个例子： 12Supplier&lt;Person&gt; personSupplier = Person::new;personSupplier.get(); // new Person FunctionsFunctions源码如下： 123456789101112131415161718@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123; Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); &#125; default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); &#125; static &lt;T&gt; Function&lt;T, T&gt; identity() &#123; return t -&gt; t; &#125;&#125; java.util.function.Function&lt;T, R&gt;接口定义了一个叫作apply的方法，它接受一个泛型T的对象，并返回一个泛型R的对象，函数描述符为(T) -&gt; R。举个例子： 1Function&lt;Apple, Double&gt; getAppleWeight = (a) -&gt; &#123; return a.getWeight();&#125;;getAppleWeight.apply(new Apple(17)); // 17.0 Functions接口还提供了两个抽象方法compose和andThen，从源码可以看出两者的根本区别。举个compose例子： 1234Function&lt;Apple, Double&gt; getAppleWeight = (a) -&gt; &#123; return a.getWeight();&#125;;getAppleWeight.apply(new Apple(17)); // 17.0 过程为：f(g(2))，也就是1+(2*2)。 举个andThen的例子： 123Function&lt;Integer, Integer&gt; f = (x) -&gt; x + 1;Function&lt;Integer, Integer&gt; g = (x) -&gt; x * 2;f.compose(g).apply(2); // 5 过程为：g(f(2))，也就是(2+1)*2。 原始类型特化在学习Function接口的时候，我们定义了f函数： 1Function&lt;Integer, Integer&gt; f = (x) -&gt; x + 1; x的类型为Integer类型，1为int类型，返回值为Integer类型，整个过程实际上为Integer.valueOf(x.intValue() + 1)。虽然编译器可以自动帮我们完成拆装箱，但这会造成不必要的性能消耗。考虑到了这一点，Java8为我们提供了int类型的Function接口：IntFunction: 1234@FunctionalInterfacepublic interface IntFunction&lt;R&gt; &#123; R apply(int value);&#125; 所以f最好重构为： 1IntFunction&lt;Integer&gt; f = (x) -&gt; x + 1; 剩余的原始类型特化函数式接口可参考上面的表格。 Java8中增强的Comparator在Java8之前，Comparator接口用于实现简单的比较排序算法。比如有如下List： 123456List&lt;Double&gt; list = new ArrayList&lt;&gt;();list.add(12.3);list.add(100.2);list.add(3.14);list.add(27.7);list.add(-9.8); 使用Comparator接口对其从小到大排序： 123456Collections.sort(list, new Comparator&lt;Double&gt;() &#123; @Override public int compare(Double o1, Double o2) &#123; return o1.compareTo(o2); &#125;&#125;); Comparator接口也是一个函数式接口，函数描述符为(T,T) -&gt; int，Java8中可以使用Lambda改造上面的排序方法： 1Collections.sort(list, (o1, o2) -&gt; o1.compareTo(o2)); Java8对List提供了sort方法，可以替代Collections.sort，所以上面的代码可以简化为： 1list.sort((o1, o2) -&gt; o1.compareTo(o2)); 使用方法的引用来进一步简化： 1list.sort(Double::compareTo); Java8对Comparator进行了增强，加入了一些实用的默认方法，比如对排序结果反转： 12Comparator&lt;Double&gt; comparator = Double::compareTo;list.sort(comparator.reversed()); 更多方法可以参考Comparator接口的JavaDoc。 查看Comparator的时候发现其虽然是函数式接口，但是却包含了compare和equals这两个抽象方法，顿时有点懵逼，函数式接口不是只能有一个抽象方法么？查找资料后发现：函数式接口中可以额外定义多个抽象方法，但这些抽象方法签名必须和Object的public方法一样，接口最终有确定的类实现，而类的最终父类是Object。因此函数式接口可以定义Object的public方法。 转载:https://mrbird.cc/java8lambda2.html]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sql Or NoSql 选型方案及比较]]></title>
    <url>%2F2019%2F08%2F16%2FSql-Or-NoSql-%E9%80%89%E5%9E%8B%E6%96%B9%E6%A1%88%E5%8F%8A%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[Sql Or NoSql前言你是否在为系统的数据库来一波大流量就几乎打满CPU，日常CPU居高不下烦恼？你是否在各种NoSql间纠结不定，到底该选用那种最好？今天的你就是昨天的我，这也是写这篇文章的初衷。 这篇文章是我好几个月来一直想写的一篇文章，也是一直想学习的一个内容，作为互联网从业人员，我们要知道关系型数据库（MySql、Oracle）无法满足我们对存储的所有要求，因此对底层存储的选型，对每种存储引擎的理解非常重要。同时也由于过去一段时间的工作经历，对这块有了一些更多的思考，想通过自己的总结把这块写出来分享给大家。 结构化数据、非结构化数据与半结构化数据 文章的开始，聊一下结构化数据、非结构化数据与半结构化数据，因为数据特点的不同，将在技术上直接影响存储引擎的选型。 首先是结构化数据，根据定义结构化数据指的是由二维表结构来逻辑表达和实现的数据，严格遵循数据格式与长度规范，也称作为行数据，特点为：数据以行为单位，一行数据表示一个实体的信息，每一行数据的属性是相同的。例如： 因此关系型数据库完美契合结构化数据的特点，关系型数据库也是关系型数据最主要的存储与管理引擎。 非结构化数据，指的是数据结构不规则或不完整，没有任何预定义的数据模型，不方便用二维逻辑表来表现的数据，例如办公文档（Word）、文本、图片、HTML、各类报表、视频音频等。 介于结构化与非结构化数据之间的数据就是半结构化数据了，它是结构化数据的一种形式，虽然不符合二维逻辑这种数据模型结构，但是包含相关标记，用来分割语义元素以及对记录和字段进行分层。常见的半结构化数据有XML和JSON，例如： 12345&lt;person&gt; &lt;name&gt;张三&lt;/name&gt; &lt;age&gt;18&lt;/age&gt; &lt;phone&gt;12345&lt;/phone&gt;&lt;/person&gt; 这种结构也被成为自描述的结构。 以关系型数据库的方式做存储的架构演进 首先，我们看一下使用关系型数据库的方式，企业一个系统发展的几个阶段的架构演进（由于本文写的是Sql与NoSql，因此只以存储方式作为切入点，不会涉及类似MQ、ZK这些中间件内容）： 阶段一：企业刚发展的阶段，最简单，一个应用服务器配一个关系型数据库，每次读写数据库。 阶段二：无论是使用MySQL还是Oracle还是别的关系型数据库，数据库通常不会先成为性能瓶颈，通常随着企业规模的扩大，一台应用服务器扛不住上游过来的流量且一台应用服务器会产生单点故障的问题，因此加应用服务器并且在流量入口使用Nginx做一层负载均衡，保证把流量均匀打到应用服务器上。 阶段三：随着企业规模的继续扩大，此时由于读写都在同一个数据库上，数据库性能出现一定的瓶颈，此时简单地做一层读写分离，每次写主库，读备库，主备库之间通过binlog同步数据，就能很大程度上解决这个阶段的数据库性能问题 阶段四：企业发展越来越好了，业务越来越大了，做了读写分离数据库压力还是越来越大，这时候怎么办呢，一台数据库扛不住，那我们就分几台吧，做分库分表，对表做垂直拆分，对库做水平拆分。以扩数据库为例，扩出两台数据库，以一定的单号（例如交易单号），以一定的规则（例如取模），交易单号对2取模为0的丢到数据库1去，交易单号对2取模为1的丢到数据库2去，通过这样的方式将写数据库的流量均分到两台数据库上。一般分库分表会使用Shard的方式，通过一个中间件，便于连接管理、数据监控且客户端无需感知数据库ip。 关系型数据库的优点 上面的方式，看似可以解决问题（实际上确实也能解决很多问题），正常对关系型数据库做一下读写分离 + 分库分表，支撑个1W+的读写QPS还是问题不大的。但是受限于关系型数据库本身，这套架构方案依然有着明显的不足，下面对利用关系型数据库方式做存储的方案的优点先进行一下分析，后一部分再分析一下缺点，对某个技术的优缺点的充分理解是技术选型的前提。 易理解 因为行 + 列的二维表逻辑是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型更加容易被理解 操作方便 通用的SQL语言使得操作关系型数据库非常方便，支持join等复杂查询 数据一致性 支持ACID特性，可以维护数据之间的一致性，这是使用数据库非常重要的一个理由之一，例如同银行转账，张三转给李四100元钱，张三扣100元，李四加100元，而且必须同时成功或者同时失败，否则就会造成用户的资损 数据稳定 数据持久化到磁盘，没有丢失数据风险，支持海量数据存储 服务稳定 最常用的关系型数据库产品MySql、Oracle服务器性能卓越，服务稳定，通常很少出现宕机异常 关系型数据库的缺点紧接着的，我们看一下关系型数据库的缺点，也是比较明显的。 高并发下IO压力大 数据按行存储，即使只针对其中某一列进行运算，也会将整行数据从存储设备中读入内存，导致IO较高 为维护索引付出的代价大 为了提供丰富的查询能力，通常热点表都会有多个二级索引，一旦有了二级索引，数据的新增必然伴随着所有二级索引的新增，数据的更新也必然伴随着所有二级索引的更新，这不可避免地降低了关系型数据库的读写能力，且索引越多读写能力越差。有机会的话可以看一下自己公司的数据库，除了数据文件不可避免地占空间外，索引占的空间其实也并不少 为维护数据一致性付出的代价大 数据一致性是关系型数据库的核心，但是同样为了维护数据一致性的代价也是非常大的。我们都知道SQL标准为事务定义了不同的隔离级别，从低到高依次是读未提交、读已提交、可重复度、串行化，事务隔离级别越低，可能出现的并发异常越多，但是通常而言能提供的并发能力越强。那么为了保证事务一致性，数据库就需要提供并发控制与故障恢复两种技术，前者用于减少并发异常，后者可以在系统异常的时候保证事务与数据库状态不会被破坏。对于并发控制，其核心思想就是加锁，无论是乐观锁还是悲观锁，只要提供的隔离级别越高，那么读写性能必然越差 水平扩展后带来的种种问题难处理 ​ 前文提过，随着企业规模扩大，一种方式是对数据库做分库，做了分库之后，数据迁移（1个库的数据按照一定规则打到2个库中）、跨库join（订单数据里有用户数据，两条数据不在同一个库中）、分布式事务处理都是需要考虑的问题，尤其是分布式事务处理，业界当前都没有特别好的解决方案 表结构扩展不方便 由于数据库存储的是结构化数据，因此表结构schema是固定的，扩展不方便，如果需要修改表结构，需要执行DDL（data definition language）语句修改，修改期间会导致锁表，部分服务不可用 全文搜索功能弱 例如like “%中国真伟大%”，只能搜索到”2019年中国真伟大，爱祖国”，无法搜索到”中国真是太伟大了”这样的文本，即不具备分词能力，且like查询在”%中国真伟大”这样的搜索条件下，无法命中索引，将会导致查询效率大大降低。 写了这么多，我的理解核心还是前三点，它反映出的一个问题是关系型数据库在高并发下的能力是有瓶颈的，尤其是写入/更新频繁的情况下，出现瓶颈的结果就是数据库CPU高、Sql执行慢、客户端报数据库连接池不够等错误，因此例如万人秒杀这种场景，我们绝对不可能通过数据库直接去扣减库存。 可能有朋友说，数据库在高并发下的能力有瓶颈，我公司有钱，加CPU、换固态硬盘、继续买服务器加数据库做分库不就好了，问题是这是一种性价比非常低的方式，花1000万达到的效果，换其他方式可能100万就达到了，不考虑人员、服务器投入产出比的Leader就是个不合格的Leader，且关系型数据库的方式，受限于它本身的特点，可能花了钱都未必能达到想要的效果。至于什么是花100万就能达到花1000万效果的方式呢？可以继续往下看，这就是我们要说的NoSql。 结合NoSql的方式做存储的架构演进 像上文分析的，数据库作为一种关系型数据的存储引擎，存储的是关系型数据，它有优点，同时也有明显的缺点，因此通常在企业规模不断扩大的情况下，不会一味指望通过增强数据库的能力来解决数据存储问题，而是会引入其他存储，也就是我们说的NoSql。 NoSql的全称为Not Only SQL，泛指非关系型数据库，是对关系型数据库的一种补充，特别注意补充这两个字，这意味着NoSql与关系型数据库并不是对立关系，二者各有优劣，取长补短，在合适的场景下选择合适的存储引擎才是正确的做法。 比较简单的NoSql就是缓存： 针对那些读远多于写的数据，引入一层缓存，每次读从缓存中读取，缓存中读取不到，再去数据库中取，取完之后再写入到缓存，对数据做好失效机制通常就没有大问题了。通常来说，缓存是性能优化的第一选择也是见效最明显的方案。 但是，缓存通常都是KV型存储且容量有限（基于内存），无法解决所有问题，于是再进一步的优化，我们继续引入其他NoSql： 数据库、缓存与其他NoSql并行工作，充分发挥每种NoSql的特点。当然NoSql在性能方面大大优于关系挺数据库的同时，往往也伴随着一些特性的缺失，比较常见的就是事务功能的缺失。 下面看一下常用的NoSql及他们的代表产品，并对每种NoSql的优缺点和适用场景做一下分析，便于熟悉每种NoSql的特点，方便技术选型。 KV型NoSql（代表—-Redis） KV型NoSql顾名思义就是以键值对形式存储的非关系型数据库，是最简单、最容易理解也是大家最熟悉的一种NoSql，因此比较快地带过。Redis、MemCache是其中的代表，Redis又是KV型NoSql中应用最广泛的NoSql，KV型数据库以Redis为例，最大的优点我总结下来就两点： 数据基于内存，读写效率高 K/V型数据，时间复杂度为O(1)，查询速度快 因此，KV型NoSql最大的优点就是高性能，利用Redis自带的BenchMark做基准测试，TPS可达到10万的级别，性能非常强劲。同样的Redis也有所有KV型NoSql都有的比较明显的缺点： 只能根据K查V，无法根据V查K 查询方式单一，只有KV的方式，不支持条件查询，多条件查询唯一的做法就是数据冗余，但这会极大的浪费存储空间。 内存是有限的，无法支持海量数据存储 同样的，由于KV型NoSql的存储是基于内存的，会有丢失数据的风险 综上所述，KV型NoSql最合适的场景就是缓存的场景： 读远多于写 读取能力强 没有持久化的需求，可以容忍数据丢失，反正丢了再查询一把写入就是了 例如根据用户id查询用户信息，每次根据用户id去缓存中查询一把，查到数据直接返回，查不到去关系型数据库里面根据id查询一把数据写到缓存中去。 搜索型NoSql（代表—-ElasticSearch） 传统关系型数据库主要通过索引来达到快速查询的目的，但是在全文搜索的场景下，索引是无能为力的，like查询一来无法满足所有模糊匹配需求，二来使用限制太大且使用不当容易造成慢查询，搜索型NoSql的诞生正是为了解决关系型数据库全文搜索能力较弱的问题，ElasticSearch是搜索型NoSql的代表产品。 全文搜索的原理是倒排索引，我们看一下什么是倒排索引。要说倒排索引我们先看下什么是正排索引，传统的正排索引是文档–&gt;关键字的映射，例如”Tom is my friend”这句话，会将其切分为”Tom”、”is”、”my”、”friend”四个单词，在搜索的时候对文档进行扫描，符合条件的查出来。这种方式原理非常简单，但是由于其检索效率太低，基本没什么实用价值。 倒排索引则完全相反，它是关键字–&gt;文档的映射，我用张表格展示一下就比较清楚了： 意思是我现在这里有”Tom is Tom”、”Tom is my friend”、”Thank you, Betty”、”Tom is Betty’s husband”四句话，搜索引擎会根据一定的切分规则将这句话切成N个关键字，并以关键字的维度维护关键字在每个文本中的出现次数。这样下次搜索”Tom”的时候，由于Tom这个词语在”Tom is Tom”、”Tom is my friend”、”Tom is Betty’s husband”三句话中都有出现，因此这三条记录都会被检索出来，且由于”Tom is Tom”这句话中”Tom”出现了2次，因此这条记录对”Tom”这个单词的匹配度最高，最先展示。这就是搜索引擎倒排索引的基本原理，假设某个关键字在某个文档中出现，那么倒排索引中有两部分内容： 文档ID 在该文档中出现的位置情况 可以举一反三，我们搜索”Betty Tom”这两个词语也是一样，搜索引擎将”Betty Tom”切分为”Tom”、”Betty”两个单词，根据开发者指定的满足率，比如满足率=50%，那么只要记录中出现了两个单词之一的记录都会被检索出来，再按照匹配度进行展示。 搜索型NoSql以ElasticSearch为例，它的优点为： 支持分词场景、全文搜索，这是区别于关系型数据库最大特点 支持条件查询，支持聚合操作，类似关系型数据库的Group By，但是功能更加强大，适合做数据分析 数据写文件无丢失风险，在集群环境下可以方便横向扩展，可承载PB级别的数据 高可用，自动发现新的或者失败的节点，重组和重新平衡数据，确保数据是安全和可访问的。 同样，ElasticSearch也有比较明显的缺点： 性能全靠内存来顶，也是使用的时候最需要注意的点，非常吃硬件资源、吃内存，大数据量下64G + SSD基本是标配，算得上是数据库中的爱马仕了。为什么要专门提一下内存呢，因为内存这个东西是很值钱的，相同的配置多一倍内存，一个月差不多就要多花几百块钱，至于ElasticSearch内存用在什么地方，大概有如下这些： Indexing Buffer—-ElasticSearch基于Luence，Lucene的倒排索引是先在内存里生成，然后定期以Segment File的方式刷磁盘的，每个Segment File实际就是一个完整的倒排索引 Segment Memory—-倒排索引前面说过是基于关键字的，Lucene在4.0后会将所有关键字以FST这种数据结构的方式将所有关键字在启动的时候全量加载到内存，加快查询速度，官方建议至少留系统一半内存给Lucene 各类缓存—-Filter Cache、Field Cache、Indexing Cache等，用于提升查询分析性能，例如Filter Cache用于缓存使用过的Filter的结果集 Cluter State Buffer—-ElasticSearch被设计为每个Node都可以响应用户请求，因此每个Node的内存中都包含有一份集群状态的拷贝，一个规模很大的集群这个状态信息可能会非常大 读写之间有延迟，写入的数据差不多1s样子会被读取到，这也正常，写入的时候自动加入这么多索引肯定影响性能 数据结构灵活性不高，ElasticSearch这个东西，字段一旦建立就没法修改类型了，假如建立的数据表某个字段没有加全文索引，想加上，那么只能把整个表删了再重建 因此，搜索型NoSql最适用的场景就是有条件搜索尤其是全文搜索的场景，作为关系型数据库的一种替代方案。 另外，搜索型数据库还有一种特别重要的应用场景。我们可以想，一旦对数据库做了分库分表后，原来可以在单表中做的聚合操作、统计操作是否通通失效？例如我把订单表分16个库，1024张表，那么订单数据就散落在1024张表中，我想要统计昨天浙江省单笔成交金额最高的订单是哪笔如何做？我想要把昨天的所有订单按照时间排序分页展示如何做？这就是文档型NoSql的另一大作用了，我们可以把分表之后的数据统一打在文档型NoSql中，利用文档型NoSql的搜索与聚合能力完成对全量数据的查询。 至于为什么把它放在KV型NoSql后面作为第二个写呢，因为通常搜索型NoSql也会作为一层前置缓存，来对关系型数据库进行保护。 列式NoSql（代表—-HBase） 列式NoSql，大数据时代最具代表性的技术之一了，以HBase为代表。 列式NoSql是基于列式存储的，那么什么是列式存储呢，列式Sql和关系型数据库一样都有主键的概念，区别在于关系型数据库是按照行组织的数据： 看到每行有name、phone、address三个字段，这是行式存储的方式，且可以观察id = 2的这条数据，即使phone字段没有，它也是占空间的。数据库会根据创建表的字段类型预分配空间。 列式存储完全是另一种方式，它是按每一列进行组织的数据： 这么做有什么好处呢？大致有以下几点： 查询时只有指定的列会被读取，不会读取所有列 存储上节约空间，Null值不会被存储，一列中有时候会有很多重复数据（尤其是枚举数据，性别、状态等），这类数据可压缩，行式数据库压缩率通常在3:15:1之间，列式数据库的压缩率一般在8:130:1左右。 列数据被组织到一起，一次磁盘IO可以将一列数据一次性读取到内存中 第二点说到了数据压缩，什么意思呢，以比较常见的字典表压缩方式举例： 接着继续讲讲优缺点，列式NoSql，以HBase为代表的，优点为： 海量数据无限存储，PB级别数据随便存，底层基于HDFS（Hadoop文件系统），数据持久化 读写性能好，只要没有滥用造成数据热点，读写基本随便玩 横向扩展在关系型数据库及非关系型数据库中都是最方便的之一，只需要添加新机器就可以实现数据容量的线性增长，且可用在廉价服务器上，节省成本 本身没有单点故障，可用性高 可存储结构化或者半结构化的数据 列数理论上无限，HBase本身只对列族数量有要求，建议1~3个 说了这么多HBase的优点，又到了说HBase缺点的时候了： HBase是Hadoop生态的一部分，因此它本身是一款比较重的产品，依赖很多Hadoop组件，数据规模不大没必要用，运维还是有点复杂的 KV式，不支持条件查询，或者说条件查询非常非常弱吧，HBase在Scan扫描一批数据的情况下还是提供了前缀匹配这种API的，条件查询除非定义多个RowKey做数据冗余 不支持分页查询，因为统计不了数据总数 因此HBase比较适用于那种KV型的且未来无法预估数据增长量的场景，另外HBase使用还是需要一定的经验，主要体现在RowKey的设计上。 文档型NoSql（代表—-MongoDB）坦白讲，根据我的工作经历，文档型NoSql我只有比较浅的使用经验，因此这部分只能结合之前的使用与网上的文章大致给大家介绍一下。 什么是文档型NoSql呢，文档型NoSql指的是将半结构化数据存储为文档的一种NoSql，文档型NoSql通常以JSON或者XML格式存储数据，因此文档型NoSql是没有Schema的，由于没有Schema的特性，我们可以随意地存储与读取数据，因此文档型NoSql的出现是解决关系型数据库表结构扩展不方便的问题的。 MongoDB是文档型NoSql的代表产品，同时也是所有NoSql产品中的明星产品之一，因此这里以MongoDB为例。按我的理解，作为文档型NoSql，MongoDB是一款完全和关系型数据库对标的产品，就我们从存储上来看： 看到，关系型数据库是按部就班地每个字段一列存，在MongDB里面就是一个JSON字符串存储。关系型数据可以为name、phone建立索引，MongoDB使用createIndex命令一样可以为列建立索引，建立索引之后可以大大提升查询效率。其他方面而言，就大的基本概念，二者之间基本也是类似的： 因此，对于MongDB，我们只要理解成一个Free-Schema的关系型数据库就完事了，它的优缺点比较一目了然，优点： 没有预定义的字段，扩展字段容易 相较于关系型数据库，读写性能优越，命中二级索引的查询不会比关系型数据库慢，对于非索引字段的查询则是全面胜出 缺点在于： 不支持事务操作，虽然Mongodb4.0之后宣称支持事务，但是效果待观测 多表之间的关联查询不支持（虽然有嵌入文档的方式），join查询还是需要多次操作 空间占用较大，这个是MongDB的设计问题，空间预分配机制 + 删除数据后空间不释放，只有用db.repairDatabase()去修复才能释放 目前没发现MongoDB有关系型数据库例如MySql的Navicat这种成熟的运维工具 总而言之，MongDB的使用场景很大程度上可以对标关系型数据库，但是**比较适合处理那些没有join、没有强一致性要求且表Schema会常变化的数据**。 总结：数据库与NoSql及各种NoSql间的对比最后一部分，做一个总结，本文归根到底是两个话题： 何时选用关系型数据库，何时选用非关系型数据库 选用非关系型数据库，使用哪种非关系型数据库 首先是第一个话题，关系型数据库与非关系型数据库的选择，在我理解里面无非就是两点考虑： 第一点，不多解释应该都理解，非关系型数据库都是通过牺牲了ACID特性来获取更高的性能的，假设两张表之间有比较强的一致性需求，那么这类数据是不适合放在非关系型数据库中的。 第二点，核心数据不走非关系型数据库，例如用户表、订单表，但是这有一个前提，就是这一类核心数据会有多种查询模式，例如用户表有ABCD四个字段，可能根据AB查，可能根据AC查，可能根据D查，假设核心数据，但是就是个KV形式，比如用户的聊天记录，那么HBase一存就完事了。 这几年的工作经验来看，非核心数据尤其是日志、流水一类中间数据千万不要写在关系型数据库中，这一类数据通常有两个特点： 写远高于读 写入量巨大 一旦使用关系型数据库作为存储引擎，将大大降低关系型数据库的能力，正常读写QPS(**每秒查询率**)不高的核心服务会受这一类数据读写的拖累。 接着是第二个问题，如果我们使用非关系型数据库作为存储引擎，那么如何选型？其实上面的文章基本都写了，这里只是做一个总结（所有的缺点都不会体现事务这个点，因为这是所有NoSql相比关系型数据库共有的一个问题） 但是这里特别说明，选型一定要结合实际情况而不是照本宣科，比如： 企业发展之初，明明一个关系型数据库就能搞定且支撑一年的架构，搞一套大而全的技术方案出来 有一些数据条件查询多，更适合使用ElasticSearch做存储降低关系型数据库压力，但是公司成本有限，这种情况下这类数据可以尝试继续使用关系型数据库做存储 有一类数据格式简单，就是个KV类型且增长量大，但是公司没有HBase这方面的人才，运维上可能会有一定难度，出于实际情况考虑，可先用关系型数据库顶一阵子 所以，如果不考虑实际情况，虽然合适有些存储引擎更加合适，但是强行使用反而适得其反，总而言之，适合自己的才是最好的。 转载: 五月的仓颉:Sql Or NoSql]]></content>
      <categories>
        <category>架构方案</category>
      </categories>
      <tags>
        <tag>Sql</tag>
        <tag>NoSql</tag>
        <tag>架构方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis使用接口访问数据库原理]]></title>
    <url>%2F2019%2F08%2F16%2FMybatis%E4%BD%BF%E7%94%A8%E6%8E%A5%E5%8F%A3%E8%AE%BF%E9%97%AE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Mybatis使用接口访问数据库原理相关类: MapperProxyFactory MapperProxy MapperMethod 最终委托给了SqlSession,通过sqlStatement进行匹配方法,这里的statement等于接口的全类限定名+方法名,也就意味着Mybatis的dao接口,不要出现相同的方法签名。而Mybatis存储访问数据库的一个MappedStatement(很重要,存储SQL,输入参数,输出参数等等)是使用StrictMap结构存储,该类继承了HashMap,在内部重写了put()方法,限定了dao接口不能出现相同的方法签名,该类是org.apache.ibatis.session.Configuration的静态内部类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130 // MapperMethod的执行查询的主要方法public class MapperMethod&#123; private final SqlCommand command; private final MethodSignature method; public MapperMethod(Class&lt;?&gt; mapperInterface, Method method, Configuration config) &#123; this.command = new SqlCommand(config, mapperInterface, method); this.method = new MethodSignature(config, mapperInterface, method); &#125; public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); // 取出MappedStatement的id,即dao的接口全限定名+方法名 result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) &#123; result = Optional.ofNullable(result); &#125; &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException("Unknown execution method for: " + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException("Mapper method '" + command.getName() + " attempted to return null from a method with a primitive return type (" + method.getReturnType() + ")."); &#125; return result; &#125; ... ...&#125;// MapperProxy,生成Mapper类的代理public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; private static final long serialVersionUID = -6424540398559729838L; private final SqlSession sqlSession; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache; public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123; this.sqlSession = sqlSession; this.mapperInterface = mapperInterface; this.methodCache = methodCache; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125; private MapperMethod cachedMapperMethod(Method method) &#123; return methodCache.computeIfAbsent(method, k -&gt; new MapperMethod(mapperInterface, method, sqlSession.getConfiguration())); &#125; ...&#125;//MapperProxyFactorypublic class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache = new ConcurrentHashMap&lt;&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; public Map&lt;Method, MapperMethod&gt; getMethodCache() &#123; return methodCache; &#125; @SuppressWarnings("unchecked") protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125;&#125; 相关流程: 设计模式使用 代理模式(Jdk代理) 命令模式 委托模式 使用限制 你无法通过反射的方式来调用接口的方法。 你需要使用SqlSession来进行一次数据库查询或者更新。利用MappedStatement的id属性,即接口的全类限定名+方法名。这样可以写出通用的Mybatis程序。]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>代理模式</tag>
        <tag>命令模式</tag>
        <tag>Jdk代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 Stream学习]]></title>
    <url>%2F2019%2F08%2F15%2FJava8-Stream%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Java8 Stream学习 Java 8 中的 Stream 俗称为流，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。Stream 用于对集合对象进行各种非常便利、高效的聚合操作，或者大批量数据操作。Stream API 借助于Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势。通过下面的例子我们可以初步体会到使用 Stream 处理集合的便利性。 初探Stream有如下一个List，现要从中筛选出以J开头的元素，然后转换为大写，最后输出结果。Java 8之前我们是这样做的： 12345678910List&lt;String&gt; list = Arrays.asList("Java", "JavaScript", "python", "PHP", "C#", "Golang", "Swift");List&lt;String&gt; filterList = new ArrayList&lt;&gt;();for (String str : list) &#123; if (str.startsWith("J")) &#123; filterList.add(str.toUpperCase()); &#125;&#125;for (String str : filterList) &#123; System.out.println(str);&#125; 为了筛选集合我们进行了两次外部迭代，并且还创建了一个用来临时存放筛选元素的集合对象。借助Java 8中的Stream我们可以极大的简化这个处理过程： 12345List&lt;String&gt; list = Arrays.asList("Java", "JavaScript", "python", "PHP", "C#", "Golang", "Swift");list.stream() .filter(s -&gt; s.startsWith("J")) .map(String::toUpperCase) .forEach(System.out::println); 上面的例子中，集合使用stream方法创建了一个流，然后使用filter和map方法来处理这个集合，它们统称为中间操作。中间操作都会返回另一个流，以便于将各种对集合的操作连接起来形成一条流水线。最后我们使用了forEach方法迭代筛选结果，这种位于流的末端，对流进行处理并且生成结果的方法称为终端操作。 总而言之，流的使用一般包括三件事情： 一个数据源（如集合）来执行一个查询； 一个中间操作链，形成一条流的流水线； 一个终端操作，执行流水线，并能生成结果。 下表列出了流中常见的中间操作和终端操作： 操作 类型 返回类型 使用的类型/函数式接口 函数描述符 filter 中间 Stream&lt;T&gt; Predicate&lt;T&gt; T -&gt; boolean distinct 中间 Stream&lt;T&gt; skip 中间 Stream&lt;T&gt; long limit 中间 Stream&lt;T&gt; long map 中间 Stream&lt;R&gt; Function&lt;T, R&gt; T -&gt; R flatMap 中间 Stream&lt;R&gt; Function&lt;T, Stream&lt;R&gt;&gt; T -&gt; Stream&lt;R&gt; sorted 中间 Stream&lt;T&gt; Comparator&lt;T&gt; (T, T) -&gt; int anyMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean noneMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean allMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean findAny 终端 Optional&lt;T&gt; findFirst 终端 Optional&lt;T&gt; forEach 终端 void Consumer&lt;T&gt; T -&gt; void collect 终端 R Collector&lt;T, A, R&gt; reduce 终端 Optional&lt;T&gt; BinaryOperator&lt;T&gt; (T, T) -&gt; T count 终端 long 下面详细介绍这些操作的使用。除了特殊说明，默认使用下面这个集合作为演示： 1List&lt;String&gt; list = Arrays.asList("Java", "JavaScript", "python", "PHP", "C#", "Golang", "Swift", "C++", "Ruby"); 中间操作filterStreams接口支持·filter方法，该方法接收一个Predicate&lt;T&gt;，函数描述符为T -&gt; boolean，用于对集合进行筛选，返回所有满足的元素： 1list.stream().filter(s -&gt; s.contains("#")) .forEach(System.out::println); 结果输出C#。 distinctdistinct方法用于排除流中重复的元素，类似于SQL中的distinct操作。比如筛选中集合中所有的偶数，并排除重复的结果： 12345List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 1, 3, 3, 2, 4);numbers.stream() .filter(i -&gt; i % 2 == 0) .distinct() .forEach(System.out::println); 结果输出2 4。 skipskip(n)方法用于跳过流中的前n个元素，如果集合元素小于n，则返回空流。比如筛选出以J开头的元素，并排除第一个： 1234list.stream() .filter(s -&gt; s.startsWith("J")) .skip(1) .forEach(System.out::println); 结果输出JavaScript。 limitlimit(n)方法返回一个长度不超过n的流，比如下面的例子将输出Java JavaScript python： 123list.stream() .limit(3) .forEach(System.out::println); mapmap方法接收一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素。如： 123list.stream() .map(String::length) .forEach(System.out::println); 结果输出4 10 6 3 2 6 5 3 4。 map还支持将流特化为指定原始类型的流，如通过mapToInt，mapToDouble和mapToLong方法，可以将流转换为IntStream，DoubleStream和LongStream。特化后的流支持sum，min和max方法来对流中的元素进行计算。比如： 123List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 1, 3, 3, 2, 4);IntStream intStream = numbers.stream().mapToInt(a -&gt; a);System.out.println(intStream.sum()); // 16 也可以通过下面的方法，将IntStream转换为Stream： 1Stream&lt;Integer&gt; s = intStream.boxed(); flatMapflatMap用于将多个流合并成一个流，俗称流的扁平化。这么说有点抽象，举个例子，比如现在需要将list中的各个元素拆分为一个个字母，并过滤掉重复的结果，你可能会这样做： 1234list.stream() .map(s -&gt; s.split("")) .distinct() .forEach(System.out::println); 输出如下： 123456789[Ljava.lang.String;@e9e54c2[Ljava.lang.String;@65ab7765[Ljava.lang.String;@1b28cdfa[Ljava.lang.String;@eed1f14[Ljava.lang.String;@7229724f[Ljava.lang.String;@4c873330[Ljava.lang.String;@119d7047[Ljava.lang.String;@776ec8df[Ljava.lang.String;@4eec7777 这明显不符合我们的预期。实际上在map(s -&gt; s.split(&quot;&quot;))操作后，返回了一个Stream&lt;String[]&gt;类型的流，所以输出结果为每个数组对象的句柄，而我们真正想要的结果是Stream&lt;String&gt;。在Stream中，可以使用Arrays.stream()方法来将数组转换为流，改造上面的方法： 12345list.stream() .map(s -&gt; s.split("")) .map(Arrays::stream) .distinct() .forEach(System.out::println); 123456789java.util.stream.ReferencePipeline$Head@eed1f14java.util.stream.ReferencePipeline$Head@7229724fjava.util.stream.ReferencePipeline$Head@4c873330java.util.stream.ReferencePipeline$Head@119d7047java.util.stream.ReferencePipeline$Head@776ec8dfjava.util.stream.ReferencePipeline$Head@4eec7777java.util.stream.ReferencePipeline$Head@3b07d329java.util.stream.ReferencePipeline$Head@41629346java.util.stream.ReferencePipeline$Head@404b9385 因为上面的流经过map(Arrays::stream)处理后，将每个数组变成了一个新的流，返回结果为流的数组Stream&lt;String&gt;[]，所以输出是各个流的句柄。我们还需将这些新的流连接成一个流，使用flatMap来改写上面的例子： 12345list.stream() .map(s -&gt; s.split("")) .flatMap(Arrays::stream) .distinct() .forEach(s -&gt; System.out.print(s + " ")); 输出如下： 1J a v S c r i p t y h o n P H C # G l g w f + R u b 和map类似，flatMap方法也有相应的原始类型特化方法，如flatMapToInt等。 终端操作anyMatchanyMatch方法用于判断流中是否有符合判断条件的元素，返回值为boolean类型。比如判断list中是否含有SQL元素： 12list.stream() .anyMatch(s -&gt; "SQL".equals(s)); // false allMatchallMatch方法用于判断流中是否所有元素都满足给定的判断条件，返回值为boolean类型。比如判断list中是否所有元素长度都不大于10： 12list.stream() .allMatch(s -&gt; s.length() &lt;= 10); // true noneMatchnoneMatch方法用于判断流中是否所有元素都不满足给定的判断条件，返回值为boolean类型。比如判断list中不存在长度大于10的元素： 12list.stream() .noneMatch(s -&gt; s.length() &gt; 10); // true findAnyfindAny方法用于返回流中的任意元素的Optional类型，例如筛选出list中任意一个以J开头的元素，如果存在，则输出它： 1list.stream().filter(s -&gt; s.startsWith("J")).findAny().ifPresent(System.out::println); // Java findFirstfindFirst方法用于返回流中的第一个元素的Optional类型，例如筛选出list中长度大于5的元素，如果存在，则输出第一个： 1234list.stream() .filter(s -&gt; s.length() &gt; 5) .findFirst() .ifPresent(System.out::println); // JavaScript reducereduce函数从字面上来看就是压缩，缩减的意思，它可以用于数字类型的流的求和，求最大值和最小值。如对numbers中的元素求和： 123List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 1, 3, 3, 2, 4);numbers.stream() .reduce(0, Integer::sum); // 16 reduce函数也可以不指定初始值，但这时候将返回一个Optional对象，比如求最大值和最小值： 12numbers.stream().reduce(Integer::max.ifPresent(System.out::println); // 4numbers.stream().reduce(Integer::min).ifPresent(System.out::println); // 1 forEachforEach用于迭代流中的每个元素，最为常见的就是迭代输出，如： 1list.stream().forEach(System.out::println); countcount方法用于统计流中元素的个数，比如： 1list.stream().count(); // 9 collectcollect方法用于收集流中的元素，并放到不同类型的结果中，比如List、Set或者Map。举个例子： 1List&lt;String&gt; filterList = list.stream().filter(s -&gt; s.startsWith("J")).collect(Collectors.toList()); 如果需要以Set来替代List，只需要使用Collectors.toSet()就好了。 流的构建除了使用集合对象的stream方法构建流之外，我们可以手动构建一些流。 数值范围构建IntStream和LongStream对象支持range和rangeClosed方法来构建数值流。这两个方法都是第一个参数接受起始值，第二个参数接受结束值。但range是不包含结束值的，而rangeClosed则包含结束值。比如对1到100的整数求和： 1IntStream.rangeClosed(1, 100).sum(); // 5050 由值构建静态方法Stream.of可以显式值创建一个流。它可以接受任意数量的参数。例如，以下代码直接使用Stream.of创建了一个字符串流: 1Stream&lt;String&gt; s = Stream.of("Java", "JavaScript", "C++", "Ruby"); 也可以使用Stream.empty()构建一个空流： 1Stream&lt;Object&gt; emptyStream = Stream.empty(); 由数组构建静态方法Arrays.stream可以通过数组创建一个流。它接受一个数组作为参数。例如： 12int[] arr = &#123;1, 2, 3, 4, 5&#125;;IntStream intStream = Arrays.stream(arr); 由文件生成流java.nio.file.Files中的很多静态方法都会返回一个流。例如Files.lines方法会返回一个由指定文件中的各行构成的字符串流。比如统计一个文件中共有多少个字： 123456long wordCout = 0L;try (Stream&lt;String&gt; lines = Files.lines(Paths.get("file.txt"), Charset.defaultCharset())) &#123; wordCout = lines.map(l -&gt; l.split("")) .flatMap(Arrays::stream) .count();&#125; catch (Exception ignore) &#123;&#125; 由函数构造Stream API提供了两个静态方法来从函数生成流：Stream.iterate和Stream.generate。这两个操作可以创建所谓的无限流。比如下面的例子构建了10个偶数： 1Stream.iterate(0, n -&gt; n + 2).limit(10).forEach(System.out::println); iterate方法接受一个初始值（在这里是0），还有一个依次应用在每个产生的新值上的Lambda（UnaryOperator类型）。这里，我们使用Lambda n -&gt; n + 2，返回的是前一个元 素加上2。因此，iterate方法生成了一个所有正偶数的流：流的第一个元素是初始值0。然后加上2来生成新的值2，再加上2来得到新的值4，以此类推。 与iterate方法类似，generate方法也可让你按需生成一个无限流。但generate不是依次对每个新生成的值应用函数，比如下面的例子生成了5个0到1之间的随机双精度数： 1Stream.generate(Math::random).limit(5).forEach(System.out::println); 输出结果如下： 123450.63346468505878630.41901476418340090.43619683945154750.69117964568386550.08156838267267075 转载:https://mrbird.cc/java8stream1.html]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Lamdba</tag>
        <tag>Java8 Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet状态管理]]></title>
    <url>%2F2019%2F08%2F11%2FServlet%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[使用Jsoup防御XSS攻击]]></title>
    <url>%2F2019%2F08%2F11%2F%E4%BD%BF%E7%94%A8Jsoup%E9%98%B2%E5%BE%A1XSS%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot异常处理]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Boot%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot开启Spring Security]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Boot%E5%BC%80%E5%90%AFSpring-Security%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security自定义用户登录]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security%E8%87%AA%E5%AE%9A%E4%B9%89%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security添加图像验证码]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security%E6%B7%BB%E5%8A%A0%E5%9B%BE%E5%83%8F%E9%AA%8C%E8%AF%81%E7%A0%81%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security添加记住我功能]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security%E6%B7%BB%E5%8A%A0%E8%AE%B0%E4%BD%8F%E6%88%91%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security短信验证码登录]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81%E7%A0%81%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security退出登录]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security%E9%80%80%E5%87%BA%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security Session管理]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security-Session%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security权限控制]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security Oauth2入门]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security-Oauth2%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security Oauth2自定义Token获取方式]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security-Oauth2%E8%87%AA%E5%AE%9A%E4%B9%89Token%E8%8E%B7%E5%8F%96%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security OAuth2自定义令牌控制]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security-OAuth2%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BB%A4%E7%89%8C%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Security OAuth2 SSO]]></title>
    <url>%2F2019%2F08%2F11%2FSpring-Security-OAuth2-SSO%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot配合Hibernate Validator参数校验]]></title>
    <url>%2F2019%2F08%2F11%2FSpringBoot%E9%85%8D%E5%90%88Hibernate-Validator%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2019%2F08%2F11%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[深入理解volatile关键字]]></title>
    <url>%2F2019%2F08%2F11%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3volatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Fork/Join学习]]></title>
    <url>%2F2019%2F08%2F11%2FFork-Join%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal学习]]></title>
    <url>%2F2019%2F08%2F11%2FThreadLocal%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[深入学习Java线程池]]></title>
    <url>%2F2019%2F08%2F11%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[前言 在前面的例子中，我们都是通过new Thread来创建一个线程，由于线程的创建和销毁都需要消耗一定的CPU资源，所以在高并发下这种创建线程的方式将严重影响代码执行效率。而线程池的作用就是让一个线程执行结束后不马上销毁，继续执行新的任务，这样就节省了不断创建线程和销毁线程的开销。 ThreadPoolExecutor创建Java线程池最为核心的类为ThreadPoolExecutor： 它提供了四种构造函数来创建线程池，其中最为核心的构造函数如下所示： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 这7个参数的含义如下： corePoolSize 线程池核心线程数。即线程池中保留的线程个数，即使这些线程是空闲的，也不会被销毁，除非通过ThreadPoolExecutor的allowCoreThreadTimeOut(true)方法开启了核心线程的超时策略； maximumPoolSize 线程池中允许的最大线程个数； keepAliveTime 用于设置那些超出核心线程数量的线程的最大等待时间，超过这个时间还没有新任务的话，超出的线程将被销毁； unit 超时时间单位； workQueue 线程队列。用于保存通过execute方法提交的，等待被执行的任务； threadFactory 线程创建工程，即指定怎样创建线程； handler 拒绝策略。当ThreadPoolExecutor已经关闭或者ThreadPoolExecutor已经饱和时(达到了最大线程池大小且工作对了已满),execute()方法将要调用Handler。 在通过这个构造方法创建线程池的时候，这几个参数必须满足以下条件，否则将抛出IllegalArgumentException异常： corePoolSize不能小于0； keepAliveTime不能小于0； maximumPoolSize 不能小于等于0； maximumPoolSize不能小于corePoolSize； 此外，workQueue、threadFactory和handler不能为null，否则将抛出空指针异常。 下面举些例子来深入理解这几个参数的含义。 使用上面的构造方法创建一个线程池： 123456789101112131415161718192021ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 1, 2, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy()); System.out.println("线程池创建完毕"); int activeCount = -1; int queueSize = -1; while (true) &#123; if (activeCount != threadPoolExecutor.getActiveCount() || queueSize != threadPoolExecutor.getQueue().size()) &#123; System.out.println("活跃线程个数 " + threadPoolExecutor.getActiveCount()); System.out.println("核心线程个数 " + threadPoolExecutor.getCorePoolSize()); System.out.println("队列线程个数 " + threadPoolExecutor.getQueue().size()); System.out.println("最大线程数 " + threadPoolExecutor.getMaximumPoolSize()); System.out.println("------------------------------------"); activeCount = threadPoolExecutor.getActiveCount(); queueSize = threadPoolExecutor.getQueue().size(); &#125;&#125; 上面的代码创建了一个核心线程数量为1，允许最大线程数量为2，最大活跃时间为10秒，线程队列长度为1的线程池。 假如我们通过execute方法向线程池提交1个任务，看看结果如何： 1234567891011121314151617181920212223ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 1, 2, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy());System.out.println("线程池创建完毕"); threadPoolExecutor.execute(() -&gt; sleep(100)); int activeCount = -1; int queueSize = -1; while (true) &#123; if (activeCount != threadPoolExecutor.getActiveCount() || queueSize != threadPoolExecutor.getQueue().size()) &#123; System.out.println("活跃线程个数 " + threadPoolExecutor.getActiveCount()); System.out.println("核心线程个数 " + threadPoolExecutor.getCorePoolSize()); System.out.println("队列线程个数 " + threadPoolExecutor.getQueue().size()); System.out.println("最大线程数 " + threadPoolExecutor.getMaximumPoolSize()); System.out.println("------------------------------------"); activeCount = threadPoolExecutor.getActiveCount(); queueSize = threadPoolExecutor.getQueue().size(); &#125;&#125; ThreadPoolExecutor的execute和submit方法都可以向线程池提交任务，区别是，submit方法能够返回执行结果，返回值类型为Future sleep方法代码： 12private static void sleep(long value)&#123; try &#123; System.out.println(Thread.currentThread().getName() + "线程执行sleep方法"); TimeUnit.SECONDS.sleep(value); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; 启动程序，控制台输出如下： 线程池核心线程数量为1，通过execute提交了一个任务后，由于核心线程是空闲的，所以任务被执行了。由于这个任务的逻辑是休眠100秒，所以在这100秒内，线程池的活跃线程数量为1。此外，因为提交的任务被核心线程执行了，所以并没有线程需要被放到线程队列里等待，线程队列长度为0。 假如我们通过execute方法向线程池提交2个任务，看看结果如何： 12threadPoolExecutor.execute(() -&gt; sleep(100));threadPoolExecutor.execute(() -&gt; sleep(100)); 线程池核心线程数量为1，通过execute提交了2个任务后，一开始核心线程是空闲的，Thread-0被执行。由于这个任务的逻辑是休眠100秒，所以在这100秒内，线程池的活跃线程数量为1。因为核心线程数量为1，所以另外一个任务在这100秒内不能被执行，于是被放到线程队列里等待，线程队列长度为1。 假如我们通过execute方法向线程池提交3个任务，看看结果如何： 123threadPoolExecutor.execute(() -&gt; sleep(100));threadPoolExecutor.execute(() -&gt; sleep(100));threadPoolExecutor.execute(() -&gt; sleep(100)); 这三个任务都是休眠100秒，所以核心线程池中第一个任务正在被执行，第二个任务被放入到了线程队列。而当第三个任务被提交进来时，线程队列满了（我们定义的长度为1），由于该线程池允许的最大线程数量为2，所以线程池还可以再创建一个线程来执行另外一个任务，于是乎之前在线程队列里的线程被取出执行（FIFO），第三个任务被放入到了线程队列。 改变第二个和第三个任务的睡眠时间，观察输出： 12threadPoolExecutor.execute(() -&gt; sleep(100));threadPoolExecutor.execute(() -&gt; sleep(5));threadPoolExecutor.execute(() -&gt; sleep(5)); 第二个任务提交5秒后，任务执行完毕，所以线程队列里的任务被执行，于是队列线程个数为0，活跃线程数量为2（第一个和第三个任务）。再过5秒后，第三个任务执行完毕，于是活跃线程数量为1（第一个100秒还没执行完毕）。 在第三个任务结束的瞬间，我们观察线程快照: 可以看到，线程池中有两个线程，Thread-0在执行第一个任务（休眠100秒，还没结束），Thread-1执行完第三个任务后并没有马上被销毁。过段时间后（10秒钟后）再观察线程快照: 可以看到，Thread-1这个线程被销毁了，因为我们在创建线程池的时候，指定keepAliveTime 为10秒，10秒后，超出核心线程池线程外的那些线程将被销毁。 假如一次性提交4个任务，看看会怎样： 12threadPoolExecutor.execute(() -&gt; sleep(100));threadPoolExecutor.execute(() -&gt; sleep(100));threadPoolExecutor.execute(() -&gt; sleep(100));threadPoolExecutor.execute(() -&gt; sleep(100)); 因为我们设置的拒绝策略为AbortPolicy，所以最后提交的那个任务直接被拒绝了。更多拒绝策略下面会介绍到。 关闭线程池线程池包含以下几个状态： 当线程池中所有任务都处理完毕后，线程并不会自己关闭。我们可以通过调用shutdown和shutdownNow方法来关闭线程池。两者的区别在于： shutdown方法将线程池置为shutdown状态，拒绝新的任务提交，但线程池并不会马上关闭，而是等待所有正在执行的和线程队列里的任务都执行完毕后，线程池才会被关闭。所以这个方法是平滑的关闭线程池。 shutdownNow方法将线程池置为stop状态，拒绝新的任务提交，中断正在执行的那些任务，并且清除线程队列里的任务并返回。所以这个方法是比较“暴力”的。 举两个例子观察下两者的区别： shutdown例子: 123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args) &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 4, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(2), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy()); threadPoolExecutor.execute(new shortTask()); threadPoolExecutor.execute(new longTask()); threadPoolExecutor.execute(new longTask()); threadPoolExecutor.execute(new shortTask()); threadPoolExecutor.shutdown(); System.out.println("已经执行了线程池shutdown方法");&#125;static class shortTask implements Runnable &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + "执行shortTask完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("shortTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125;static class longTask implements Runnable &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + "执行longTask完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("longTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125; 启动程序，控制台输出如下： 可以看到，虽然在任务都被提交后马上执行了shutdown方法，但是并不会马上关闭线程池，而是等待所有被提交的任务都执行完了才关闭。 shutdownNow例子： 1234567891011121314151617181920212223242526272829303132333435363738394041public static void main(String[] args) &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 4, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(2), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy()); threadPoolExecutor.execute(new shortTask()); threadPoolExecutor.execute(new longTask()); threadPoolExecutor.execute(new longTask()); threadPoolExecutor.execute(new shortTask()); List&lt;Runnable&gt; runnables = threadPoolExecutor.shutdownNow(); // 马上关闭，并返回还未被执行的任务 System.out.println(runnables); System.out.println("已经执行了线程池shutdownNow方法");&#125;static class shortTask implements Runnable &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + "执行shortTask完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("shortTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125;static class longTask implements Runnable &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + "执行longTask完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("longTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125; 启动程序，控制台输出如下： 可以看到，在执行shutdownNow方法后，线程池马上就被关闭了，正在执行中的两个任务被打断，并且返回了线程队列中等待被执行的两个任务。 通过上面两个例子我们还可以看到shutdown和shutdownNow方法都不是阻塞的。常与shutdown搭配的方法有awaitTermination。 awaitTermination方法接收timeout和TimeUnit两个参数，用于设定超时时间及单位。当等待超过设定时间时，会监测ExecutorService是否已经关闭，若关闭则返回true，否则返回false。该方法是阻塞的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 4, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(2), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy()); threadPoolExecutor.execute(new shortTask()); threadPoolExecutor.execute(new longTask()); threadPoolExecutor.execute(new longTask()); threadPoolExecutor.execute(new shortTask()); threadPoolExecutor.shutdown(); boolean isShutdown = threadPoolExecutor.awaitTermination(3, TimeUnit.SECONDS); if (isShutdown) &#123; System.out.println("线程池在3秒内成功关闭"); &#125; else &#123; System.out.println("等了3秒还没关闭，不等了╰（‵□′）╯"); &#125; System.out.println("------------");&#125;static class shortTask implements Runnable &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + "执行shortTask完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("shortTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125;static class longTask implements Runnable &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + "执行longTask完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("longTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125; 启动程序输出如下： 4大拒绝策略当线程池无法再接收新的任务的时候，可采取如下四种策略： CallerRunsPolicyCallerRunsPolicy策略：由调用线程处理该任务： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 3, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.CallerRunsPolicy()); threadPoolExecutor.execute(new shortTask("任务1")); threadPoolExecutor.execute(new longTask("任务2")); threadPoolExecutor.execute(new longTask("任务3")); threadPoolExecutor.execute(new shortTask("任务4")); threadPoolExecutor.execute(new shortTask("任务5")); threadPoolExecutor.shutdown();&#125;static class shortTask implements Runnable &#123; private String name; public shortTask(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + "执行shortTask-name-" + name + "完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("shortTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125;static class longTask implements Runnable &#123; private String name; public longTask(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + "执行longTask-name-" + name + "完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("longTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125; 上面的线程池最多只能一次性提交4个任务，第5个任务提交后会被拒绝策略处理。启动程序输出如下： 可以看到，第5个提交的任务由调用线程（即main线程）处理该任务。 AbortPolicyAbortPolicy策略：丢弃任务，并抛出RejectedExecutionException异常。前面的例子就是使用该策略，所以不再演示。 DiscardOldestPolicyDiscardOldestPolicy策略：丢弃最早被放入到线程队列的任务，将新提交的任务放入到线程队列末端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 3, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.DiscardOldestPolicy()); threadPoolExecutor.execute(new shortTask("任务1")); threadPoolExecutor.execute(new longTask("任务2")); threadPoolExecutor.execute(new longTask("任务3")); threadPoolExecutor.execute(new shortTask("任务4")); threadPoolExecutor.execute(new shortTask("任务5")); threadPoolExecutor.shutdown();&#125;static class shortTask implements Runnable &#123; private String name; public shortTask(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + "执行shortTask-name-" + name + "完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("shortTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125;static class longTask implements Runnable &#123; private String name; public longTask(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + "执行longTask-name-" + name + "完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("longTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125; 启动程序输出如下： 可以看到最后提交的任务被执行了，而第3个任务是第一个被放到线程队列的任务，被丢弃了。 DiscardPolicyDiscardPolicy策略：直接丢弃新的任务，不抛异常： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 3, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.DiscardPolicy()); threadPoolExecutor.execute(new shortTask("任务1")); threadPoolExecutor.execute(new longTask("任务2")); threadPoolExecutor.execute(new longTask("任务3")); threadPoolExecutor.execute(new shortTask("任务4")); threadPoolExecutor.execute(new shortTask("任务5")); threadPoolExecutor.shutdown();&#125;static class shortTask implements Runnable &#123; private String name; public shortTask(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + "执行shortTask-name-" + name + "完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("shortTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125;static class longTask implements Runnable &#123; private String name; public longTask(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + "执行longTask-name-" + name + "完毕"); &#125; catch (InterruptedException e) &#123; System.err.println("longTask执行过程中被打断" + e.getMessage()); &#125; &#125;&#125; 启动程序，输出如下： 第5个任务直接被拒绝丢弃了，而没有抛出任何异常 线程池工厂方法除了使用ThreadPoolExecutor的构造方法创建线程池外，我们也可以使用Executors提供的工厂方法来创建不同类型的线程池： newFixedThreadPool适用于为了满足资源管理的请求,而需要限制当前线程数量的应用场景,它适用于负载比较重的服务器。 查看newFixedThreadPool方法源码： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 可以看到，通过newFixedThreadPool创建的是一个固定大小的线程池，大小由nThreads参数指定，它具有如下几个特点: 当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize。 由于1,使用无界队列时,使用无界队列时maximumPoolSize将是一个无效参数。 由于1和2，使用无界队列时keepAliveTime将是一个无效参数 由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。 newCachedThreadPool适用于执行很多的短期异步任务的小程序,或者负载较轻的服务器。 查看newCachedThreadPool方法源码： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 这是一个理论上无限大小的线程池： 核心线程数为0，SynchronousQueue队列是没有长度的队列，所以当有新的任务提交，如果有空闲的还未超时的（最大空闲时间60秒）线程则执行该任务，否则新增一个线程来处理该任务。 因为线程数量没有限制，理论上可以接收无限个新任务，所以这里也没有指定拒绝策略。 CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。 newSingleThreadExecutor适用于需要保证顺序的执行各个任务;并且在任意时间点,不会有多个线程活动的场景。 查看newSingleThreadExecutor源码： 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 核心线程数和最大线程数都为1，每次只能有一个线程处理任务。 LinkedBlockingQueue队列可以接收无限个新任务。 newScheduledThreadPool ScheduledThreadPoolExecutor：适用于多个后台线程执行周期任务,同时为了满足资源管理需求而需要限制后台线程的数量的应用场景。 SingleThreadScheduledExecutor：适用于需要单个后台线程执行周期任务，同时需要保证顺 序地执行各个任务的应用场景。 查看newScheduledThreadPool源码： 123456789public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;......public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; 所以newScheduledThreadPool理论是也是可以接收无限个任务，DelayedWorkQueue也是一个无界队列。 使用newScheduledThreadPool创建的线程池除了可以处理普通的Runnable任务外，它还具有调度的功能： 1.延迟指定时间后执行： 123ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);// 延迟5秒执行executorService.schedule(() -&gt; System.out.println("hello"), 5, TimeUnit.SECONDS); 2.按指定的速率执行： 12345ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);// 延迟1秒执行，然后每5秒执行一次executorService.scheduleAtFixedRate( () -&gt; System.out.println(LocalTime.now()), 1, 5, TimeUnit.SECONDS); 3.按指定的时延执行： 1ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);executorService.scheduleWithFixedDelay(() -&gt; System.out.println(LocalTime.now()), 1, 5, TimeUnit.SECONDS); 乍一看，scheduleAtFixedRate和scheduleWithFixedDelay没啥区别，实际它们还是有区别的： scheduleAtFixedRate按照固定速率执行任务，比如每5秒执行一个任务，即使上一个任务没有结束，5秒后也会开始处理新的任务； scheduleWithFixedDelay按照固定的时延处理任务，比如每延迟5秒执行一个任务，无论上一个任务处理了1秒，1分钟还是1小时，下一个任务总是在上一个任务执行完毕后5秒钟后开始执行。 对于这些线程池工厂方法的使用，阿里巴巴编程规程指出： 因为这几个线程池理论是都可以接收无限个任务，所以这就有内存溢出的风险。实际上只要我们掌握了ThreadPoolExecutor构造函数7个参数的含义，我们就可以根据不同的业务来创建出符合需求的线程池。一般线程池的创建可以参考如下规则： IO密集型任务，线程池线程数量可以设置为2 X CPU核心数； 计算密集型任务，线程池线程数量可以设置为CPU核心数 + 1。 混合型: 可以拆分成IO密集型任务和计算密集型任务。 一些API的用法ThreadPoolExecutor提供了几个判断线程池状态的方法： 12345678910111213141516171819202122public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 1, 2, 5, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy() ); threadPoolExecutor.execute(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); threadPoolExecutor.shutdown(); System.out.println("线程池为shutdown状态：" + threadPoolExecutor.isShutdown()); System.out.println("线程池正在关闭：" + threadPoolExecutor.isTerminating()); System.out.println("线程池已经关闭：" + threadPoolExecutor.isTerminated()); threadPoolExecutor.awaitTermination(6, TimeUnit.SECONDS); System.out.println("线程池已经关闭" + threadPoolExecutor.isTerminated());&#125; 程序输出如下： 前面我们提到，线程池核心线程即使是空闲状态也不会被销毁，除非使用allowCoreThreadTimeOut设置了允许核心线程超时： 12345678910111213141516public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 1, 2, 3, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy() ); threadPoolExecutor.allowCoreThreadTimeOut(true); threadPoolExecutor.execute(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println("任务执行完毕"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; 程序输出如下所示： 5秒后任务执行完毕，核心线程处于空闲的状态。因为通过allowCoreThreadTimeOut方法设置了允许核心线程超时，所以3秒后（keepAliveTime设置为3秒），核心线程被销毁。核心线程被销毁后，线程池也就没有作用了，于是就自动关闭了。 值得注意的是，如果一个线程池调用了allowCoreThreadTimeOut(true)方法，那么它的keepAliveTime不能为0。 ThreadPoolExecutor提供了一remove方法，查看其源码： 12345public boolean remove(Runnable task) &#123; boolean removed = workQueue.remove(task); tryTerminate(); // In case SHUTDOWN and now empty return removed;&#125; 可看到，它删除的是线程队列中的任务，而非正在被执行的任务。举个例子： 123456789101112131415161718192021public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 1, 2, 3, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy() ); threadPoolExecutor.execute(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println("任务执行完毕"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); Runnable r = () -&gt; System.out.println("看看我是否会被删除"); threadPoolExecutor.execute(r); threadPoolExecutor.remove(r); threadPoolExecutor.shutdown();&#125; 执行程序，输出如下： 可看到任务并没有被执行，已经被删除，因为唯一一个核心线程已经在执行任务了，所以后提交的这个任务被放到了线程队列里，然后通过remove方法删除。 默认情况下，只有当往线程池里提交了任务后，线程池才会启动核心线程处理任务。我们可以通过调用preStartCoreThread方法，让核心线程即使没有任务提交，也处于等待执行任务的活跃状态： 1234567891011121314public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 2, 3, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy() ); System.out.println("活跃线程数: " + threadPoolExecutor.getActiveCount()); threadPoolExecutor.prestartCoreThread(); System.out.println("活跃线程数: " + threadPoolExecutor.getActiveCount()); threadPoolExecutor.prestartCoreThread(); System.out.println("活跃线程数: " + threadPoolExecutor.getActiveCount()); threadPoolExecutor.prestartCoreThread(); System.out.println("活跃线程数: " + threadPoolExecutor.getActiveCount());&#125; 程序输出如下所示： 该方法返回boolean类型值，如果所以核心线程都启动了，返回false，反之返回true。 还有一个和它类似的preStartAllCoreThreads方法，它的作用是一次性启动所有核心线程，让其处于活跃地等待执行任务的状态。 ThreadPoolExecutor的invokeAny方法用于随机执行任务集合中的某个任务，并返回执行结果，该方法是同步方法： 123456789101112131415161718public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 5, 3, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy() ); // 任务集合 List&lt;Callable&lt;Integer&gt;&gt; tasks = IntStream.range(0, 4).boxed().map(i -&gt; (Callable&lt;Integer&gt;) () -&gt; &#123; TimeUnit.SECONDS.sleep(ThreadLocalRandom.current().nextInt(5)); return i; &#125;).collect(Collectors.toList()); // 随机执行结果 Integer result = threadPoolExecutor.invokeAny(tasks); System.out.println("-------------------"); System.out.println(result); threadPoolExecutor.shutdownNow();&#125; 启动程序，输出如下： ThreadPoolExecutor的invokeAll则是执行任务集合中的所有任务，返回Future集合： 1234567891011121314151617181920212223public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 5, 3, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.AbortPolicy() ); List&lt;Callable&lt;Integer&gt;&gt; tasks = IntStream.range(0, 4).boxed().map(i -&gt; (Callable&lt;Integer&gt;) () -&gt; &#123; TimeUnit.SECONDS.sleep(ThreadLocalRandom.current().nextInt(5)); return i; &#125;).collect(Collectors.toList()); List&lt;Future&lt;Integer&gt;&gt; futureList = threadPoolExecutor.invokeAll(tasks); futureList.stream().map(f-&gt;&#123; try &#123; return f.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; return null; &#125; &#125;).forEach(System.out::println); threadPoolExecutor.shutdownNow();&#125; 输出如下： 总结下这些方法： 方法 描述 allowCoreThreadTimeOut(boolean value) 是否允许核心线程空闲后超时，是的话超时后核心线程将销毁，线程池自动关闭 awaitTermination(long timeout, TimeUnit unit) 阻塞当前线程，等待线程池关闭，timeout用于指定等待时间。 execute(Runnable command) 向线程池提交任务，没有返回值 submit(Runnable task) 向线程池提交任务，返回Future isShutdown() 判断线程池是否为shutdown状态 isTerminating() 判断线程池是否正在关闭 isTerminated() 判断线程池是否已经关闭 remove(Runnable task) 移除线程队列中的指定任务 prestartCoreThread() 提前让一个核心线程处于活跃状态，等待执行任务 prestartAllCoreThreads() 提前让所有核心线程处于活跃状态，等待执行任务 getActiveCount() 获取线程池活跃线程数 getCorePoolSize() 获取线程池核心线程数 threadPoolExecutor.getQueue() 获取线程池线程队列 getMaximumPoolSize() 获取线程池最大线程数 shutdown() 让线程池处于shutdown状态，不再接收任务，等待所有正在运行中的任务结束后，关闭线程池。 shutdownNow() 让线程池处于stop状态，不再接受任务，尝试打断正在运行中的任务，并关闭线程池，返回线程队列中的任务。 转载:https://mrbird.cc/Java-Thread-Pool.html]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>JUC</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git标签管理]]></title>
    <url>%2F2019%2F08%2F11%2FGit%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[创建标签(tag)在Git中打标签非常简单，首先，切换到需要打标签的分支上： 12345$ git branch* dev master$ git checkout masterSwitched to branch 'master' 然后，敲命令git tag &lt;name&gt;就可以打一个新标签： 1$ git tag v1.0 可以用命令git tag查看所有标签： 12$ git tagv1.0 默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？ 方法是找到历史提交的commit id，然后打上就可以了： 12345678910111213141516$ git log --pretty=oneline --abbrev-commit12a631b (HEAD -&gt; master, tag: v1.0, origin/master) merged bug fix 1014c805e2 fix bug 101e1e9c68 merge with no-fff52c633 add mergecf810e4 conflict fixed5dc6824 &amp; simple14096d0 AND simpleb17d20e branch testd46f35e remove test.txtb84166e add test.txt519219b git tracks changese43a48b understand how stage works1094adb append GPLe475afc add distributedeaadf4e wrote a readme file 比方说要对add merge这次提交打标签，它对应的commit id是f52c633，敲入命令： 1$ git tag v0.9 f52c633 再用命令git tag查看标签： 123$ git tagv0.9v1.0 注意，标签不是按时间顺序列出，而是按字母排序的。可以用git show &lt;tagname&gt;查看标签信息： 123456789$ git show v0.9commit f52c63349bc3c1593499807e5c8e972b82c8f286 (tag: v0.9)Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:56:54 2018 +0800 add mergediff --git a/readme.txt b/readme.txt... 可以看到，v0.9确实打在add merge这次提交上。 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字： 1$ git tag -a v0.1 -m "version 0.1 released" 1094adb 用命令git show &lt;tagname&gt;可以看到说明文字： 123456789101112131415$ git show v0.1tag v0.1Tagger: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 22:48:43 2018 +0800version 0.1 releasedcommit 1094adb7b9b3807259d8cb349e7df1d4d6477073 (tag: v0.1)Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:06:15 2018 +0800 append GPLdiff --git a/readme.txt b/readme.txt... 注意：标签总是和某个commit挂钩。如果这个commit既出现在master分支，又出现在dev分支，那么在这两个分支上都可以看到这个标签 小结 命令git tag &lt;tagname&gt;用于新建一个标签，默认为HEAD，也可以指定一个commit id； 命令git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;可以指定标签信息； 命令git tag可以查看所有标签。 操作标签如果标签打错了，也可以删除： 12$ git tag -d v0.1Deleted tag 'v0.1' (was f15b0dd) 因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。 如果要推送某个标签到远程，使用命令git push origin &lt;tagname&gt;： 1234$ git push origin v1.0Total 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v1.0 -&gt; v1.0 或者，一次性推送全部尚未推送到远程的本地标签： 1234$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v0.9 -&gt; v0.9 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除： 12$ git tag -d v0.9Deleted tag 'v0.9' (was f52c633) 然后，从远程删除。删除命令也是push，但是格式如下： 123$ git push origin :refs/tags/v0.9To github.com:michaelliao/learngit.git - [deleted] v0.9 要看看是否真的从远程库删除了标签，可以登陆GitHub查看。 小结 命令git push origin &lt;tagname&gt;可以推送一个本地标签； 命令git push origin --tags可以推送全部未推送过的本地标签； 命令git tag -d &lt;tagname&gt;可以删除一个本地标签； 命令git push origin :refs/tags/&lt;tagname&gt;可以删除一个远程标签。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git多人协作]]></title>
    <url>%2F2019%2F08%2F11%2FGit%E5%A4%9A%E4%BA%BA%E5%8D%8F%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。 要查看远程库的信息，用git remote： 12$ git remoteorigin 或者，用git remote -v显示更详细的信息： 123$ git remote -vorigin git@github.com:michaelliao/learngit.git (fetch)origin git@github.com:michaelliao/learngit.git (push) 上面显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址。 推送分支推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上： 1$ git push origin master 如果要推送其他分支，比如dev，就改成： 1$ git push origin dev 但是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？ master分支是主分支，因此要时刻与远程同步； dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步； bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug； feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。 总之，就是在Git中，分支完全可以在本地自己藏着玩，是否推送，视你的心情而定！ 抓取分支多人协作时，大家都会往master和dev分支上推送各自的修改。 现在，模拟一个你的小伙伴，可以在另一台电脑（注意要把SSH Key添加到GitHub）或者同一台电脑的另一个目录下克隆： 1234567$ git clone git@github.com:michaelliao/learngit.gitCloning into &apos;learngit&apos;...remote: Counting objects: 40, done.remote: Compressing objects: 100% (21/21), done.remote: Total 40 (delta 14), reused 40 (delta 14), pack-reused 0Receiving objects: 100% (40/40), done.Resolving deltas: 100% (14/14), done. 当你的小伙伴从远程库clone时，默认情况下，你的小伙伴只能看到本地的master分支。不信可以用git branch命令看看： 12$ git branch* master 现在，你的小伙伴要在dev分支上开发，就必须创建远程origin的dev分支到本地，于是他用这个命令创建本地dev分支： 在，你的小伙伴要在dev分支上开发，就必须创建远程origin的dev分支到本地，于是他用这个命令创建本地dev分支： 1$ git checkout -b dev origin/dev 现在，他就可以在dev上继续修改，然后，时不时地把dev分支push到远程： 123456789101112131415$ git add env.txt$ git commit -m "add env"[dev 7a5e5dd] add env 1 file changed, 1 insertion(+) create mode 100644 env.txt$ git push origin devCounting objects: 3, done.Delta compression using up to 4 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 308 bytes | 308.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git f52c633..7a5e5dd dev -&gt; dev 你的小伙伴已经向origin/dev分支推送了他的提交，而碰巧你也对同样的文件作了修改，并试图推送： 123456789101112131415161718$ cat env.txtenv$ git add env.txt$ git commit -m "add new env"[dev 7bd91f1] add new env 1 file changed, 1 insertion(+) create mode 100644 env.txt$ git push origin devTo github.com:michaelliao/learngit.git ! [rejected] dev -&gt; dev (non-fast-forward)error: failed to push some refs to 'git@github.com:michaelliao/learngit.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 推送失败，因为你的小伙伴的最新提交和你试图推送的提交有冲突，解决办法也很简单，Git已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后，在本地合并，解决冲突，再推送： 12345678910$ git pullThere is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt;If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=origin/&lt;branch&gt; dev git pull也失败了，原因是没有指定本地dev分支与远程origin/dev分支的链接，根据提示，设置dev和origin/dev的链接： 12$ git branch --set-upstream-to=origin/dev devBranch 'dev' set up to track remote branch 'dev' from 'origin'. 再pull： 1234$ git pullAuto-merging env.txtCONFLICT (add/add): Merge conflict in env.txtAutomatic merge failed; fix conflicts and then commit the result. 这回git pull成功，但是合并有冲突，需要手动解决，解决的方法和分支管理中的解决冲突完全一样。解决后，提交，再push： 1234567891011$ git commit -m "fix env conflict"[dev 57c53ab] fix env conflict$ git push origin devCounting objects: 6, done.Delta compression using up to 4 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (6/6), 621 bytes | 621.00 KiB/s, done.Total 6 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git 7a5e5dd..57c53ab dev -&gt; dev 因此，多人协作的工作模式通常是这样： 首先，可以试图用git push origin &lt;branch-name&gt;推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送就能成功！ 如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;。 这就是多人协作的工作模式，一旦熟悉了，就非常简单。 小结 查看远程库信息，使用git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch --set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git中Feature分支]]></title>
    <url>%2F2019%2F08%2F11%2FGit%E4%B8%ADFeature%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[软件开发中，总有无穷无尽的新的功能要不断添加进来。 添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 现在，你终于接到了一个新任务：开发代号为Vulcan的新功能，该功能计划用于下一代星际飞船。 于是准备开发： 12$ git checkout -b feature-vulcanSwitched to a new branch 'feature-vulcan' 5分钟后，开发完毕： 12345678910111213$ git add vulcan.py$ git statusOn branch feature-vulcanChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: vulcan.py$ git commit -m &quot;add feature vulcan&quot;[feature-vulcan 287773e] add feature vulcan 1 file changed, 2 insertions(+) create mode 100644 vulcan.py 切回dev，准备合并： 1$ git checkout dev 一切顺利的话，feature分支和bug分支是类似的，合并，然后删除。 但是！就在此时，接到上级命令，因经费不足，新功能必须取消！虽然白干了，但是这个包含机密资料的分支还是必须就地销毁： 123$ git branch -d feature-vulcanerror: The branch 'feature-vulcan' is not fully merged.If you are sure you want to delete it, run 'git branch -D feature-vulcan'. 销毁失败。Git友情提醒，feature-vulcan分支还没有被合并，如果删除，将丢失掉修改，如果要强行删除，需要使用大写的-D参数。。 现在我们强行删除： 12$ git branch -D feature-vulcanDeleted branch feature-vulcan (was 287773e). 终于删除成功！ 小结开发一个新feature，最好新建一个分支； 如果要丢弃一个没有被合并过的分支，可以通过git branch -D &lt;name&gt;强行删除。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git中bug分支]]></title>
    <url>%2F2019%2F08%2F11%2FGit%E4%B8%ADbug%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[Bug分支软件开发中，bug就像家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。 当你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支issue-101来修复它，但是，等等，当前正在dev上进行的工作还没有提交： 123456789101112$ git statusOn branch devChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: hello.pyChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txt 并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？ 幸好，Git还提供了一个stash功能(该命令需要文件被加入缓存区，即add过后)，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作： 123456## 先add文件$ git add filename$ git stash## 记录工作目录和索引的当前状态,但是想要返回到干净目录,保存了本地修改,并恢复工作目录## 以匹配HEAD提交Saved working directory and index state WIP on dev: f52c633 add merge 命令介绍 1234567891011121314### 查看储藏修改git stash list [&lt;options&gt;]### 储藏的列表进行检查git stash show [&lt;stash&gt;]### 重新应用储藏git stash ( pop | apply ) [--index] [-q|--quiet] [&lt;stash&gt;]git stash branch &lt;branchname&gt; [&lt;stash&gt;]### git stash相当于git stash save,默认情况下,储藏列表为"分支名称的WIP"### stash@&#123;0&#125;是最近创建的垃圾邮件,stash@&#123;1&#125;依次内推git stash save [-p|--patch] [-k|--[no-]keep-index] [-q|--quiet] [-u|--include-untracked] [-a|--all] [&lt;message&gt;]git stash [push [-p|--patch] [-k|--[no-]keep-index] [-q|--quiet] [-u|--include-untracked] [-a|--all] [-m|--message &lt;message&gt;]] [--] [&lt;pathspec&gt;…​]] 现在，用git status查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心地创建分支来修复bug。 首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支： 1234567$ git checkout masterSwitched to branch 'master'Your branch is ahead of 'origin/master' by 6 commits. (use "git push" to publish your local commits)$ git checkout -b issue-101Switched to a new branch 'issue-101' 现在修复bug，需要把“Git is free software …”改为“Git is a free software …”，然后提交： 1234$ git add readme.txt $ git commit -m "fix bug 101"[issue-101 4c805e2] fix bug 101 1 file changed, 1 insertion(+), 1 deletion(-) 修复完成后，切换到master分支，并完成合并，最后删除issue-101分支： 123456789$ git checkout masterSwitched to branch 'master'Your branch is ahead of 'origin/master' by 6 commits. (use "git push" to publish your local commits)$ git merge --no-ff -m "merged bug fix 101" issue-101Merge made by the 'recursive' strategy. readme.txt | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) 太棒了，原计划两个小时的bug修复只花了5分钟！现在，是时候接着回到dev分支干活了！ 123456$ git checkout devSwitched to branch 'dev'$ git statusOn branch devnothing to commit, working tree clean 工作区是干净的，刚才的工作现场存到哪去了？用git stash list命令看看： 12$ git stash liststash@&#123;0&#125;: WIP on dev: f52c633 add merge 工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，有两个办法： 一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除； 另一种方式是用git stash pop，恢复的同时把stash内容也删了： 1234567891011121314$ git stash popOn branch devChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: hello.pyChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txtDropped refs/stash@&#123;0&#125; (5d677e2ee266f39ea296182fb2354265b91b3b2a) 再用git stash list查看，就看不到任何stash内容了： 1$ git stash list 你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令： 1$ git stash apply stash@&#123;0&#125; 小结修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除； 当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git rebase命令实战]]></title>
    <url>%2F2019%2F08%2F10%2FGit-rebase%E5%91%BD%E4%BB%A4%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[多人在同一个分支上协作时，很容易出现冲突。即使没有冲突，后push的童鞋不得不先pull，在本地合并，然后才能push成功。 每次合并再push后，分支变成了这样： 12345678910111213141516171819$ git log --graph --pretty=oneline --abbrev-commit* d1be385 (HEAD -&gt; master, origin/master) init hello* e5e69f1 Merge branch 'dev'|\ | * 57c53ab (origin/dev, dev) fix env conflict| |\ | | * 7a5e5dd add env| * | 7bd91f1 add new env| |/ * | 12a631b merged bug fix 101|\ \ | * | 4c805e2 fix bug 101|/ / * | e1e9c68 merge with no-ff|\ \ | |/ | * f52c633 add merge|/ * cf810e4 conflict fixed 总之看上去很乱，有强迫症的童鞋会问：为什么Git的提交历史不能是一条干净的直线？ 其实是可以做到的！ Git有一种称为rebase的操作，有人把它翻译成“变基”。 先不要随意展开想象。我们还是从实际问题出发，看看怎么把分叉的提交变成直线。 在和远程分支同步后，我们对hello.py这个文件做了两次提交。用git log命令看看： 1234567891011$ git log --graph --pretty=oneline --abbrev-commit* 582d922 (HEAD -&gt; master) add author* 8875536 add comment* d1be385 (origin/master) init hello* e5e69f1 Merge branch 'dev'|\ | * 57c53ab (origin/dev, dev) fix env conflict| |\ | | * 7a5e5dd add env| * | 7bd91f1 add new env... 注意到Git用(HEAD -&gt; master)和(origin/master)标识出当前分支的HEAD和远程origin的位置分别是582d922 add author和d1be385 init hello，本地分支比远程分支快两个提交。 现在我们尝试推送本地分支： 123456789$ git push origin masterTo github.com:michaelliao/learngit.git ! [rejected] master -&gt; master (fetch first)error: failed to push some refs to 'git@github.com:michaelliao/learngit.git'hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 很不幸，失败了，这说明有人先于我们推送了远程分支。按照经验，先pull一下： 123456789101112$ git pullremote: Counting objects: 3, done.remote: Compressing objects: 100% (1/1), done.remote: Total 3 (delta 1), reused 3 (delta 1), pack-reused 0Unpacking objects: 100% (3/3), done.From github.com:michaelliao/learngit d1be385..f005ed4 master -&gt; origin/master * [new tag] v1.0 -&gt; v1.0Auto-merging hello.pyMerge made by the 'recursive' strategy. hello.py | 1 + 1 file changed, 1 insertion(+) 再用git status看看状态： 123456$ git statusOn branch masterYour branch is ahead of 'origin/master' by 3 commits. (use "git push" to publish your local commits)nothing to commit, working tree clean 加上刚才合并的提交，现在我们本地分支比远程分支超前3个提交。 用git log看看： 123456789$ git log --graph --pretty=oneline --abbrev-commit* e0ea545 (HEAD -&gt; master) Merge branch &apos;master&apos; of github.com:michaelliao/learngit|\ | * f005ed4 (origin/master) set exit=1* | 582d922 add author* | 8875536 add comment|/ * d1be385 init hello... 对强迫症童鞋来说，现在事情有点不对头，提交历史分叉了。如果现在把本地分支push到远程，有没有问题？不好看。 这个时候，rebase就派上了用场。我们输入命令git rebase试试： 123456789101112$ git rebaseFirst, rewinding head to replay your work on top of it...Applying: add commentUsing index info to reconstruct a base tree...M hello.pyFalling back to patching base and 3-way merge...Auto-merging hello.pyApplying: add authorUsing index info to reconstruct a base tree...M hello.pyFalling back to patching base and 3-way merge...Auto-merging hello.py 输出了一大堆操作，到底是啥效果？再用git log看看： 123456$ git log --graph --pretty=oneline --abbrev-commit* 7e61ed4 (HEAD -&gt; master) add author* 3611cfe add comment* f005ed4 (origin/master) set exit=1* d1be385 init hello... 原本分叉的提交现在变成一条直线了！这种神奇的操作是怎么实现的？其实原理非常简单。我们注意观察，发现Git把我们本地的提交“挪动”了位置，放到了f005ed4 (origin/master) set exit=1之后，这样，整个提交历史就成了一条直线。rebase操作前后，最终的提交内容是一致的，但是，我们本地的commit修改内容已经变化了，它们的修改不再基于d1be385 init hello，而是基于f005ed4 (origin/master) set exit=1，但最后的提交7e61ed4内容是一致的。 这就是rebase操作的特点：把分叉的提交历史“整理”成一条直线，看上去更直观。缺点是本地的分叉提交已经被修改过了。 最后，通过push操作把本地分支推送到远程： 123456789Mac:~/learngit michael$ git push origin masterCounting objects: 6, done.Delta compression using up to 4 threads.Compressing objects: 100% (5/5), done.Writing objects: 100% (6/6), 576 bytes | 576.00 KiB/s, done.Total 6 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), completed with 1 local object.To github.com:michaelliao/learngit.git f005ed4..7e61ed4 master -&gt; master 再用git log看看效果： 123456$ git log --graph --pretty=oneline --abbrev-commit* 7e61ed4 (HEAD -&gt; master, origin/master) add author* 3611cfe add comment* f005ed4 set exit=1* d1be385 init hello... 远程分支的提交历史也是一条直线。 小结 rebase操作可以把本地未push的分叉提交历史整理成直线； rebase的目的是使得我们在查看历史提交的变化时更容易，因为分叉的提交需要三方对比。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git命令总结]]></title>
    <url>%2F2019%2F08%2F10%2FGit%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Git命令文档]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git差异和冲突解决]]></title>
    <url>%2F2019%2F08%2F10%2FGit%E5%B7%AE%E5%BC%82%E5%92%8C%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[Git差异和冲突解决Git冲突解决人生不如意之事十之八九，合并分支往往也不是一帆风顺的。 准备新的feature1分支，继续我们的新分支开发： 12$ git checkout -b feature1Switched to a new branch 'feature1' 修改readme.txt最后一行，改为： 1Creating a new branch is quick AND simple. 在feature1分支上提交： 12345$ git add readme.txt$ git commit -m "AND simple"[feature1 14096d0] AND simple 1 file changed, 1 insertion(+), 1 deletion(-) 切换到master分支： 1234$ git checkout masterSwitched to branch 'master'Your branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits) Git还会自动提示我们当前master分支比远程的master分支要超前1个提交。 在master分支上把readme.txt文件的最后一行改为： 1Creating a new branch is quick &amp; simple. 提交： 1234$ git add readme.txt $ git commit -m "&amp; simple"[master 5dc6824] &amp; simple 1 file changed, 1 insertion(+), 1 deletion(-) 现在，master分支和feature1分支各自都分别有新的提交，变成了这样： 这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突，我们试试看： 1234$ git merge feature1Auto-merging readme.txtCONFLICT (content): Merge conflict in readme.txtAutomatic merge failed; fix conflicts and then commit the result. 果然冲突了！Git告诉我们，readme.txt文件存在冲突，必须手动解决冲突后再提交。git status也可以告诉我们冲突的文件： 123456789101112131415$ git statusOn branch masterYour branch is ahead of 'origin/master' by 2 commits. (use "git push" to publish your local commits)You have unmerged paths. (fix conflicts and run "git commit") (use "git merge --abort" to abort the merge)Unmerged paths: (use "git add &lt;file&gt;..." to mark resolution) both modified: readme.txtno changes added to commit (use "git add" and/or "git commit -a") 我们可以直接查看readme.txt的内容： 123456789Git is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，我们修改如下后保存： 1Creating a new branch is quick and simple. 再提交： 123$ git add readme.txt $ git commit -m "conflict fixed"[master cf810e4] conflict fixed 现在，master分支和feature1分支变成了下图所示： 用带参数的git log也可以看到分支的合并情况： 1234567891011121314$ git log --graph --pretty=oneline --abbrev-commit* cf810e4 (HEAD -&gt; master) conflict fixed|\ | * 14096d0 (feature1) AND simple* | 5dc6824 &amp; simple|/ * b17d20e branch test* d46f35e (origin/master) remove test.txt* b84166e add test.txt* 519219b git tracks changes* e43a48b understand how stage works* 1094adb append GPL* e475afc add distributed* eaadf4e wrote a readme file 最后，删除feature1分支： 12$ git branch -d feature1Deleted branch feature1 (was 14096d0) Git差异比较工作目录 vs 暂存区1$ git diff &lt;filename&gt; 意义：查看文件在工作目录与暂存区的差别。如果还没 add 进暂存区，则查看文件自身修改前后的差别。也可查看和另一分支的区别。 1$ git diff &lt;branch&gt; &lt;filename&gt; 暂存区 vs Git仓库(–cached :代表进暂存区,即add过后)1git diff --cached &lt;filename&gt; 意义：表示查看已经 add 进暂存区但是尚未 commit 的内容同最新一次 commit 时的内容的差异。 也可以指定仓库版本： 1git diff --cached &lt;commit&gt; &lt;filename&gt; 工作目录 vs Git仓库1git diff &lt;commit&gt; &lt;filename&gt; 意义：查看工作目录同Git仓库指定 commit 的内容的差异。 &lt;commit&gt;=HEAD 时：查看工作目录同最近一次 commit 的内容的差异。 Git仓库 vs Git仓库1git diff &lt;commit&gt; &lt;commit&gt; 意义：Git仓库任意两次 commit 之间的差别。 扩展以上命令可以不指定 &lt;filename&gt;，则对全部文件操作。 以上命令涉及和 Git仓库 对比的，均可指定 commit 的版本。 HEAD 最近一次 commit HEAD^ 上次提交 HEAD~100 上100次提交 每次提交产生的哈希值]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis Dynamic SQL]]></title>
    <url>%2F2019%2F08%2F07%2FMybatis-Dynamic-SQL%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[钉钉消息推送开发总结]]></title>
    <url>%2F2019%2F08%2F07%2F%E9%92%89%E9%92%89%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%BC%80%E5%8F%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot中的JSON技术]]></title>
    <url>%2F2019%2F08%2F07%2FSpring-Boot%E4%B8%AD%E7%9A%84JSON%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[平日里在项目中处理JSON一般用的都是阿里巴巴的Fastjson，后来发现使用Spring Boot内置的Jackson来完成JSON的序列化和反序列化操作也挺方便。Jackson不但可以完成简单的序列化和反序列化操作，也能实现复杂的个性化的序列化和反序列化操作。 自定义ObjectMapper我们都知道，在Spring中使用@ResponseBody注解可以将方法返回的对象序列化成JSON，比如： 12345678@RequestMapping("getuser")@ResponseBodypublic User getUser() &#123; User user = new User(); user.setUserName("mrbird"); user.setBirthday(new Date()); return user;&#125; User类： 123456789public class User implements Serializable &#123; private static final long serialVersionUID = 6222176558369919436L; private String userName; private int age; private String password; private Date birthday; ...&#125; 访问getuser页面输出： 1&#123;"userName":"mrbird","age":0,"password":null,"birthday":1522634892365&#125; 可看到时间默认以时间戳的形式输出，如果想要改变这个默认行为，我们可以自定义一个ObjectMapper来替代： 12345678910111213141516import java.text.SimpleDateFormat;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.fasterxml.jackson.databind.ObjectMapper;@Configurationpublic class JacksonConfig &#123; @Bean public ObjectMapper getObjectMapper()&#123; ObjectMapper mapper = new ObjectMapper(); mapper.setDateFormat(new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")); return mapper; &#125;&#125; 上面配置获取了ObjectMapper对象，并且设置了时间格式。再次访问getuser，页面输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;age&quot;:0,&quot;password&quot;:null,&quot;birthday&quot;:&quot;2018-04-02 10:14:24&quot;&#125; 序列化Jackson通过使用mapper的writeValueAsString方法将Java对象序列化为JSON格式字符串： 1234567891011121314151617@AutowiredObjectMapper mapper;@RequestMapping("serialization")@ResponseBodypublic String serialization() &#123; try &#123; User user = new User(); user.setUserName("mrbird"); user.setBirthday(new Date()); String str = mapper.writeValueAsString(user); return str; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; 反序列化使用@ResponseBody注解可以使对象序列化为JSON格式字符串，除此之外，Jackson也提供了反序列化方法。 树遍历当采用树遍历的方式时，JSON被读入到JsonNode对象中，可以像操作XML DOM那样读取JSON。比如： 1234567891011121314151617@AutowiredObjectMapper mapper;@RequestMapping("readjsonstring")@ResponseBodypublic String readJsonString() &#123; try &#123; String json = "&#123;\"name\":\"mrbird\",\"age\":26&#125;"; JsonNode node = this.mapper.readTree(json); String name = node.get("name").asText(); int age = node.get("age").asInt(); return name + " " + age; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; readTree方法可以接受一个字符串或者字节数组、文件、InputStream等， 返回JsonNode作为根节点，你可以像操作XML DOM那样操作遍历JsonNode以获取数据。 解析多级JSON例子： 1234String json = "&#123;\"name\":\"mrbird\",\"hobby\":&#123;\"first\":\"sleep\",\"second\":\"eat\"&#125;&#125;";;JsonNode node = this.mapper.readTree(json);JsonNode hobby = node.get("hobby");String first = hobby.get("first").asText(); 绑定对象我们也可以将Java对象和JSON数据进行绑定，如下所示： 1234567891011121314151617@AutowiredObjectMapper mapper;@RequestMapping("readjsonasobject")@ResponseBodypublic String readJsonAsObject() &#123; try &#123; String json = "&#123;\"name\":\"mrbird\",\"age\":26&#125;"; User user = mapper.readValue(json, User.class); String name = user.getUserName(); int age = user.getAge(); return name + " " + age; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; Jackson注解Jackson包含了一些实用的注解： @JsonProperty@JsonProperty，作用在属性上，用来为JSON Key指定一个别名。 1@JsonProperty("bth")private Date birthday; 再次访问getuser页面输出： 1&#123;"userName":"mrbird","age":0,"password":null,"bth":"2018-04-02 10:38:37"&#125; key birthday已经被替换为了bth。 @Jsonlgnore@Jsonlgnore，作用在属性上，用来忽略此属性。 1@JsonIgnoreprivate String password; 再次访问getuser页面输出： 1&#123;"userName":"mrbird","age":0,"bth":"2018-04-02 10:40:45"&#125; password属性已被忽略。 @JsonIgnoreProperties@JsonIgnoreProperties，忽略一组属性，作用于类上，比如JsonIgnoreProperties({ &quot;password&quot;, &quot;age&quot; })。 1234@JsonIgnoreProperties(&#123; "password", "age" &#125;)public class User implements Serializable &#123; ...&#125; 再次访问getuser页面输出： 1&#123;"userName":"mrbird","bth":"2018-04-02 10:45:34"&#125; @JsonFormat@JsonFormat，用于日期格式化，如： 12@JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss")private Date birthday; @JsonNaming@JsonNaming，用于指定一个命名策略，作用于类或者属性上。Jackson自带了多种命名策略，你可以实现自己的命名策略，比如输出的key 由Java命名方式转为下面线命名方法 —— userName转化为user-name。 1234@JsonNaming(PropertyNamingStrategy.LowerCaseWithUnderscoresStrategy.class)public class User implements Serializable &#123; ...&#125; 再次访问getuser页面输出： 1&#123;"user_name":"mrbird","bth":"2018-04-02 10:52:12"&#125; @JsonSerialize@JsonSerialize，指定一个实现类来自定义序列化。类必须实现JsonSerializer接口，代码如下： 123456789101112131415161718import java.io.IOException;import com.example.pojo.User;import com.fasterxml.jackson.core.JsonGenerator;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonSerializer;import com.fasterxml.jackson.databind.SerializerProvider;public class UserSerializer extends JsonSerializer&lt;User&gt; &#123; @Override public void serialize(User user, JsonGenerator generator, SerializerProvider provider) throws IOException, JsonProcessingException &#123; generator.writeStartObject(); generator.writeStringField("user-name", user.getUserName()); generator.writeEndObject(); &#125;&#125; 上面的代码中我们仅仅序列化userName属性，且输出的key是user-name。 使用注解@JsonSerialize来指定User对象的序列化方式： 1234@JsonSerialize(using = UserSerializer.class)public class User implements Serializable &#123; ...&#125; 再次访问getuser页面输出： 1&#123;"user-name":"mrbird"&#125; @JsonDeserialize@JsonDeserialize，用户自定义反序列化，同@JsonSerialize ，类需要实现JsonDeserializer接口。 123456789101112131415161718192021import java.io.IOException;import com.example.pojo.User;import com.fasterxml.jackson.core.JsonParser;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.DeserializationContext;import com.fasterxml.jackson.databind.JsonDeserializer;import com.fasterxml.jackson.databind.JsonNode;public class UserDeserializer extends JsonDeserializer&lt;User&gt; &#123; @Override public User deserialize(JsonParser parser, DeserializationContext context) throws IOException, JsonProcessingException &#123; JsonNode node = parser.getCodec().readTree(parser); String userName = node.get("user-name").asText(); User user = new User(); user.setUserName(userName); return user; &#125;&#125; 使用注解@JsonDeserialize来指定User对象的序列化方式： 1234@JsonDeserialize (using = UserDeserializer.class)public class User implements Serializable &#123; ...&#125; 测试： 12345678910111213141516@AutowiredObjectMapper mapper;@RequestMapping("readjsonasobject")@ResponseBodypublic String readJsonAsObject() &#123; try &#123; String json = "&#123;\"user-name\":\"mrbird\"&#125;"; User user = mapper.readValue(json, User.class); String name = user.getUserName(); return name; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; 访问readjsonasobject，页面输出： 1mrbird @JsonView@JsonView，作用在类或者属性上，用来定义一个序列化组。 比如对于User对象，某些情况下只返回userName属性就行，而某些情况下需要返回全部属性。 因此User对象可以定义成如下： 12345678910111213141516171819public class User implements Serializable &#123; private static final long serialVersionUID = 6222176558369919436L; public interface UserNameView &#123;&#125;; public interface AllUserFieldView extends UserNameView &#123;&#125;; @JsonView(UserNameView.class) private String userName; @JsonView(AllUserFieldView.class) private int age; @JsonView(AllUserFieldView.class) private String password; @JsonView(AllUserFieldView.class) private Date birthday; ... &#125; User定义了两个接口类，一个为userNameView，另外一个为AllUserFieldView继承了userNameView接口。这两个接口代表了两个序列化组的名称。属性userName使用了@JsonView(UserNameView.class)，而剩下属性使用了@JsonView(AllUserFieldView.class)。 Spring中Controller方法允许使用@JsonView指定一个组名，被序列化的对象只有在这个组的属性才会被序列化，代码如下： 1234567891011@JsonView(User.UserNameView.class)@RequestMapping("getuser")@ResponseBodypublic User getUser() &#123; User user = new User(); user.setUserName("mrbird"); user.setAge(26); user.setPassword("123456"); user.setBirthday(new Date()); return user;&#125; 访问getuser页面输出： 1&#123;"userName":"mrbird"&#125; 如果将@JsonView(User.UserNameView.class)替换为@JsonView(User.AllUserFieldView.class)，输出： 1&#123;"userName":"mrbird","age":26,"password":"123456","birthday":"2018-04-02 11:24:00"&#125; 因为接口AllUserFieldView继承了接口UserNameView所以userName也会被输出。 集合的反序列化在Controller方法中，可以使用＠RequestBody将提交的JSON自动映射到方法参数上，比如： 12345@RequestMapping("updateuser")@ResponseBodypublic int updateUser(@RequestBody List&lt;User&gt; list)&#123; return list.size();&#125; 上面方法可以接受如下一个JSON请求，并自动映射到User对象上： 1[&#123;"userName":"mrbird","age":26&#125;,&#123;"userName":"scott","age":27&#125;] Spring Boot 能自动识别出List对象包含的是User类，因为在方法中定义的泛型的类型会被保留在字节码中，所以Spring Boot能识别List包含的泛型类型从而能正确反序列化。 有些情况下，集合对象并没有包含泛型定义，如下代码所示，反序列化并不能得到期望的结果。 1234567891011121314@AutowiredObjectMapper mapper;@RequestMapping("customize")@ResponseBodypublic String customize() throws JsonParseException, JsonMappingException, IOException &#123; String jsonStr = "[&#123;\"userName\":\"mrbird\",\"age\":26&#125;,&#123;\"userName\":\"scott\",\"age\":27&#125;]"; List&lt;User&gt; list = mapper.readValue(jsonStr, List.class); String msg = ""; for (User user : list) &#123; msg += user.getUserName(); &#125; return msg;&#125; 访问customize，控制台抛出异常： 1java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to com.example.pojo.User 这是因为在运行时刻，泛型己经被擦除了（不同于方法参数定义的泛型，不会被擦除）。为了提供泛型信息，Jackson提供了JavaType ，用来指明集合类型，将上述方法改为： 123456789101112131415@AutowiredObjectMapper mapper;@RequestMapping("customize")@ResponseBodypublic String customize() throws JsonParseException, JsonMappingException, IOException &#123; String jsonStr = "[&#123;\"userName\":\"mrbird\",\"age\":26&#125;,&#123;\"userName\":\"scott\",\"age\":27&#125;]"; JavaType type = mapper.getTypeFactory().constructParametricType(List.class, User.class); List&lt;User&gt; list = mapper.readValue(jsonStr, type); String msg = ""; for (User user : list) &#123; msg += user.getUserName(); &#125; return msg;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>JSON</tag>
        <tag>Jackson</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git分支管理]]></title>
    <url>%2F2019%2F08%2F07%2FGit%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Git分支管理git branch 命令不仅仅能创建和删除分支，如果不加任何参数，它会给出当前所有的分支清单。 1234$ git branch develop* master test 带 * 表示当前所在分支。使用命令 git branch -v 可以查看各个分支最后一个提交对象的信息： 1234$ git branch -v develop ef993bc update About.html* master 0986092 [ahead 26] update index.html test 19fffc0 add test file 使用命令 git branch –merged 可以查看哪些分支与当前分支进行了合并操作： 123$ git branch --merged develop* master 与之相反的命令为 git branch –no-merged： 12$ git branch --no-merged test test分支中还包含着尚未合并进来的工作成果，所以简单地用git branch -d删除该分支会提示错误，因为那样做会丢失数据： 123$ git branch -d testerror: The branch 'test' is not fully merged.If you are sure you want to delete it, run 'git branch -D test'. Git提示可以用大写的删除选项 -D 强制执行。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git版本回退]]></title>
    <url>%2F2019%2F08%2F07%2FGit%E7%89%88%E6%9C%AC%E5%9B%9E%E9%80%80%2F</url>
    <content type="text"><![CDATA[Git版本回退Git中，每次commit提交都会生成一个历史纪录。使用 git log 查看commit历史： 12345678910$ git log --oneline ec88247 modifyed bar.html,foo.txt add new.txt47384c8 modify bar.html in clone again31e1f6f modify foo.txt in original again8747b24 Merge branch 'master' of /home/mrbird/projects/first-project27b76ec modify foo.txt in original796e40d modify bar.html in clone8e1b132 modify foo.txt,add 'hello msg'94418b1 add bar.html,modify foo.txt,delete bar.txtc2e4810 add foo.txt bar.txt 每个记录都有一个与之对应的commit id，所以可以使用命令 git reset –hard commit-id 来回退到相应的版本。除此之卡，在Git中，使用HEAD来代表当前版本，如需回退到前一个版本，可以使用命令git reset --hard HEAD^，前两个版本则用HEAD~2表示，以此类推。 当前版本id为ec88247…比如，现要回退到commit_id为47384c8…的版本，可以使用如下命令： 12$ git reset --hard 47384c8HEAD is now at 47384c8again modify bar.html in clone 或者 12$ git reset --hard HEAD~1HEAD is now at 47384c8 modify bar.html in clone again 再次查看commit历史 123456789$ git log --oneline 47384c8 modify bar.html in clone again31e1f6f modify foo.txt in original again8747b24 Merge branch 'master' of /home/mrbird/projects/first-project27b76ec modify foo.txt in original796e40d modify bar.html in clone8e1b132 modify foo.txt,add 'hello msg'94418b1 add bar.html,modify foo.txt,delete bar.txtc2e4810 add foo.txt bar.txt 可发现，commit_id为ec88247…的记录已经不见了，如果要回退到这个版本，又忘记了与之对应的commit_id该怎么办呢。这时候可以使用 git reflog 命令来查看操作历史： 1234$ git reflog47384c8 HEAD@&#123;0&#125;: reset: moving to 47384c8ec88247 HEAD@&#123;1&#125;: reset: moving to ec88247... 可看到，回退到commit_id为47384c8…的上一个版本的commit_id为ec88247…，所以，使用如下命令即可回到一开始回退前的版本： 12$ git reset --hard ec88247HEAD is now at ec88247 modifyed bar.html,foo.txt add new.txt Git回退的三种类型: git reset git reset –mixed HEAD~1:回退一个版本,且会将暂存区的内容和本地已提交的内容全部恢复到未暂存的状态,不影响原来本地文件(未提交的也不受影响)。 git reset –soft HEAD~1：回退一个版本,不清空暂存区,将已提交的内容恢复到暂存区,不影响原来本地的文件(未提交的也不受影响) git reset –hard HEAD~1：回退一个版本,清空暂存区,将已提交的内容的版本恢复到本地,本地的文件也将被恢复的版本替换。注意,这种方式是改变本地代码仓库源码。 Git版本回退：reset和revert的区别和使用场景(1):未使用git add缓存代码git checkout – filepathname 进行放弃文件修改。 git checkout . 放弃所有的文件修改。 该命令不会删除掉刚新建的文件。 (2):没有push(本地分支版本回退)这种情况发生在你的本地代码仓库,可能你add ,commit 以后发现代码有点问题,准备取消提交,用到下面命令。 12345//找到需要回退的版本commit idgit reflog// 回退版本git reset [--soft | --mixed | --hardgit reset HEAD &lt;file&gt; (3):已经push(公共远程分支版本)对于已经把代码push到线上仓库,你回退本地代码其实也想同时回退线上代码,回滚到某个指定的版本,线上,线下代码保持一致。你要用到下面的命令。 123git revert HEAD //撤销最近一次提交git revert HEAD~1 //撤销上上次的提交,注意: 数字从0开始。git revert commit_id //撤销commit_id这次提交 git revert用于反转提交,执行evert命令时要求工作树必须是干净的. git revert用一个新提交来消除一个历史提交所做的任何修改. revert 之后你的本地代码会回滚到指定的历史版本,这时你再 git push 既可以把线上的代码更新.(这里不会像reset造成冲突的问题)。 revert 使用,需要先找到你想回滚版本唯一的commit标识代码,可以用 git log 或者在adgit搭建的web环境历史提交记录里查看。通常是前几位即可。 特别注意:不要使用下面方式来回滚公共远程分支版本(使用reset+push -f命令)。因为同事的本地分支并没有主动回退。(如果是一个人开发的，可以这样做) 1234//找到回退的版本git refloggit reset --hard HEAD~1(commit_id)git push -f revert是撤销一次提交,所以后面的commit id是你需要回滚到的版本的前一次提交。 使用revert HEAD是撤销最近的一次提交，如果你最近一次提交是用revert命令产生的，那么你再执行一次，就相当于撤销了上次的撤销操作，换句话说，你连续执行两次revert HEAD命令，就跟没执行是一样的。 使用revert HEAD~1 表示撤销最近2次提交，这个数字是从0开始的，如果你之前撤销过产生了commi id，那么也会计算在内的。 如果使用 revert 撤销的不是最近一次提交，那么一定会有代码冲突，需要你合并代码，合并代码只需要把当前的代码全部去掉，保留之前版本的代码就可以了。 (4):区别git revert是用一次新的commit来回滚之前的commit，git reset是直接删除指定的commit git reset只是在本地仓库中回退版本，而远程仓库版本不会变化。这样，即使本地reset,但是如果在git pull， 那么远程仓库内容又会和本地之前版本内容进行merge。 上面我们说的如果你已经push到线上代码库, reset 删除指定commit以后,你git push可能导致一大堆冲突。但是revert 并不会。 如果在日后现有分支和历史分支需要合并的时候,reset 恢复部分的代码依然会出现在历史分支里。但是revert 方向提交的commit 并不会出现在历史分支里。 reset 是在正常的commit历史中,删除了指定的commit,这时 HEAD 是向后移动了,而 revert 是在正常的commit历史中再commit一次,只不过是反向提交,他的 HEAD 是一直向前的。 (4):实例下面来看一个revert的使用例子 创建A.txt 内容为AAAA。然后添加到git 123git add .git commit -m "A.txt"12 修改A.txt 添加内容”BBBB”。然后添加到git 123git add .git commit -m "A.txt add BBBB"12 此时A.txt文件内容如下 123AAAABBBB12 此时的提交记录： 1234567891011121314git log ---commit 329515ee5d367bda3effa3e8f0c958e98e93ce31Author: *****Date: Tue Mar 6 19:25:39 2018 +0800 A.txt add BBBBcommit fe0d9b1d7ed0176f542a52835b1923584a4ba060Author: *****Date: Tue Mar 6 19:24:34 2018 +0800 A.txt12345678910111213 现在我要撤回内容BBBB，如下 12git revert 3295151 现在A.txt里的文件内容变为： 12AAAA1 再次查看提交记录： 12345678910111213141516171819202122git log---commit 23880e1f7649b7dca14cfda7553b2ff2e6088d6eAuthor: *****Date: Tue Mar 6 19:29:35 2018 +0800 Revert "A.txt add BBBB" This reverts commit 329515ee5d367bda3effa3e8f0c958e98e93ce31.commit 329515ee5d367bda3effa3e8f0c958e98e93ce31Author: *****Date: Tue Mar 6 19:25:39 2018 +0800 A.txt add BBBBcommit fe0d9b1d7ed0176f542a52835b1923584a4ba060Author: *****Date: Tue Mar 6 19:24:34 2018 +0800 A.txt123456789101112131415161718192021 可以看到我们撤回了提交的内容同时增加了一条commit记录。 如果撤回到之前版本出现冲突怎么办？我们先回到329515版本 12git reset --hard 3295151 恢复后在往里面添加内容“CCCC”并提交。此时A.txt文件内容为： 1234AAAABBBBCCCC123 此时的提交记录： 1234567891011121314151617181920git log ---commit f1258438d3b63e78bb747c510f9af3e56be5b3b0Author: *****Date: Tue Mar 6 19:39:20 2018 +0800 A.txt add CCCCcommit 329515ee5d367bda3effa3e8f0c958e98e93ce31Author: *****Date: Tue Mar 6 19:25:39 2018 +0800 A.txt add BBBBcommit fe0d9b1d7ed0176f542a52835b1923584a4ba060Author: *****Date: Tue Mar 6 19:24:34 2018 +0800 A.txt12345678910111213141516171819 然后我们撤回329515的修改 12git revert 3295151 这个时候git提示你有冲突要解决。我们打开A.txt保留parent … 329515这个版本的内容(git add A.txt)，即”AAAA”。并执行以下命令 12git revert --continue1 这个时候git会继续撤回，如果发现冲突会继续提示。此时的提交日志为 1234567891011121314151617181920212223242526commit 78979e45add34a0f009263e49cc1c6c48a0f93d4Author: *****Date: Tue Mar 6 19:46:40 2018 +0800 Revert "A.txt add BBBB" This reverts commit 329515ee5d367bda3effa3e8f0c958e98e93ce31.commit f1258438d3b63e78bb747c510f9af3e56be5b3b0Author: *****Date: Tue Mar 6 19:39:20 2018 +0800 A.txt add CCCCcommit 329515ee5d367bda3effa3e8f0c958e98e93ce31Author: *****Date: Tue Mar 6 19:25:39 2018 +0800 A.txt add BBBBcommit fe0d9b1d7ed0176f542a52835b1923584a4ba060Author: *****Date: Tue Mar 6 19:24:34 2018 +0800 A.txt12345678910111213141516171819202122232425 如果不想解决冲突的话可以取消撤回：git revert --abort。 (5):revert合并代码,解决冲突使用revert命令，如果不是撤销的最近一次提交，那么一定会有冲突，如下所示： 123456&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD全部清空第一次提交=======全部清空&gt;&gt;&gt;&gt;&gt;&gt;&gt; parent of c24cde7... 全部清空 解决冲突很简单，因为我们只想回到某次提交，因此需要把当前最新的代码去掉即可，也就是HEAD标记的代码： 1234&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD全部清空第一次提交======= 把上面部分代码去掉就可以了，然后再提交一次代码就可以解决冲突了。 (6):继续扩展,简单扩展的回滚方法看到这里也许你已经觉得学会了远程仓库版本回滚方法了，但是实践中总是会遇到很多不按套路来的问题，考虑下面一种情况： 如果你们开发中，忽然发现前面很远的地方有一次错误的合并代码，把本来下一次才能发的功能的代码合并到了这一次来了，这个时候全体成员都觉得直接回滚比较快，因为他们都有备份，覆盖了无所谓，这个时候用reset的话对队友的要求比较高，用revert的话呢要大面积的解决冲突，也很麻烦呀，怎么办呢？ 这个时候，可以使用简单粗暴的办法，直接从那个错误的提交的前一次拉取一份代码放到其他目录，然后将master代码全部删除，把那份新代码方进去，然后提交，果然简单粗暴啊，虽然这种方法不入流，但是，实践中发现很好使啊，所以，实践是检验真理的唯一标准。遇到问题还是要灵活应对。 (7): 撤销文件三种情况场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD &lt;file&gt;，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git状态跟踪]]></title>
    <url>%2F2019%2F08%2F07%2FGit%E7%8A%B6%E6%80%81%E8%B7%9F%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[Git状态跟踪对于任何一个文件，在 Git 内都只有三种状态：已提交（committed），已修改（modified）和已暂存（staged）。 1.已提交：表示该文件已经被安全地保存在版本库中了。 2.已修改：表示修改了某个文件，但还没有提交到暂存区。 3.已暂存：表示把已修改的文件已经放到暂存区了，下次提交时一并被保存到版本库中。 检查当前文件状态要确定哪些文件当前处于什么状态，可以用 git status 命令。 1234$ git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.nothing to commit, working tree clean 说明现在的工作目录相当干净，并且当前所在分支为master。 在当前目录下创建一个README文件，然后运行 git status 会看到该文件出现在未跟踪文件列表中： 123456789$ git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) READMEnothing added to commit but untracked files present (use &quot;git add&quot; to track) 未跟踪的文件意味着Git在之前的快照（提交）中没有这些文件。 跟踪新文件使用命令 git add 开始跟踪文件README： 1git add README 再运行 git status 命令，会看到 README 文件已被跟踪，并处于暂存状态： 1234567$ git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README 只要在 “Changes to be committed” 这行下面的，就说明是已暂存状态。git add 后面可以指明要跟踪的文件或目录路径。如果是目录的话，就说明要递归跟踪该目录下的所有文件。 暂存已修改的文件修改已跟踪过的文件 README，然后再次运行 git status 命令： 12345678910111213$ git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: READMEChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README README文件出现了两次，一次是未暂存，一次是一暂存。如果现在提交的话，那么提交的将是已暂存的README，对README的修改并不会被提交。 重新运行 git add 把最新版本README重新暂存起来： 12345678$ git add README$ git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README 忽略某些文件如日志文件，编译缓存文件等没必要纳入Git管理的文件，我们可以创建一个.gitignore文件来将这些文件排除在外。比如： 123$ cat .gitignore*.[oa]*~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。 第二行告诉 Git 忽略所有以波浪符（~）结尾的文件。 文件 .gitignore 的格式规范如下： 所有空行或者以注释符号 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配（glob指shell简化后的正则表达式）。 匹配模式最后跟反斜杠（/）说明要忽略的是目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 例子如下： 12345678910111213# 此为注释 – 将被 Git 忽略# 忽略所有 .a 结尾的文件*.a# 但 lib.a 除外!lib.a# 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO/TODO# 忽略 build/ 目录下的所有文件build/# 会忽略 doc/notes.txt 但不包括 doc/server/arch.txtdoc/*.txt# ignore all .txt files in the doc/ directorydoc/**/*.txt 查看已暂存和未暂存的更新再次修改README文件，但不添加到暂存区。现在README已经修改了两次，第一次添加内容“hello git”并且使用 git add 添加到了暂存区。第二次添加内容“hello world”，但并未添加到暂存区。 若要看已经暂存起来的文件和上次提交时的快照之间的差异，可以用 git diff –staged 命令： 12345678$ git diff --stageddiff --git a/README b/READMEnew file mode 100644index 0000000..8d0e412--- /dev/null+++ b/README@@ -0,0 +1 @@+hello git 直接使用 git diff 命令查看已暂存和未暂存文件之间的差异： 12345678$ git diffdiff --git a/README b/READMEindex 8d0e412..05fe86c 100644--- a/README+++ b/README@@ -1 +1,2 @@ hello git+hello world 可看到，对于README文件来说，未暂存和已暂存文件相比，添加了一行“hello world”。 提交更新使用 git commit -m 命令来提交更新 1234$ git commit -m &apos;创建README文件，内容为hello git&apos;[master 1f9882d] 创建README文件，内容为hello git 1 file changed, 1 insertion(+) create mode 100644 README 跳过暂存区假如你觉得 git add 过程繁琐，可以使用 git commit -a 命令来跳过添加文件到暂存区的步骤，直接提交。 比如，对于README的第二次修改，我们还未将其添加到暂存区，所以第一次使用 git commit 命令只是提交了对README文件的第一次修改。 1234567891011$ git statusOn branch masterYour branch is ahead of &apos;origin/master&apos; by 1 commit. (use &quot;git push&quot; to publish your local commits)Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: READMEno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 使用 git commit -a 命令直接将README文件的第二次修改提交到版本库： 123$ git commit -a -m &quot;添加hello world&quot;[master db06721] 添加hello world 1 file changed, 1 insertion(+) 移除文件移除文件分为两种情况：从版本库和本地工作目录中移除；仅从版本库移除。 1.从版本库和本地工作目录中移除。使用 git rm 命令来移除README: 123456$ git rm READMErm &apos;README&apos;$ git commit -m &apos;删除README&apos;[master 99a0462] 删除README 1 file changed, 3 deletions(-) delete mode 100644 README 到本地工作目录下查看，会发现README文件已经不存在了。 这里有种情况，假如README文件还在暂存区并未提交，使用 git rm 命令将会出错： 1234$ git rm READMEerror: the following file has changes staged in the index: README(use --cached to keep the file, or -f to force removal) Git提示我们使用 git rm -f 命令来删除。 12$ git rm -f temp.logrm &apos;temp.log&apos; 2.仅从版本库移除。 比如现在不小心将temp.log文件添加并提交到版本库中了： 12345$ git add temp.log$ git commit -m &quot;add temp.log&quot;[master fa31ea5] add temp.log 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 temp.log 现在想将其从版本库中删除，但并不删除本地文件，而是随后将其添加到.gitignore文件中，可以使用命令 git rm –cached： 1234567$ git rm --cached temp.logrm &apos;temp.log&apos;$ git commit -m &quot;delete temp.log&quot;[master e512a82] delete temp.log 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 temp.log 移动文件（重命名）git mv 命令用来重命名文件，比如将REAME文件重命名为README.config： 123456789$ git mv README README.config$ git statusOn branch masterYour branch is ahead of 'origin/master' by 7 commits. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) renamed: README -&gt; README.config 其过程类似于： 123$ mv README README.config$ git rm README$ git add README.config]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git撤销操作]]></title>
    <url>%2F2019%2F08%2F07%2FGit%E6%92%A4%E9%94%80%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Git撤销操作修改最后一次提交如果提交后发现想要修改提交信息，可以直接使用 git commit –amend，使用该命令后，Git会启动文本编辑器，然后可看到上次提交时的说明，编辑它确认没问题后保存退出，就会使用新的提交说明覆盖刚才的提交信息： 1$ git commit --amend 如果刚才提交时忘了暂存某些修改，可以先补上暂存操作，然后再运行 --amend 提交： 12$ git add forgotten_file$ git commit --amend 取消已经暂存的文件123456789$ git statusOn branch masterYour branch is ahead of 'origin/master' by 8 commits. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: README.config modified: README.md 使用命令 git reset HEAD README.config 将README.config移出暂存区： 123456789101112131415161718$ git reset HEAD README.configUnstaged changes after reset:M README.config$ git statusOn branch masterYour branch is ahead of 'origin/master' by 8 commits. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: README.mdChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.config 可看到，README.config已经为Changes not staged for commit状态。 取消对文件的修改将README.config移出暂存区后，可以进一步使用命令，git checkout – README.config 取消对README.config的修改。 123456789101112131415$ cat README.confighello$ git checkout -- README.config$ git statusOn branch masterYour branch is ahead of 'origin/master' by 8 commits. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: README.md$ cat README.config]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ListenableFuture的使用心得]]></title>
    <url>%2F2019%2F08%2F06%2FListenableFuture%E7%9A%84%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[1.由来​ ListenableFuture是可以监听的Future任务执行情况，是执行成功还是执行失败，并提供响应接口用于对不同结果进行处理。如果异步任务完成自动调用回调函数，减少并发程序复杂度。 ​ Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？ 2.适用场景 如果一个主任务开始执行，然后需要执行各个小任务，并且需要等待返回结果，统一返回给前端，此时Future和ListenableFuture作用几乎差不多，都是通过get()方法阻塞等待每个任务执行完毕返回。 如果一个主任务开始执行，然后执行各个小任务，主任务不需要等待每个小任务执行完，不需要每个小任务的结果，此时用ListenableFuture非常合适，它提供的FutureCallBack接口可以对每个任务的成功或失败单独做出响应。 3.使用示例(1):使用Future示例: 需要阻塞轮训，查看异步任务是否完成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * @author denny.zhang * @ClassName: FutureDemo * @Description: Future多线程并发任务结果归集 * @date 2016年11月4日 下午1:50:32 */public class FutureDemo &#123; public static void main(String[] args) &#123; Long start = System.currentTimeMillis();//开启多线程 ExecutorService exs = Executors.newFixedThreadPool(10); try &#123;//结果集 List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); List&lt;Future&lt;Integer&gt;&gt; futureList = new ArrayList&lt;Future&lt;Integer&gt;&gt;();//1.高速提交10个任务，每个任务返回一个Future入list for (int i = 0; i &lt; 10; i++) &#123; futureList.add(exs.submit(new CallableTask(i + 1))); &#125; Long getResultStart = System.currentTimeMillis(); System.out.println("结果归集开始时间=" + new Date());//2.结果归集，遍历futureList,高速轮询（模拟实现了并发）获取future状态成功完成后获取结果，退出当前循环 for (Future&lt;Integer&gt; future : futureList) &#123; while (true) &#123;//CPU高速轮询：每个future都并发轮循，判断完成状态然后获取结果，这一行，是本实现方案的精髓所在。即有10个future在高速轮询，完成一个future的获取结果，就关闭一个轮询 if (future.isDone() &amp;&amp; !future.isCancelled()) &#123;//获取future成功完成状态，如果想要限制每个任务的超时时间，取消本行的状态判断+future.get(1000*1, TimeUnit.MILLISECONDS)+catch超时异常使用即可。 Integer i = future.get();//获取结果 System.out.println("任务i=" + i + "获取完成!" + new Date()); list.add(i); break;//当前future获取结果完毕，跳出while &#125; else &#123; Thread.sleep(1);//每次轮询休息1毫秒（CPU纳秒级），避免CPU高速轮循耗空CPU---》新手别忘记这个 &#125; &#125; &#125; System.out.println("list=" + list); System.out.println("总耗时=" + (System.currentTimeMillis() - start) + ",取结果归集耗时=" + (System.currentTimeMillis() - getResultStart)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; exs.shutdown(); &#125; &#125; static class CallableTask implements Callable&lt;Integer&gt; &#123; Integer i; public CallableTask(Integer i) &#123; super(); this.i = i; &#125; @Override public Integer call() throws Exception &#123; if (i == 1) &#123; Thread.sleep(3000);//任务1耗时3秒 &#125; else if (i == 5) &#123; Thread.sleep(5000);//任务5耗时5秒 &#125; else &#123; Thread.sleep(1000);//其它任务耗时1秒 &#125; System.out.println("task线程：" + Thread.currentThread().getName() + "任务i=" + i + ",完成！"); return i; &#125; &#125;&#125; (2):使用**CompletionService，**任务先完成优先获取到，结果按照任务的完成先后顺序排序。内部通过阻塞队列+FutureTask。 (3):使用ListenableFuture，异步任务完成之后进行回调，不用在主线程进行等待 123456789101112131415161718192021222324252627282930313233// Guava 和 spring4.0public class TestListenableFuture &#123; // 创建线程池 final static ListeningExecutorService service = MoreExecutors.listeningDecorator(Executors.newCachedThreadPool()); public static void main(String[] args) throws Exception &#123; // 任务1 ListenableFuture&lt;Boolean&gt; booleanTask = service.submit(new Callable&lt;Boolean&gt;() &#123; @Override public Boolean call() throws Exception &#123; return true; &#125; &#125;); // 增加回调函数 Futures.addCallback(booleanTask, new FutureCallback&lt;Boolean&gt;() &#123; // 成功处理 @Override public void onSuccess(Boolean result) &#123; System.err.println("BooleanTask: " + result); &#125; // 失败处理 @Override public void onFailure(Throwable t) &#123; &#125; &#125;); // 任务2 ListenableFuture&lt;String&gt; stringTask = service.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return "Hello World"; &#125; &#125;&#125; 4.原理分析(1):Future增加监听机制相关类 ListenableFuture：增加扩展功能使用，addCallback()方法为了支持增加回调函数 ListenableFutureCallback：Future回调函数接口 ListenableFutureTask：FutureTask子类，主要是为了增加回调函数注册和回调函数调用功能。该类重写了done()方法，执行对回调函数队列的调用。 ListenableFutureCallbackRegistry：回调函数注册类，调用addCallback()注册ListenableFutureTask。 (2):ListenableFutureTask该类继承了FutureTask，重写了done()方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Extension of &#123;@link FutureTask&#125; that implements &#123;@link ListenableFuture&#125;. * * @author Arjen Poutsma * @since 4.0 */public class ListenableFutureTask&lt;T&gt; extends FutureTask&lt;T&gt; implements ListenableFuture&lt;T&gt; &#123; // 并发编程,尽量使用final关键字,让变量不可变. private final ListenableFutureCallbackRegistry&lt;T&gt; callbacks = new ListenableFutureCallbackRegistry&lt;&gt;(); /** * Create a new &#123;@code ListenableFutureTask&#125; that will, upon running, * execute the given &#123;@link Callable&#125;. * @param callable the callable task */ public ListenableFutureTask(Callable&lt;T&gt; callable) &#123; super(callable); &#125; /** * Create a &#123;@code ListenableFutureTask&#125; that will, upon running, * execute the given &#123;@link Runnable&#125;, and arrange that &#123;@link #get()&#125; * will return the given result on successful completion. * @param runnable the runnable task * @param result the result to return on successful completion */ public ListenableFutureTask(Runnable runnable, @Nullable T result) &#123; super(runnable, result); &#125; ... ... ... @Override protected void done() &#123; Throwable cause; try &#123; // 成功 T result = get(); this.callbacks.success(result); return; &#125; // 第一处捕获异常 catch (InterruptedException ex) &#123; // 异常,则中断线程 Thread.currentThread().interrupt(); return; &#125; // 第二处捕获异常 catch (ExecutionException ex) &#123; // JUC并发异常,需要捕获ExecutionException异常 cause = ex.getCause(); if (cause == null) &#123; cause = ex; &#125; &#125; // 第三处捕获异常 catch (Throwable ex) &#123; cause = ex; &#125; // 失败添加 this.callbacks.failure(cause); &#125;&#125; (3):ListenableFutureCallbackRegistry：回调函数注册类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class ListenableFutureCallbackRegistry&lt;T&gt; &#123; private final Queue&lt;SuccessCallback&lt;? super T&gt;&gt; successCallbacks = new LinkedList&lt;&gt;(); private final Queue&lt;FailureCallback&gt; failureCallbacks = new LinkedList&lt;&gt;(); private State state = State.NEW; @Nullable private Object result; /** 互斥锁,控制并发变量,这里需要控制线程执行状态。NEW,SUCCESS,FAILURE **/ private final Object mutex = new Object(); public void addCallback(ListenableFutureCallback&lt;? super T&gt; callback) &#123; Assert.notNull(callback, "'callback' must not be null"); synchronized (this.mutex) &#123; switch (this.state) &#123; case NEW: this.successCallbacks.add(callback); this.failureCallbacks.add(callback); break; case SUCCESS: notifySuccess(callback); break; case FAILURE: notifyFailure(callback); break; &#125; &#125; &#125; private void notifySuccess(SuccessCallback&lt;? super T&gt; callback) &#123; try &#123; callback.onSuccess((T) this.result); &#125; catch (Throwable ex) &#123; // Ignore &#125; &#125; private void notifyFailure(FailureCallback callback) &#123; Assert.state(this.result instanceof Throwable, "No Throwable result for failure state"); try &#123; callback.onFailure((Throwable) this.result); &#125; catch (Throwable ex) &#123; // Ignore &#125; &#125; public void addSuccessCallback(SuccessCallback&lt;? super T&gt; callback) &#123; Assert.notNull(callback, "'callback' must not be null"); synchronized (this.mutex) &#123; switch (this.state) &#123; case NEW: this.successCallbacks.add(callback); break; case SUCCESS: notifySuccess(callback); break; &#125; &#125; &#125; public void addFailureCallback(FailureCallback callback) &#123; Assert.notNull(callback, "'callback' must not be null"); synchronized (this.mutex) &#123; switch (this.state) &#123; case NEW: this.failureCallbacks.add(callback); break; case FAILURE: notifyFailure(callback); break; &#125; &#125; &#125; public void success(@Nullable T result) &#123; synchronized (this.mutex) &#123; this.state = State.SUCCESS; this.result = result; SuccessCallback&lt;? super T&gt; callback; while ((callback = this.successCallbacks.poll()) != null) &#123; notifySuccess(callback); &#125; &#125; &#125; public void failure(Throwable ex) &#123; synchronized (this.mutex) &#123; this.state = State.FAILURE; this.result = ex; FailureCallback callback; while ((callback = this.failureCallbacks.poll()) != null) &#123; notifyFailure(callback); &#125; &#125; &#125; private enum State &#123;NEW, SUCCESS, FAILURE&#125;&#125; 5：设计模式运用(1):适配器模式：FutureAdapter(对象适配器,使用聚合的方式)，ListenableFutureAdapter(类适配器,使用继承的方式)。对象适配器：**FutureAdapter** 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public abstract class FutureAdapter&lt;T, S&gt; implements Future&lt;T&gt; &#123; private final Future&lt;S&gt; adaptee; @Nullable private Object result; private State state = State.NEW; private final Object mutex = new Object(); /** * Constructs a new &#123;@code FutureAdapter&#125; with the given adaptee. * @param adaptee the future to delegate to */ protected FutureAdapter(Future&lt;S&gt; adaptee) &#123; Assert.notNull(adaptee, "Delegate must not be null"); this.adaptee = adaptee; &#125; /** * Returns the adaptee. */ protected Future&lt;S&gt; getAdaptee() &#123; return this.adaptee; &#125; ... ... ... @SuppressWarnings("unchecked") @Nullable final T adaptInternal(S adapteeResult) throws ExecutionException &#123; synchronized (this.mutex) &#123; switch (this.state) &#123; ... ... ... case NEW: try &#123; T adapted = adapt(adapteeResult); this.result = adapted; this.state = State.SUCCESS; return adapted; &#125; ... ... ... &#125; &#125; &#125; /** * Adapts the given adaptee's result into T. * @return the adapted result */ @Nullable protected abstract T adapt(S adapteeResult) throws ExecutionException; ... ...&#125; 类适配器：**ListenableFutureAdapter** 12345678910111213141516171819202122232425262728293031323334353637383940public abstract class ListenableFutureAdapter&lt;T, S&gt; extends FutureAdapter&lt;T, S&gt; implements ListenableFuture&lt;T&gt; &#123; /** * Construct a new &#123;@code ListenableFutureAdapter&#125; with the given adaptee. * @param adaptee the future to adapt to */ protected ListenableFutureAdapter(ListenableFuture&lt;S&gt; adaptee) &#123; super(adaptee); &#125; ... ... ... @Override public void addCallback(final SuccessCallback&lt;? super T&gt; successCallback, final FailureCallback failureCallback) &#123; ListenableFuture&lt;S&gt; listenableAdaptee = (ListenableFuture&lt;S&gt;) getAdaptee(); listenableAdaptee.addCallback(new ListenableFutureCallback&lt;S&gt;() &#123; @Override public void onSuccess(@Nullable S result) &#123; T adapted = null; if (result != null) &#123; try &#123; adapted = adaptInternal(result); &#125; ... ... ... &#125; successCallback.onSuccess(adapted); &#125; @Override public void onFailure(Throwable ex) &#123; failureCallback.onFailure(ex); &#125; &#125;); &#125;&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Guava</tag>
        <tag>Spring</tag>
        <tag>并发</tag>
        <tag>ListenableFuture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lamdba表达式学习(Java8)]]></title>
    <url>%2F2019%2F08%2F06%2FLamdba%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AD%A6%E4%B9%A0-Java8%2F</url>
    <content type="text"><![CDATA[1：lamdba语法java8新增了一个操作符-&gt;，称为lambda操作符或箭头操作符，它将lambda表达式分为两部分，箭头之前的是参数，箭头之后的是动作。例如： (Integer n1,Integer n2) -&gt; n1 + n2 这个就相当于 1234&gt; Integer method(Integer n1, Integer n2) &#123;&gt; return n1 + n2;&gt; &#125;&gt; 参数类型可以忽略，可以推断出来。 (n1,n2) -&gt; n1 + n2 如果只有一个参数的话，圆括号也可以省略，像这样 n1 -&gt; n1 * n1 如果没有参数，如下所示： 12&gt; () -&gt; 5; //固定返回5&gt; 箭头符号右侧是动作，除了我们看到的这种单行的形式之外，还可以声明一个代码段作为动作，像下面这样 1234&gt; n -&gt; &#123;&gt; return n * n;&gt; &#125;&gt; 这个代码段可以写的很长很长。如果有返回值的话，需要使用return语句返回。 2:函数接口: FunctionInterface在java中，lambda表达式一定要结合functional interface来使用，functional interface是指一个只包含一个抽象方法的接口，可以包含默认实现default。下面来看一个例子。这是一个functional interface： 123456789101112131415161718192021222324252627@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); /** * Returns a composed &#123;@code Consumer&#125; that performs, in sequence, this * operation followed by the &#123;@code after&#125; operation. If performing either * operation throws an exception, it is relayed to the caller of the * composed operation. If performing this operation throws an exception, * the &#123;@code after&#125; operation will not be performed. * * @param after the operation to perform after this operation * @return a composed &#123;@code Consumer&#125; that performs in sequence this * operation followed by the &#123;@code after&#125; operation * @throws NullPointerException if &#123;@code after&#125; is null */ default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; &#123; accept(t); after.accept(t); &#125;; &#125;&#125; 3:变量捕获说到lambda表达式，有一个话题是绕不开的，就是闭包。但这个问题在java中被简化了好多。这个问题可以分为两种情况来讨论： lambda表达式可以访问到所在的类中定义的字段(filed)，也可以修改这个字段。 lambda表达式可以访问到外层代码块(enclosing scope)中定义的局部变量(local varable)，但不能修改他们，并且，如果一个局部变量在lambda表达式中被读取的话，这个变量必须是final或事实上final（变量赋值以后就不能再任何地方再修改了）。如果在匿名类或 Lambda 表达式中访问的局部变量，如果不是 final 类型的话，编译器自动加上 final 修饰符。 为什么 Lambda 表达式(匿名类) 不能访问非 final 的局部变量呢？ 因为实例变量存在堆中，而局部变量是在栈上分配，Lambda 表达(匿名类) 会在另一个线程中执行。如果在线程中要直接访问一个局部变量，可能线程执行时该局部变量已经被销毁了，而 final 类型的局部变量在 Lambda 表达式(匿名类) 中其实是局部变量的一个拷贝。 4.局部变量类型 (1):对象类型，则对象的引用地址不可改变。 (2):基本类型,，则对象的值不能改变。 123456789101112131415public class App &#123; private int filed1 = 10; void method1() &#123; int varable1 = 10; MyInterface myInterface = n -&gt; &#123; filed1 += 2; //可读取，可修改 int m = varable1; //可读取 //varable1 += 2; //不可修改 return 1; &#125;; //varable1 += 2; //已经在lambda表达式中被读取了，就是final了，不能被修改。 &#125;&#125; 4:方法引用lambda表达式的本质是一个匿名方法，但如果有一个方法的签名（参数列表和返回值）和functional interface的签名一样并且逻辑正好是你需要的，那么你可以使用方法引用的方式来将它赋值给你的functional interface，而无需再编写lambda表达式。 方法引用类型： 静态方法: 语法: ClassName::methodName 12myInterface = MyClass::staticMethod;myInterface.doSomething(5); 实例方法: 语法: instance::methodName 123MyClass myClass = new MyClass();myInterface = myClass::instanceMethod;myInterface.doSomething(5); 泛型方法: 语法：instace::methodName 123MyClass myClass = new MyClass();myInterface = myClass::&lt;integer&gt;genericMethod;myInterface.doSomething(5);&lt;/integer&gt; 构造方法: 语法: ClassName::new 123456789101112131415public class Foo &#123; String msg1, msg2; public Foo(String msg1, String msg2) &#123; this.msg1 = msg1; this.msg2 = msg2; &#125;&#125;interface FooInterface &#123; Foo fooMethod(String m1, String m2);&#125;FooInterface fooInterface = Foo::new;Foo fooObj = fooInterface.fooMethod("hello", "world");]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>lamdba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot配置篇]]></title>
    <url>%2F2019%2F08%2F06%2FSpring-Boot%E9%85%8D%E7%BD%AE%E7%AF%87%2F</url>
    <content type="text"><![CDATA[1:概述SpringBoot支持外部化配置,配置文件格式如下所示: properties files yaml files environment variables command-line arguments 使用外部化配置方式: @Value注解 Environment抽象(Spring环境接口抽象) @ConfigurationProperties PropertySource(文件属性抽象) 2:自定义属性 POM内容如下 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--生成spring-configuration-metadata.json文件,提示属性--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 当使用Spring Boot开发项目时,Spring Boot会默认读取classpath下application.properties application.yml文件,详情请查看源码ConfigFileApplicationListener。这种自定义少量 属性常常通过@Value注解进行加载,但是@Value所在类必须在Spring IOC容器中。 application.yml自定义属性 123hello: user: name: "刘恩源" 读取该属性常常通过@Value注解进行读取。 12345678@Component@Datapublic class HelloUser &#123; //hello.user.name:default==&gt;&gt;表示当时该属性在 //spring Environment没有找到取默认值default @Value("$&#123;hello.user.name:default&#125;") private String userName;&#125; ​ 123456789101112131415161718192021222324/** * 类描述: spring boot config * * @author liuenyuan * @date 2019/6/16 11:36 * @describe * @see org.springframework.beans.factory.annotation.Value * @see org.springframework.context.annotation.PropertySource * @see org.springframework.boot.context.properties.ConfigurationProperties * @see org.springframework.boot.context.properties.EnableConfigurationProperties * @see org.springframework.core.env.Environment * @see org.springframework.context.annotation.Profile * @see org.springframework.context.support.PropertySourcesPlaceholderConfigurer */@SpringBootApplicationpublic class ConfigApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = SpringApplication.run(ConfigApplication.class, args); HelloUser helloUser = context.getBean(HelloUser.class); System.out.println(String.format("通过@Value注解读取自定义的少量属性: %s", helloUser.getUserName())); context.close(); &#125;&#125; @Value注解注入使用情况 转载自:https://www.cnblogs.com/wangbin2188/p/9014837.html 注入普通字符串 注入操作系统属性 注入表达式结果 注入其他Bean属性 注入文件资源 注入URL资源 注入${…}来处理placeholder。 1234567891011121314151617@Value("normal")private String normal; // 注入普通字符串@Value("#&#123;systemProperties['os.name']&#125;")private String systemPropertiesName; // 注入操作系统属性@Value("#&#123; T(java.lang.Math).random() * 100.0 &#125;")private double randomNumber; //注入表达式结果@Value("#&#123;beanInject.another&#125;")private String fromAnotherBean; // 注入其他Bean属性：注入beanInject对象的属性another，类具体定义见下面@Value("classpath:com/hry/spring/configinject/config.txt")private Resource resourceFile; // 注入文件资源@Value("http://www.baidu.com")private Resource testUrl; // 注入URL资源 3:将配置文件属性赋给实体类当有许多配置属性(建议超过5这样),可以将这些属性作为字段来创建一个JavaBean,并将属性赋给他们。例如 在application.yml配置属性如下: person: name: &quot;刘恩源&quot; age: 21 school: &quot;天津师范大学&quot;配置属性类PersonProperties @ConfigurationProperties注解是将properties配置文件转换为bean使用,默认是将application.yml 或者application.properties属性转换成bean使用。@PropertySource只支持properties结尾的文件。 @EnableConfigurationProperties注解的作用是@ConfigurationProperties注解生效,并将属性 配置类注册到Spring IOC容器中。 如果需要加载指定配置文件,可以使用@PropertySource注解。 12345678910111213141516171819202122232425 @ConfigurationProperties(prefix = "person")@Datapublic class PersonProperties &#123; private String name; private Integer age; private String school;&#125;@EnableConfigurationProperties(&#123;PersonProperties.class&#125;)@Configurationpublic class PersonConfiguration &#123; private final PersonProperties personProperties; public PersonConfiguration(PersonProperties personProperties) &#123; this.personProperties = personProperties; System.out.println(String.format("PersonProperties: %s", this.personProperties)); &#125; public PersonProperties getPersonProperties() &#123; return personProperties; &#125;&#125; 4:自定义配置文件上面介绍了读取默认配置文件application.yml|application.properties中的配置属性。当然,我们也可以读取 自定义的配置文件中属性。目前官方使用@PropertySource注解导入自定义的配置文件属性。 建立hello.properties #load config properties person.name=刘恩源 person.age=20 person.school=天津师范大学建立PersonProperties.java 123456789101112//建立声明加载properties配置文件的encoding和name@ConfigurationProperties(prefix = "person")@Data@PropertySource(value = &#123;"classpath:/hello.properties"&#125;, encoding = "UTF-8", name = "hello")public class PersonProperties &#123; private String name; private Integer age; private String school;&#125; 建立PersonConfiguration,使用@EnableConfigurationProperties激活@ConfigurationProperties 注解,将其标注的JavaBean注入到Spring IOC容器中。 1234567891011121314@EnableConfigurationProperties(&#123;PersonProperties.class&#125;)@Configurationpublic class PersonConfiguration &#123; private final PersonProperties personProperties public PersonConfiguration(PersonProperties personProperties) &#123; this.personProperties = personProperties; System.out.println(String.format("PersonProperties: %s", this.personProperties)); &#125; public PersonProperties getPersonProperties() &#123; return personProperties; &#125;&#125; 加载指定yml|yaml文件 配置如下: 1234567891011public class YamlPropertiesConfiguration &#123; @Bean public static PropertySourcesPlaceholderConfigurer properties() &#123; PropertySourcesPlaceholderConfigurer configurer = new PropertySourcesPlaceholderConfigurer(); YamlPropertiesFactoryBean yml = new YamlPropertiesFactoryBean(); yml.setResources(new ClassPathResource("/hello.yml")); configurer.setProperties(yml.getObject()); return configurer; &#125;&#125; 可以参照我实现的自定义注解@YmlPropertySource,加载yml|yaml文件,可以大致实现和@PropertySource 注解同样的功能。 @YmlPropertySource实现加载yml|yaml文件 5:多环境配置在企业开发环境中,需要不同的配置环境.SpringBoot使用spring.profiles.active属性加载不同环境的配置文件,配置文件格式为application-{profile}.properties|yml|yaml。{profile}对应环境标识。 application-test.yml:测试环境 application-dev.yml:开发环境 application.prod:生产环境 可以在springboot默认配置文件application.yml通过配置spring.profiles.active激活环境。也可以在 特定的类使用@Profile注解激活环境。该注解可以使用逻辑运算符。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Spring</tag>
        <tag>外部化配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强大JSON解析工具gson]]></title>
    <url>%2F2019%2F08%2F06%2F%E5%BC%BA%E5%A4%A7JSON%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7gson%2F</url>
    <content type="text"><![CDATA[1:GsonUtils工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * google json utils * **/public class GsonUtils &#123; public static final String DATE_FORMAT="yyyy-MM-dd HH:mm:ss"; /** * get google json * @see Gson * **/ public static Gson getGson() &#123; return (new GsonBuilder()).serializeNulls().setDateFormat(GsonUtils.DATE_FORMAT).create(); &#125; /** * object to json * **/ public static String toJson(Object obj) &#123; return getGson().toJson(obj); &#125; /** * json to type * @see Gson#toJson(Object, Type) * **/ public static String toJson(Object obj, Type type) &#123; return getGson().toJson(obj, type); &#125; /** * generic t to json * **/ public static &lt;T&gt; String t2Json(T t) &#123; return getGson().toJson(t); &#125; /** * json to generic t * **/ public static &lt;T&gt; T json2T(String jsonString, Class&lt;T&gt; clazz) &#123; return getGson().fromJson(jsonString, clazz); &#125; /** * json to collection * **/ public static &lt;T&gt; List&lt;T&gt; json2Collection(String jsonStr, Type type) &#123; return (List&lt;T&gt;) getGson().fromJson(jsonStr, type); &#125; /** * json to type * @see Gson#fromJson(String, Type) * **/ public static &lt;T&gt; T fromJson(String jsonStr, Type type) &#123; return getGson().fromJson(jsonStr, type); &#125; /** * json to class type * **/ public static &lt;T&gt; T fromJson(String jsonStr, Class&lt;T&gt; clazz) &#123; return getGson().fromJson(jsonStr, clazz); &#125;&#125; 1:java bean对象转换成json123456789101112//实体类@Data@AllArgsConstructor@NoArgsConstructorpublic class User &#123; private Integer id; private String name; private Integer age;&#125; 1234@Testpublic void testBean2Json() &#123; System.out.println(GsonUtils.toJson(new User(1, "王旭", 22)));&#125; 2:List对象转换成json1234567891011121314151617181920 //方法1 @Test public void testBeanList2Json() &#123; System.out.println(GsonUtils.toJson(Arrays.asList( new User(1, "王旭", 22), new User(2, "王旭1", 23), new User(3, "王旭2", 24) ) )); &#125;//方法2,指定具体的泛型@Test public void testBeanList2Json2() &#123; System.out.println(GsonUtils.toJson(Arrays.asList( new User(1, "王旭", 22), new User(2, "王旭1", 23), new User(3, "王旭2", 24) ), new TypeToken&lt;List&lt;User&gt;&gt;() &#123; &#125;.getType())); &#125; 3:Map对象转换成json1234567891011private static Map&lt;String, User&gt; userMap = new HashMap&lt;&gt;();static &#123; userMap.put("1", new User(1, "王旭", 22)); userMap.put("2", new User(2, "王旭", 23));&#125;@Testpublic void testMap2Json() &#123; System.out.println(GsonUtils.toJson(userMap));&#125; 4:Json转成java bean对象12345@Testpublic void testJson2Bean() &#123; User user = GsonUtils.fromJson("&#123;\"id\":1,\"name\":\"王旭\",\"age\":22&#125;", User.class); System.out.println(user);&#125; 5:Json转成List对象12345678//TypeToken用来获取转换出来的泛型类型,如果转换成泛型请使用该类 @Test public void testJson2List() &#123; String jsonList = "[&#123;\"id\":1,\"name\":\"王旭\",\"age\":22&#125;,&#123;\"id\":2,\"name\":\"王旭1\",\"age\":23&#125;,&#123;\"id\":3,\"name\":\"王旭2\",\"age\":24&#125;]"; List&lt;User&gt; userList = GsonUtils.fromJson(jsonList, new TypeToken&lt;List&lt;User&gt;&gt;() &#123; &#125;.getType()); System.out.println(userList); &#125; 6:Json转成map对象1234567891011121314151617181920212223//其中,使用TypeToken可以将json转换成对应的Java类型 @Test public void testJson2Map() &#123; TypeToken&lt;Map&lt;String, User&gt;&gt; typeToken = new TypeToken&lt;Map&lt;String, User&gt;&gt;() &#123; &#125;; Map&lt;String, User&gt; map = GsonUtils.fromJson("&#123;\"1\":&#123;\"id\":1,\"name\":\"王旭\",\"age\":22&#125;,\"2\":&#123;\"id\":2,\"name\":\"王旭\",\"age\":23&#125;&#125;", typeToken.getType()); System.out.println(map); &#125;//在转换json的时候//第一步:知道json是什么构造的//第二步:转换出相应的Java类型@Test public void testJson2Map() &#123; TypeToken&lt;TreeMap&lt;String, User&gt;&gt; typeToken = new TypeToken&lt;TreeMap&lt;String, User&gt;&gt;() &#123; &#125;; TreeMap&lt;String, User&gt; map = GsonUtils.fromJson("&#123;\"1\":&#123;\"id\":1,\"name\":\"王旭\",\"age\":22&#125;,\"2\":&#123;\"id\":2,\"name\":\"王旭\",\"age\":23&#125;&#125;", typeToken.getType()); for (Map.Entry&lt;String, User&gt; entry : map.entrySet()) &#123; System.out.println(entry.getKey()+":"+entry.getValue()); &#125; &#125;]]></content>
      <categories>
        <category>json</category>
      </categories>
      <tags>
        <tag>gson</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Request header is too large 的问题解决]]></title>
    <url>%2F2019%2F08%2F06%2FRequest-header-is-too-large-%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[1:问题原因: 后台接受前台传入的内容字符串,由于内容字符串太大,导致打印台报错. 1-1:错误描述: 123456789101112java.lang.IllegalArgumentException: Request header is too large at org.apache.coyote.http11.Http11InputBuffer.fill(Http11InputBuffer.java:701) at org.apache.coyote.http11.Http11InputBuffer.parseRequestLine(Http11InputBuffer.java:455) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:667) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) 1-2:解决方案(服务器容器:tomcat): 1:请求头超过了tomcat的限值。本来post请求是没有参数大小限制，但是服务器有自己的默认大小。2:配置 tomcat的server.xml文件,增加请求字段长度 1234&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; maxHttpHeaderSize=&quot;102400&quot; maxPostSize=&quot;0&quot; URIEncoding=&quot;UTF-8&quot;/&gt; 增加maxHttpHeaderSize参数配置,当maxPostSize=0时,表示不限制. 1-3:SpringBoot项目: 在application.yml文件中,配置server.max-http-header-size=102400参数,即可改变内嵌tomcat容器的最大头大小. 1-4:详细错误原因: 在tomcat的org.apache.coyote.http11.AbstractHttp11Protocol类中定义了其默认值: 12345/** * Maximum size of the HTTP message header. */private int maxHttpHeaderSize = 8 * 1024;//所以当请求头大于8*1024时,就会报错.增对大数据量的请求,需要单独配置maxHttpHeaderSize参数属性.]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>maxHttpHeaderSize</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot中RedisTemplate注意问题]]></title>
    <url>%2F2019%2F08%2F06%2FSpringBoot%E4%B8%ADRedisTemplate%E6%B3%A8%E6%84%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1:ERR value is not an integer or out of range1-1:背景:使用redisTemplate.opsForValue().increment(key, delat)方法。 1-2:分析:redis对任何不合法的值,都称为ERR。只有使用StringRedisSerializer序列化器才能使用incrment或者decrement方法。 1-3:问题解决: GenericJackson2JsonRedisSerializer、Jackson2JsonRedisSerializer是先将对象转为json，然后再保存到redis，所以，1在redis中是字符串1，所以无法进行加1 JdkSerializationRedisSerializer使用的jdk对象序列化，序列化后的值有类信息、版本号等，所以是一个包含很多字母的字符串，所以根本无法加1,这个序列化器跟memcache的序列化规则很像memcache怎样存储的对象 GenericToStringSerializer、StringRedisSerializer将字符串的值直接转为字节数组，所以保存到redis中是数字，所以可以进行加1 1-4:总结: 使用GenericToStringSerializer、StringRedisSerializer序列化器，都可以使用increment方法. 1-5:建议redis key序列化使用StringRedisSerializer,redis value序列化使用Jackson2JsonRedisSerializer。 1234567891011121314151617/** * key redis serializer: &#123;@link StringRedisSerializer&#125; and * key redis serializer: &#123;@link Jackson2JsonRedisSerializer&#125; **/@Bean(name = &quot;genericRedisTemplate&quot;)public RedisTemplate&lt;String, String&gt; redisTemplate3(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, String&gt; template = new RedisTemplate&lt;&gt;(); RedisSerializer valueRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); RedisSerializer keyRedisSerializer = new StringRedisSerializer(); template.setKeySerializer(keyRedisSerializer); template.setValueSerializer(valueRedisSerializer); template.setHashKeySerializer(keyRedisSerializer); template.setHashValueSerializer(valueRedisSerializer); template.setConnectionFactory(factory); template.afterPropertiesSet(); return template;&#125; 2:key前面会有一堆\xac\xed\x00\x05t\x00\tb1-1:背景:使用SpringData对redis进行操作 1-2:分析 分析spring-data的org.springframework.data.redis.core.RedisTemplate源代码以后发现.Spring默认采用defaultSerializer = new JdkSerializationRedisSerializer();来对key,value进行序列化操作，在经过查看JdkSerializationRedisSerializer中对序列化的一系列操作,即默认使用。由于spring操作redis是在jedis客户端基础上进行的，而jedis客户端与redis交互的时候协议中定义是用byte类型交互，jedis中提供了string类型转为byte[]类型.原因其实就出现在这里，解决的办法就是手动定义序列化的方法。 1-3:解决方法: 建议redis key序列化使用StringRedisSerializer,redis value序列化使用Jackson2JsonRedisSerializer. // 使用SpringBoot默认配置的redisTemplate 1234567891011121314151617181920212223242526/** * Standard Redis configuration. */@Configurationprotected static class RedisConfiguration &#123; @Bean @ConditionalOnMissingBean(name = "redisTemplate") public RedisTemplate&lt;Object, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;Object, Object&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; &#125; @Bean @ConditionalOnMissingBean(StringRedisTemplate.class) public StringRedisTemplate stringRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>RedisTemplate</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中RestTemplate的使用]]></title>
    <url>%2F2019%2F08%2F06%2FSpring%E4%B8%ADRestTemplate%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Spring中RestTemplate的使用Get请求1:带参数的Get请求 请求URL示例:http://localhost:8080/test/sendSms?phone=手机号&amp;msg=短信内容 12345678910111213141516//错误使用:@Autowiredprivate RestOperations restOperations;public void test() throws Exception&#123; String url = &quot;http://localhost:8080/test/sendSms&quot;; Map&lt;String, Object&gt; uriVariables = new HashMap&lt;String, Object&gt;(); uriVariables.put(&quot;phone&quot;, &quot;151xxxxxxxx&quot;); uriVariables.put(&quot;msg&quot;, &quot;测试短信内容&quot;); String result = restOperations.getForObject(url, String.class, uriVariables);&#125;**服务器接收的时候你会发现，接收的该请求时没有参数的** 123456789101112131415//正确使用:public void test() throws Exception&#123; String url = &quot;http://localhost:8080/test/sendSms?phone=&#123;phone&#125;&amp;msg=&#123;phone&#125;&quot;; Map&lt;String, Object&gt; uriVariables = new HashMap&lt;String, Object&gt;(); uriVariables.put(&quot;phone&quot;, &quot;151xxxxxxxx&quot;); uriVariables.put(&quot;msg&quot;, &quot;测试短信内容&quot;); String result = restOperations.getForObject(url, String.class, uriVariables);&#125;public void test() throws Exception&#123; String url = &quot;http://localhost:8080/test/sendSms?phone=&#123;phone&#125;&amp;msg=&#123;phone&#125;&quot;; String result = restOperations.getForObject(url, String.class, &quot;151xxxxxxxx&quot;, &quot;测试短信内容&quot;);&#125; 2:Spring提供的Get请求方法 1234567891011&lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;&lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;&lt;T&gt; T getForObject(URI url, Class&lt;T&gt; responseType) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(URI url, Class&lt;T&gt; responseType) throws RestClientException; Post请求1:带参数的POST请求 带参数的URL示例:http://api.map.baidu.com/geodata/v3/poi/create 123456789101112131415161718192021//正确使用: HttpHeaders headers = new HttpHeaders(); MultiValueMap&lt;String, String&gt; createPostParams = new LinkedMultiValueMap&lt;&gt;(16); headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED); createPostParams.add(&quot;ak&quot;, PositionConstants.AK); createPostParams.add(&quot;geotable_id&quot;, PositionConstants.GEOTABLE_ID); createPostParams.add(&quot;coord_type&quot;, PositionConstants.COORD_TYPE); createPostParams.add(&quot;latitude&quot;, String.valueOf(article.getPositionX())); createPostParams.add(&quot;longitude&quot;, String.valueOf(article.getPositionY())); createPostParams.add(&quot;address&quot;, article.getPositionName()); createPostParams.add(&quot;title&quot;, article.getArticleName()); createPostParams.add(&quot;article_img&quot;, articleImg); createPostParams.add(&quot;article_id&quot;, article.getArticleId()); createPostParams.add(&quot;article_title&quot;, article.getArticleName()); createPostParams.add(&quot;article_time&quot;, String.valueOf(article.getArticleTime())); createPostParams.add(&quot;article_username&quot;, userName); HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; requestEntity = new HttpEntity&lt;&gt;(createPostParams, headers); ResponseEntity&lt;String&gt; responseEntity = restTemplate.postForEntity(PositionConstants.CREATE_URL, requestEntity, String.class); 2:Spring提供的POST方法1234567891011121314&lt;T&gt; T postForObject(String url, Object request, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;&lt;T&gt; T postForObject(String url, Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;&lt;T&gt; T postForObject(URI url, Object request, Class&lt;T&gt; responseType) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, Object request, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;`&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;`&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(URI url, Object request, Class&lt;T&gt; responseType) throws RestClientException;` PUT请求: PUT请求和POST请求差不多. 1:Spring提供的PUT方法 12345void put(String url, Object request, Object... uriVariables) throws RestClientException;void put(String url, Object request, Map&lt;String, ?&gt; uriVariables) throws RestClientException;void put(URI url, Object request) throws RestClientException; DELETE请求:1:Spring提供的DELETE方法 12345void delete(String url, Object... uriVariables) throws RestClientException;void delete(String url, Map&lt;String, ?&gt; uriVariables) throws RestClientException;void delete(URI url) throws RestClientException;]]></content>
      <categories>
        <category>RestTemplate</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>RestTemplate</tag>
        <tag>Restful请求</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring的Bean生命周期]]></title>
    <url>%2F2019%2F08%2F06%2FSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[一：生命周期执行的过程如下: 对于一个Bean对象来说,它的生命周期有实例化–&gt;初始化–&gt;销毁三大块组成。所以会有如下对三大块前后做定制化Bean。 而对于Bean对象另一份的Spring感知接口来说,会有如下代码和类进行支持。 1234567891011121314151617181920212223242526272829303132333435363738ApplicationContextAwareProcessor对一些感知接口处理。详细看invokeAwareInterfaces方法。class ApplicationContextAwareProcessor implements BeanPostProcessor &#123; private final ConfigurableApplicationContext applicationContext; private final StringValueResolver embeddedValueResolver; /** * Create a new ApplicationContextAwareProcessor for the given context. */ public ApplicationContextAwareProcessor(ConfigurableApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; this.embeddedValueResolver = new EmbeddedValueResolver(applicationContext.getBeanFactory()); &#125;private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125; &#125;&#125; Bean感知接口处理。 AbstractAutowireCapableBeanFactory.java的invokeAwareMethods(final String beanName, final Object bean)方法上处理 12345678910111213141516private void invokeAwareMethods(final String beanName, final Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ClassLoader bcl = getBeanClassLoader(); if (bcl != null) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); &#125; &#125; if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125; 1) spring对bean进行实例化,默认bean是单例。2) spring对bean进行依赖注入。3) 如果bean实现了BeanNameAware接口,spring将bean的id传给setBeanName()方法。4) 如果bean实现了BeanFactoryAware接口,spring将调用setBeanFactory方法,将BeanFactory实例传进来。5) 如果bean实现了ApplicationContextAware()接口,spring将调用setApplicationContext()方法将应用上下文的引用传入。6) 如果bean实现了BeanPostProcessor接口,spring将调用它们的postProcessBeforeInitialization接口方法。7) 如果bean实现了InitializingBean接口,spring将调用它们的afterPropertiesSet接口方法,类似的如果bean使用了init-method属性声明了初始化方法,改方法也会被调用。8) 如果bean实现了BeanPostProcessor接口,spring将调用它们的postProcessAfterInitialization接口方法。9) 此时bean已经准备就绪,可以被应用程序使用了,他们将一直驻留在应用上下文中,直到该应用上下文被销毁。10) 若bean实现了DisposableBean接口,spring将调用它的distroy()接口方法。同样的,如果bean使用了destroy-method属性声明了销毁方法,则该方法被调用。 这里一用仓颉的一幅图说明流程： 第二幅图解释： 二：代码测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 /** * @see org.springframework.beans.factory.config.BeanFactoryPostProcessor * @see org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessorAdapter * @see org.springframework.beans.factory.InitializingBean * @see org.springframework.beans.factory.DisposableBean * @see org.springframework.beans.factory.BeanNameAware * @see org.springframework.beans.factory.BeanFactoryAware * @see org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean(String, RootBeanDefinition, Object[]) **/@Slf4j@Componentpublic class SpringBean implements BeanNameAware, BeanFactoryAware, InitializingBean, ApplicationContextAware, DisposableBean &#123; public SpringBean() &#123; log.info("new SpringBean......"); &#125; @Override public void setApplicationContext(ApplicationContext context) throws BeansException &#123; log.info("ApplicationContextAware-setApplicationContext......"); &#125; @Override public void afterPropertiesSet() throws Exception &#123; log.info("InitializingBean-afterPropertiesSet......"); &#125; @Override public void setBeanFactory(BeanFactory bf) throws BeansException &#123; log.info("BeanFactoryAware-setBeanFactory......"); &#125; @Override public void setBeanName(String name) &#123; log.info("BeanNameAware-setBeanName......"); &#125; @Override public void destroy() throws Exception &#123; log.info("DisposableBean-destroy....."); &#125;&#125;@Component@Slf4jpublic class SpringBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object o, String s) throws BeansException &#123; if (o instanceof SpringBean) &#123; log.info("BeanPostProcessor-postProcessBeforeInitialization......"); &#125; return o; &#125; @Override public Object postProcessAfterInitialization(Object o, String s) throws BeansException &#123; if (o instanceof SpringBean) &#123; log.info("BeanPostProcessor-postProcessAfterInitialization......"); &#125; return o; &#125;&#125; 结果展示]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Bean生命周期</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内省机制]]></title>
    <url>%2F2019%2F08%2F06%2FJava%E5%86%85%E7%9C%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[一. 内省1:维基百科解释 在计算机科学中，内省是指计算机程序在运行时（Run time）检查对象（Object）类型的一种能力，通常也可以称作运行时类型检查。 不应该将内省和反射混淆。相对于内省，反射更进一步，是指计算机程序在运行时（Run time）可以访问、检测和修改它本身状态或行为的一种能力。 2:Java语言中解释 内省(Introspector) 是Java 语言对 JavaBean 类属性、事件的一种缺省处理方法。JavaBean是一种特殊的类，主要用于传递数据信息，这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则。如果在两个模块之间传递信息，可以将信息封装进JavaBean中，这种对象称为“值对象”(Value Object)，或“VO”，方法比较少，这些信息储存在类的私有变量中，通过set()、get()获得 二:内省和反射的区别 1: 反射是在运行状态把Java类中的各种成分映射成相应的Java类，可以动态的获取所有的属性以及动态调用任意一个方法，强调的是运行状态。 2: 内省(Introspector)是Java 语言对 Bean 类属性、事件的一种缺省处理方法。 JavaBean是一种特殊的类，主要用于传递数据信息，这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则。如果在两个模块之间传递信息，可以将信息封装进JavaBean中，这种对象称为“值对象”(Value Object)，或“VO”。方法比较少。这些信息储存在类的私有变量中，通过set()、get()获得。内省机制是通过反射来实现的，BeanInfo用来暴露一个bean的属性、方法和事件，以后我们就可以操纵该JavaBean的属性。 3:比较 三:JDK内省类库 java.beans.Introspector：Introspector 类为通过工具学习有关受目标 Java Bean 支持的属性、事件和方法的知识提供了一个标准方法。 java.beans.BeanInfo接口：希望提供有关其 bean 的显式信息的 bean 实现者可以提供某个 BeanInfo 类，该类实现此 BeanInfo 接口并提供有关其 bean 的方法、属性、事件等显式信息。 java.beans.PropertyDescriptor：PropertyDescriptor 描述 Java Bean 通过一对存储器方法导出的一个属性 四:内省代码测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Java内省机制测试 * * @see java.beans.BeanInfo * @see java.beans.Introspector * @see java.beans.PropertyDescriptor * @see java.beans.MethodDescriptor **/public class IntrospectorTest &#123; private User user; @Before public void init() &#123; user = new User(); user.setAge(20); user.setId(UUID.randomUUID().toString()); user.setName("刘恩源"); &#125; @Test public void testIntrospector() throws Exception &#123; //get BeanInfo BeanInfo beanInfo = Introspector.getBeanInfo(User.class); //PropertyDescriptor PropertyDescriptor[] pds = beanInfo.getPropertyDescriptors(); for (PropertyDescriptor pd : pds) &#123; Method method = pd.getReadMethod(); String methodName = method.getName(); Object result = method.invoke(user); System.out.println(methodName + "--&gt;" + result); &#125; //get name property descriptor PropertyDescriptor namePropertyDescriptor = new PropertyDescriptor("name", User.class); //得到name属性的getter方法 Method readMethod = namePropertyDescriptor.getReadMethod(); //执行getter方法，获取返回值，即name属性的值 String result = (String) readMethod.invoke(user); System.out.println("user.name" + "--&gt;" + result); //得到name属性的setter方法 Method writeMethod = namePropertyDescriptor.getWriteMethod(); //执行setter方法，修改name属性的值 writeMethod.invoke(user, "刘恩源1"); System.out.println("user.name" + "--&gt;" + user.getName()); &#125;&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java内省机制</tag>
        <tag>Java反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT认证详解]]></title>
    <url>%2F2019%2F08%2F06%2FJWT%E8%AE%A4%E8%AF%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[JWT(Json web token) 认证详解1:概述JWT声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息,以便从资源服务器获取资源,增加一些额外的其他业务所必须的声明信息。 特别适用于分布式站点的单点登录(SSO)场景 2:起源基于token的认证和传统的session认证区别。 (1):传统的session认证概述 http协议本身是一种无状态的协议,而这就意味着如果用户向我们的应用提供了用户名和密码来进行用户认证,那么下一次请求时,用户还要再一次进行用户认证才行,因为根据http协议,我们并不能知道是哪个用户发出的请求,所以为了让我们的应用能识别是哪个用户发出的请求,我们只能在服务器存储一份用户登录的信息,这份登录信息会在响应时传递给浏览器,告诉其保存为cookie,以便下次请求时发送给我们的应用,这样我们的应用就能识别请求来自哪个用户了,这就是传统的基于session认证。 基于session认证所显露的问题 session存储问题:由于用户的信息存储在服务端,而且session都是保存在内存中,随之认证用户增多,服务端开销明显增大。 扩展性:用户认证之后,服务端做认证记录,如果认证记录被保存在内存中,意味着用户下次请求还必须要请求这台服务器,才能拿到授权资源。在分布式应用中,相应的限制了负载均衡器的能力。 CSRF:因为基于cookie来进行用户识别,如果cookie被截获,用户就会很容易受到跨站请求伪造攻击。 分布式session共享可以使用spring session data redis实现 (2):基于token的鉴权机制概述 基于token的鉴权机制类似于http协议也是无状态的,它不需要在服务端去保留用户的认证信息或者会话信息。这就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登录了,这就为应用的扩展提供了便利。 流程 用户使用用户名密码来请求服务器。 服务器进行验证用户的信息。 服务器通过验证发送给用户一个token。 客户端存储token,并在每次请求时附送上这个token值。 服务端验证token值,并返回数据。 这个token必须要在每次请求时传递给服务端,应该保存在请求头里。例外,服务端要支持CORS(跨域请求)。 3:JWT(1):设计jwt(json web token)有三部分构成。 header(头部) 声明类型:jwt 加密算法:HMAC,SHA256 头部进行base64加密。 12345//头部json&#123; "alg": "HS256", "typ": "JWT"&#125; payload:存储有效信息。 标准中注册声明(建议单不强制使用) iss: jwt签发者 sub: jwt所面向的用户 aud: 接收jwt的一方 exp: jwt的过期时间，这个过期时间必须要大于签发时间 nbf: 定义在什么时间之前，该jwt都是不可用的. iat: jwt的签发时间 jti: jwt的唯一身份标识,主要用来作为一次性token,从而回避重放攻击。 公共声明 添加任何信息,一般添加用户的相关信息或者其他业务需要的必要信息。不建议添加敏感信息。(可以在客户端进行解密) 私有声明 提供者和消费者所共同定义的声明,一般不建议存放敏感信息,因为base64是对称解密的，意味着该部分信息可以归类为明文信息。 signature:签证信息 head(base64后的) payload(base64后的) secret:保存在服务端,jwt签发生成也是在服务端。它是用来进行jwt签发和jwt验证,就是服务端的私钥。 这个部分需要base64加密后的header和payload使用。连接组成的字符串,然后通过header中声明的加密方式进行加盐secret组合加密,构成jwt第三部分。 (2):应用一般是在请求头里加入Authorization,并加上Bearer标注: 12345fetch('api/user/1', &#123; headers: &#123; 'Authorization': 'Bearer ' + token &#125;&#125;) (3):总结优点 由于json通用性,所以JWT可以跨语言。 因为有payload,所以jwt可以在自身存储一些其他业务所必要的非敏感信息。 便于传输,字节占用很小 不需要在服务端保存会话信息,易于扩展,特别适用于分布式微服务。 安全相关 不应该在jwt的payload部分存放敏感信息,因为这部分客户端可解密的部分 保护好secret私钥,该私钥非常重要。 如果可以,请使用https协议。]]></content>
      <categories>
        <category>jwt</category>
      </categories>
      <tags>
        <tag>JSON Web Token认证</tag>
        <tag>Session认证</tag>
        <tag>分布式单点登录(SSO)场景</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot自定义注解加载yml或者yaml文件]]></title>
    <url>%2F2019%2F08%2F06%2FSpringBoot%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%E5%8A%A0%E8%BD%BDyml%E6%88%96%E8%80%85yaml%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[SpringBoot自定义注解加载yml或者yaml文件1:概述SpringBoot的@PropertySource注解只支持加载 properties结尾的文件。当使用@ConfigurationProperties 注解配合@EnableConfigurationProperties注解将配置转换为JavaBean时,可能需要配合@PropertySource 注解加载指定的配置文件。所以为了支持以yml或者yaml文件,我自定义了注解@YmlPropertySource。 2:实现声明注解@YamlPropertySource 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import org.springframework.context.annotation.PropertySource;import org.springframework.core.io.support.PropertySourceFactory;import java.lang.annotation.*;/** * yaml property source and extension &#123;@link PropertySource&#125; * * @author liuenyuan * @see org.springframework.context.annotation.PropertySource **/@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(YamlPropertySources.class)public @interface YamlPropertySource &#123; /** * Indicate the name of this property source. If omitted, a name will * be generated based on the description of the underlying resource. * * @see org.springframework.core.env.PropertySource#getName() * @see org.springframework.core.io.Resource#getDescription() */ String name() default ""; /** * Indicate the resource location(s) of the properties file to be loaded. * &lt;p&gt;Both traditional and XML-based properties file formats are supported * &amp;mdash; for example, &#123;@code "classpath:/com/myco/app.properties"&#125; * or &#123;@code "file:/path/to/file.xml"&#125;. * &lt;p&gt;Resource location wildcards (e.g. *&amp;#42;/*.properties) are not permitted; * each location must evaluate to exactly one &#123;@code .properties&#125; resource. * &lt;p&gt;$&#123;...&#125; placeholders will be resolved against any/all property sources already * registered with the &#123;@code Environment&#125;. See &#123;@linkplain PropertySource above&#125; * for examples. * &lt;p&gt;Each location will be added to the enclosing &#123;@code Environment&#125; as its own * property source, and in the order declared. */ String[] value(); /** * Indicate if failure to find the a &#123;@link #value() property resource&#125; should be * ignored. * &lt;p&gt;&#123;@code true&#125; is appropriate if the properties file is completely optional. * Default is &#123;@code false&#125;. * * @since 4.0 */ boolean ignoreResourceNotFound() default false; /** * A specific character encoding for the given resources, e.g. "UTF-8". * * @since 4.3 */ String encoding() default ""; /** * Specify a custom &#123;@link PropertySourceFactory&#125;, if any. * &lt;p&gt;By default, a default factory for standard resource files will be used. * * @see org.springframework.core.io.support.DefaultPropertySourceFactory * @see org.springframework.core.io.support.ResourcePropertySource * @since 4.3 */ Class&lt;? extends PropertySourceFactory&gt; factory() default YamlPropertySourceFactory.class;&#125;/** * @author liuenyuan * @see YamlPropertySource **/@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface YamlPropertySources &#123; YamlPropertySource[] value();&#125; 具体实现如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167import lombok.extern.slf4j.Slf4j;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessorAdapter;import org.springframework.beans.factory.config.YamlPropertiesFactoryBean;import org.springframework.context.EnvironmentAware;import org.springframework.context.ResourceLoaderAware;import org.springframework.context.annotation.Configuration;import org.springframework.core.Ordered;import org.springframework.core.annotation.AnnotationUtils;import org.springframework.core.annotation.Order;import org.springframework.core.env.*;import org.springframework.core.io.Resource;import org.springframework.core.io.ResourceLoader;import org.springframework.util.Assert;import java.io.IOException;import java.util.*;/** * 类描述: &#123;@link YamlPropertySource&#125; bean post processor.this class convert the yml or yaml file &#123;@link YamlPropertySource#value()&#125; to &#123;@link PropertiesPropertySource&#125;,and add the property source * named &#123;@link YmlPropertySource#name()&#125; into &#123;@link Environment&#125;.When you use this annotation,you * must for follow example: * &lt;pre&gt;&#123;@code * @link @ConfigurationProperties(prefix = "person") * @link @YmlPropertySource(value = &#123;"classpath:/hello.yml"&#125;, name = "hello") * @link @Data * public class PersonProperties &#123; * * private String name; * * private Integer age; * * private String school; * &#125;&#125;&lt;/pre&gt; * * @author liuenyuan * @date 2019/6/16 20:13 * @describe * @see YamlPropertySource * @see InstantiationAwareBeanPostProcessorAdapter * @see EnvironmentAware * @see ResourceLoaderAware */@Slf4j@Configuration(value = YamlPropertySourceAnnotationPostProcessor.BEAN_NAME)@Order(Ordered.HIGHEST_PRECEDENCE)public class YamlPropertySourceAnnotationPostProcessor extends InstantiationAwareBeanPostProcessorAdapter implements EnvironmentAware, ResourceLoaderAware &#123; public final static String BEAN_NAME = "yamlPropertySourceAnnotationPostProcessor"; private Environment environment; private ResourceLoader resourceLoader; private final List&lt;String&gt; propertySourceNames = new ArrayList&lt;&gt;(); private static final PropertySourceFactory DEFAULT_PROPERTY_SOURCE_FACTORY = new YamlPropertySourceFactory(); @Override public void setEnvironment(Environment environment) &#123; Assert.isInstanceOf(ConfigurableEnvironment.class, environment, "environment must be instance of ConfigurableEnvironment."); this.environment = environment; &#125; @Override public void setResourceLoader(ResourceLoader resourceLoader) &#123; this.resourceLoader = resourceLoader; &#125; @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; // Process any @PropertySource annotations Set&lt;YamlPropertySource&gt; yamlPropertySources = AnnotationUtils.getRepeatableAnnotations(bean.getClass(), YamlPropertySource.class, YamlPropertySources.class); if (!yamlPropertySources.isEmpty()) &#123; Set&lt;AnnotationAttributes&gt; attributesSet = new LinkedHashSet&lt;&gt;(yamlPropertySources.size()); for (YamlPropertySource yamlPropertySource : yamlPropertySources) &#123; AnnotationAttributes attributes = AnnotationUtils.getAnnotationAttributes(bean.getClass(), yamlPropertySource); attributesSet.add(attributes); &#125; for (AnnotationAttributes propertySource : attributesSet) &#123; if (this.environment instanceof ConfigurableEnvironment) &#123; try &#123; processPropertySource(propertySource); &#125; catch (IOException e) &#123; log.warn("exception message: &#123;&#125;", e.getMessage()); &#125; &#125; else &#123; log.warn("Ignoring @YamlPropertySource annotation on [" + bean.getClass() + "]. Reason: Environment must implement ConfigurableEnvironment"); &#125; &#125; &#125; return true; &#125; private void processPropertySource(AnnotationAttributes propertySource) throws IOException &#123; String name = propertySource.getString("name"); if (!StringUtils.hasLength(name)) &#123; name = null; &#125; String encoding = propertySource.getString("encoding"); if (!StringUtils.hasLength(encoding)) &#123; encoding = null; &#125; String[] locations = propertySource.getStringArray("value"); Assert.isTrue(locations.length &gt; 0, "At least one @YamlPropertySource(value) location is required"); boolean ignoreResourceNotFound = propertySource.getBoolean("ignoreResourceNotFound"); Class&lt;? extends PropertySourceFactory&gt; factoryClass = propertySource.getClass("factory"); PropertySourceFactory factory = (factoryClass == PropertySourceFactory.class ? DEFAULT_PROPERTY_SOURCE_FACTORY : BeanUtils.instantiateClass(factoryClass)); for (String location : locations) &#123; try &#123; String resolvedLocation = this.environment.resolveRequiredPlaceholders(location); Resource resource = this.resourceLoader.getResource(resolvedLocation); addPropertySource(factory.createPropertySource(name, new EncodedResource(resource, encoding))); &#125; catch (IllegalArgumentException | FileNotFoundException | UnknownHostException ex) &#123; // Placeholders not resolvable or resource not found when trying to open it if (ignoreResourceNotFound) &#123; if (log.isInfoEnabled()) &#123; log.info("Properties or Yml or Yaml location [" + location + "] not resolvable: " + ex.getMessage()); &#125; &#125; else &#123; throw ex; &#125; &#125; &#125; &#125; private void addPropertySource(PropertySource&lt;?&gt; propertySource) &#123; String name = propertySource.getName(); MutablePropertySources propertySources = ((ConfigurableEnvironment) this.environment).getPropertySources(); if (this.propertySourceNames.contains(name)) &#123; // We've already added a version, we need to extend it PropertySource&lt;?&gt; existing = propertySources.get(name); if (existing != null) &#123; PropertySource&lt;?&gt; newSource = (propertySource instanceof ResourcePropertySource ? ((ResourcePropertySource) propertySource).withResourceName() : propertySource); if (existing instanceof CompositePropertySource) &#123; ((CompositePropertySource) existing).addFirstPropertySource(newSource); &#125; else &#123; if (existing instanceof ResourcePropertySource) &#123; existing = ((ResourcePropertySource) existing).withResourceName(); &#125; CompositePropertySource composite = new CompositePropertySource(name); composite.addPropertySource(newSource); composite.addPropertySource(existing); propertySources.replace(name, composite); &#125; return; &#125; &#125; if (this.propertySourceNames.isEmpty()) &#123; propertySources.addLast(propertySource); &#125; else &#123; String firstProcessed = this.propertySourceNames.get(this.propertySourceNames.size() - 1); propertySources.addBefore(firstProcessed, propertySource); &#125; this.propertySourceNames.add(name); &#125;&#125; 想法 使用InstantiationAwareBeanPostProcessorAdapter的postProcessAfterInstantiation(Object bean, String beanName)方法,然后通过YamlPropertiesFactoryBean将yml|yaml文件转换为properties文件,然后通过 实现EnvironmentAware接口,将配置文件属性写入到spring的Environment环境中。但是该实现有点 缺陷,就是如果使用@ConfigurationProperties和@EnableConfigurationProperties将配置属性 转换为JavaBean时,需要将@YmlProperySource注解标注到该JavaBean上。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>外部化配置</tag>
        <tag>yml|yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring类型转换]]></title>
    <url>%2F2019%2F08%2F06%2FSpring%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[Spring Type Conversion(Spring类型转换)1:概述:Spring3引入了core.convert包,提供了通用类型转换系统,定义了实现类型转换和运行时执行类型的SPI。 在Spring3.0之前,提供的PropertyEditor来将外部化bean属性值字符串转换成必需的实现类型。 2:Converter SPI12345678910111213141516171819202122232425/** * A converter converts a source object of type &#123;@code S&#125; to a target of type &#123;@code T&#125;. * * &lt;p&gt;Implementations of this interface are thread-safe and can be shared. * * &lt;p&gt;Implementations may additionally implement &#123;@link ConditionalConverter&#125;. * * @author Keith Donald * @since 3.0 * @param &lt;S&gt; the source type * @param &lt;T&gt; the target type */@FunctionalInterfacepublic interface Converter&lt;S, T&gt; &#123; /** * Convert the source object of type &#123;@code S&#125; to target type &#123;@code T&#125;. * @param source the source object to convert, which must be an instance of &#123;@code S&#125; (never &#123;@code null&#125;) * @return the converted object, which must be an instance of &#123;@code T&#125; (potentially &#123;@code null&#125;) * @throws IllegalArgumentException if the source cannot be converted to the desired target type */ @Nullable T convert(S source);&#125; 实现自定义的类型转换可以实现Converter接口。但是如果S是集合或者数组转换为T的集合或者数组, 建议参考诸如ArrayToCollectionConverter实现。前提是已经注册了委托数组或集合转换器。例如, DefaultConversionService实现。 Converter.convert(S source)中source确保不能为null,否则转换器可能抛出异常如果转换失败。具体 说,应该会抛出IllegalArgumentException报告不合理的转换源。确保Converter实现是线程安全。 在core.convert.support包下,注册了常见了类型转换器。例如: 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Converts from a String any JDK-standard Number implementation. * * &lt;p&gt;Support Number classes including Byte, Short, Integer, Float, Double, Long, BigInteger, BigDecimal. This class * delegates to &#123;@link NumberUtils#parseNumber(String, Class)&#125; to perform the conversion. * * @author Keith Donald * @since 3.0 * @see java.lang.Byte * @see java.lang.Short * @see java.lang.Integer * @see java.lang.Long * @see java.math.BigInteger * @see java.lang.Float * @see java.lang.Double * @see java.math.BigDecimal * @see NumberUtils */final class StringToNumberConverterFactory implements ConverterFactory&lt;String, Number&gt; &#123; @Override public &lt;T extends Number&gt; Converter&lt;String, T&gt; getConverter(Class&lt;T&gt; targetType) &#123; return new StringToNumber&lt;&gt;(targetType); &#125; private static final class StringToNumber&lt;T extends Number&gt; implements Converter&lt;String, T&gt; &#123; private final Class&lt;T&gt; targetType; public StringToNumber(Class&lt;T&gt; targetType) &#123; this.targetType = targetType; &#125; @Override public T convert(String source) &#123; if (source.isEmpty()) &#123; return null; &#125; return NumberUtils.parseNumber(source, this.targetType); &#125; &#125;&#125; 3:ConverterFactory当你需要集中整理类层次结构的类型转换器,可以使用ConverterFactory。例如StringToNumberConverterFactory, 该接口定义如下,当你需要范围转换器,可以转换这些对象从S类型转换成R的子类型。使用该接口。 1234567891011121314151617181920212223/** * A factory for "ranged" converters that can convert objects from S to subtypes of R. * * &lt;p&gt;Implementations may additionally implement &#123;@link ConditionalConverter&#125;. * * @author Keith Donald * @since 3.0 * @see ConditionalConverter * @param &lt;S&gt; the source type converters created by this factory can convert from * @param &lt;R&gt; the target range (or base) type converters created by this factory can convert to; * for example &#123;@link Number&#125; for a set of number subtypes. */public interface ConverterFactory&lt;S, R&gt; &#123; /** * Get the converter to convert from S to target type T, where T is also an instance of R. * @param &lt;T&gt; the target type * @param targetType the target type to convert to * @return a converter from S to T */ &lt;T extends R&gt; Converter&lt;S, T&gt; getConverter(Class&lt;T&gt; targetType);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Converts from a String any JDK-standard Number implementation. * * &lt;p&gt;Support Number classes including Byte, Short, Integer, Float, Double, Long, BigInteger, BigDecimal. This class * delegates to &#123;@link NumberUtils#parseNumber(String, Class)&#125; to perform the conversion. * * @author Keith Donald * @since 3.0 * @see java.lang.Byte * @see java.lang.Short * @see java.lang.Integer * @see java.lang.Long * @see java.math.BigInteger * @see java.lang.Float * @see java.lang.Double * @see java.math.BigDecimal * @see NumberUtils */final class StringToNumberConverterFactory implements ConverterFactory&lt;String, Number&gt; &#123; @Override public &lt;T extends Number&gt; Converter&lt;String, T&gt; getConverter(Class&lt;T&gt; targetType) &#123; return new StringToNumber&lt;&gt;(targetType); &#125; private static final class StringToNumber&lt;T extends Number&gt; implements Converter&lt;String, T&gt; &#123; private final Class&lt;T&gt; targetType; public StringToNumber(Class&lt;T&gt; targetType) &#123; this.targetType = targetType; &#125; @Override public T convert(String source) &#123; if (source.isEmpty()) &#123; return null; &#125; return NumberUtils.parseNumber(source, this.targetType); &#125; &#125;&#125; 4:GenericConverter GenericConverter提供多种源和目标类型之间转换,比Converter更灵活但是对类型要求不高。它提供了实现 转换逻辑的源和目标上下文。 这样的上下文允许类型转换由字段注释或在字段签名上声明的通用信息驱动。接口 如下: 12345678package org.springframework.core.convert.converter;public interface GenericConverter &#123; public Set&lt;ConvertiblePair&gt; getConvertibleTypes(); Object convert(Object source, TypeDescriptor sourceType, TypeDescriptor targetType);&#125; ConvertiblePair持有转换源和目标类型对。convert(Object, TypeDescriptor, TypeDescriptor)。 源TypeDescriptor提供对保存正在转换的值的源字段的访问。 目标TypeDescriptor提供对要设置转换值的目标字段的访问。TypeDescriptor类是关于要转换类型的上下文。 一个好的实例是GenericConverter在Java数组和集合之间转换。例如ArrayToCollectionConverter。 注意 1因为GenericConverter是一个更复杂的SPI接口,所以只有在需要时才应该使用它.喜欢Converter或ConverterFactory以满足基本的类型转换需求。 5:ConditionalGenericConverter该接口是一个带有判断条件的类型转换器。该接口是GenericConverter和ConditionalConverter的组合。 123456789101112131415/** * A &#123;@link GenericConverter&#125; that may conditionally execute based on attributes * of the &#123;@code source&#125; and &#123;@code target&#125; &#123;@link TypeDescriptor&#125;. * * &lt;p&gt;See &#123;@link ConditionalConverter&#125; for details. * * @author Keith Donald * @author Phillip Webb * @since 3.0 * @see GenericConverter * @see ConditionalConverter */public interface ConditionalGenericConverter extends GenericConverter, ConditionalConverter &#123;&#125; ConditionalGenericConverter 的一个好示例是StringToCollectionConverter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Converts a comma-delimited String to a Collection. * If the target collection element type is declared, only matches if * &#123;@code String.class&#125; can be converted to it. * * @author Keith Donald * @author Juergen Hoeller * @since 3.0 */final class StringToCollectionConverter implements ConditionalGenericConverter &#123; private final ConversionService conversionService; public StringToCollectionConverter(ConversionService conversionService) &#123; this.conversionService = conversionService; &#125; @Override public Set&lt;ConvertiblePair&gt; getConvertibleTypes() &#123; return Collections.singleton(new ConvertiblePair(String.class, Collection.class)); &#125; @Override public boolean matches(TypeDescriptor sourceType, TypeDescriptor targetType) &#123; return (targetType.getElementTypeDescriptor() == null || this.conversionService.canConvert(sourceType, targetType.getElementTypeDescriptor())); &#125; @Override @Nullable public Object convert(@Nullable Object source, TypeDescriptor sourceType, TypeDescriptor targetType) &#123; if (source == null) &#123; return null; &#125; String string = (String) source; String[] fields = StringUtils.commaDelimitedListToStringArray(string); TypeDescriptor elementDesc = targetType.getElementTypeDescriptor(); Collection&lt;Object&gt; target = CollectionFactory.createCollection(targetType.getType(), (elementDesc != null ? elementDesc.getType() : null), fields.length); if (elementDesc == null) &#123; for (String field : fields) &#123; target.add(field.trim()); &#125; &#125; else &#123; for (String field : fields) &#123; Object targetElement = this.conversionService.convert(field.trim(), sourceType, elementDesc); target.add(targetElement); &#125; &#125; return target; &#125;&#125; 6:ConversionService APIConversionService定义了一个统一的API,用于在运行时执行类型转换逻辑. 转换器通常在以下Facade接口后面执行。 12345678910111213package org.springframework.core.convert;public interface ConversionService &#123; boolean canConvert(Class&lt;?&gt; sourceType, Class&lt;?&gt; targetType); &lt;T&gt; T convert(Object source, Class&lt;T&gt; targetType); boolean canConvert(TypeDescriptor sourceType, TypeDescriptor targetType); Object convert(Object source, TypeDescriptor sourceType, TypeDescriptor targetType);&#125; 大多数ConversionService实现,同样也实现了ConverterRegistry,该接口提供了SPI来注册Converters. 在内部,ConversionService的实现,容器委托它来注册转换器来执行转换逻辑。 core.convert.support提供一个强大的ConversionService实现,该实现是GenericConversionSer ,它适用于大多数转换器环境实现。ConversionServiceFactory 来创建普通的ConversionService 配置。 7:配置ConversionService ConversionService被设计成无状态对象,在容器启动时被实例化,在多线程间进行共享(线程安全)。 在Spring应用中,可以自定义类型转换器。当需要框架进行类型转换时,Spring会选择合适的类型转换器 使用。你也可以注入ConversionService到beans或者直接调用。 注意 如果没有ConversionService注册到Spring容器,基于的PropertyEditor实现的类型转换会被使用。 ​ 使用如下的方式,注册默认ConversionService进Spring容器中: 12345678public class ConvertersConfiguration &#123; @Bean(name = "conversionService") public ConversionServiceFactoryBean conversionServiceFactory() &#123; ConversionServiceFactoryBean conversionServiceFactoryBean = new ConversionServiceFactoryBean(); return conversionServiceFactoryBean; &#125;&#125; 默认的ConversionService可以在字符串，数字，枚举，集合，映射和其他常见类型之间进行转换。要使用您自己的自定义转换器补充或覆盖默认转换器,请设置converter属性.属性值可以实现任何Converter,ConverterFactory或GenericConverter接口。默认ConversionService实现是DefaultConversionService。 12345678910public class ConvertersConfiguration &#123; @Bean(name = "conversionService") public ConversionServiceFactoryBean conversionServiceFactory() &#123; ConversionServiceFactoryBean conversionServiceFactoryBean = new ConversionServiceFactoryBean(); //实现自定义的类型转换器 conversionServiceFactoryBean.setConverters(Collections.singleton(new StringToDateConverter())); return conversionServiceFactoryBean; &#125;&#125; 也可以使用ConversionService在Spring MVC应用中,参考WebMvcConfigurationSupport类,该类方法 addFormatters(FormatterRegistry registry)可以注册自定义的converters。 在某些情况,希望在类型转换期间需要格式化,参考FormatterRegistry。 在程序中使用ConversionService 123456789101112@Servicepublic class MyService &#123; @Autowired public MyService(ConversionService conversionService) &#123; this.conversionService = conversionService; &#125; public void doIt() &#123; this.conversionService.convert(...) &#125;&#125; 8:Spring域属性格式化 core.convert是一个通用的类型转换系统.它提供了统一的ConversionService API以及强类型转换器SPI,用于实现从一种类型到另一种类型的转换逻辑.Spring容器使用这个系统来绑定bean属性值。额外的,还要SpEL和 DataBinder。Spring3引入了Formatter SPI来实现格式化属性值。ConversionService为两个SPI提供统一的类型转换API。 (1):Formatter SPI12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Formats objects of type T. * A Formatter is both a Printer &lt;i&gt;and&lt;/i&gt; a Parser for an object type. * * @author Keith Donald * @since 3.0 * @param &lt;T&gt; the type of object this Formatter formats */public interface Formatter&lt;T&gt; extends Printer&lt;T&gt;, Parser&lt;T&gt; &#123;&#125;/** * Parses text strings to produce instances of T. * * @author Keith Donald * @since 3.0 * @param &lt;T&gt; the type of object this Parser produces */@FunctionalInterfacepublic interface Parser&lt;T&gt; &#123; /** * Parse a text String to produce a T. * @param text the text string * @param locale the current user locale * @return an instance of T * @throws ParseException when a parse exception occurs in a java.text parsing library * @throws IllegalArgumentException when a parse exception occurs */ T parse(String text, Locale locale) throws ParseException;&#125;/** * Prints objects of type T for display. * * @author Keith Donald * @since 3.0 * @param &lt;T&gt; the type of object this Printer prints */@FunctionalInterfacepublic interface Printer&lt;T&gt; &#123; /** * Print the object of type T for display. * @param object the instance to print * @param locale the current user locale * @return the printed text string */ String print(T object, Locale locale);&#125; (2):Annotation-Driven Formatting域格式化可以通过域类型或者注解配置.为了绑定注解在一个Formatter,实现AnnotationFormatterFactory. 123456789101112131415161718192021package org.springframework.format;/** * A factory that creates formatters to format values of fields annotated with a particular * &#123;@link Annotation&#125;. * * &lt;p&gt;For example, a &#123;@code DateTimeFormatAnnotationFormatterFactory&#125; might create a formatter * that formats &#123;@code Date&#125; values set on fields annotated with &#123;@code @DateTimeFormat&#125;. * * @author Keith Donald * @since 3.0 * @param &lt;A&gt; the annotation type that should trigger formatting */public interface AnnotationFormatterFactory&lt;A extends Annotation&gt; &#123; Set&lt;Class&lt;?&gt;&gt; getFieldTypes(); Printer&lt;?&gt; getPrinter(A annotation, Class&lt;?&gt; fieldType); Parser&lt;?&gt; getParser(A annotation, Class&lt;?&gt; fieldType);&#125; 例如实现NumberFormatAnnotationFormatterFactory,绑定@NumberFormat注解到Formatter。 1234567891011121314151617181920212223242526272829303132333435363738public class NumberFormatAnnotationFormatterFactory extends EmbeddedValueResolutionSupport implements AnnotationFormatterFactory&lt;NumberFormat&gt; &#123; @Override public Set&lt;Class&lt;?&gt;&gt; getFieldTypes() &#123; return NumberUtils.STANDARD_NUMBER_TYPES; &#125; @Override public Printer&lt;Number&gt; getPrinter(NumberFormat annotation, Class&lt;?&gt; fieldType) &#123; return configureFormatterFrom(annotation); &#125; @Override public Parser&lt;Number&gt; getParser(NumberFormat annotation, Class&lt;?&gt; fieldType) &#123; return configureFormatterFrom(annotation); &#125; private Formatter&lt;Number&gt; configureFormatterFrom(NumberFormat annotation) &#123; String pattern = resolveEmbeddedValue(annotation.pattern()); if (StringUtils.hasLength(pattern)) &#123; return new NumberStyleFormatter(pattern); &#125; else &#123; Style style = annotation.style(); if (style == Style.CURRENCY) &#123; return new CurrencyStyleFormatter(); &#125; else if (style == Style.PERCENT) &#123; return new PercentStyleFormatter(); &#125; else &#123; return new NumberStyleFormatter(); &#125; &#125; &#125;&#125; (3):格式化注解APIDateTimeFormat和NumberFormat。 (4):FormatterRegistry SPIFormatterRegistry是用来注册formatters 和 converters的SPI。FormattingConversionService 是FormatterRegistry 一个实现,可以支持大多数环境。可以通过FormattingConversionServiceFactoryBean 来配置。也可以通过Spring’s DataBinder和SpEL。 123456789101112package org.springframework.format;public interface FormatterRegistry extends ConverterRegistry &#123; void addFormatterForFieldType(Class&lt;?&gt; fieldType, Printer&lt;?&gt; printer, Parser&lt;?&gt; parser); void addFormatterForFieldType(Class&lt;?&gt; fieldType, Formatter&lt;?&gt; formatter); void addFormatterForFieldType(Formatter&lt;?&gt; formatter); void addFormatterForAnnotation(AnnotationFormatterFactory&lt;?, ?&gt; factory);&#125; (5):FormatterRegistrar SPIFormatterRegistrar是通过FormatterRegistry注册formatters和converters的SPI。 123456package org.springframework.format;public interface FormatterRegistrar &#123; void registerFormatters(FormatterRegistry registry);&#125; 9:在Spring MVC配置Formatting12345678910Configuration@Slf4jpublic class WebConfiguration extends WebMvcConfigurationSupport &#123; @Override protected void addFormatters(FormatterRegistry registry) &#123; registry.addConverter(new StringToDateConverter()); &#125;&#125; 10:配置全局的Date和时间FormatJodaTimeFormatterRegistrar和DateFormatterRegistrar,使用Joda需要引入joda库 配置如下: 1234567891011121314151617181920@Configurationpublic class AppConfig &#123; @Bean public FormattingConversionService conversionService() &#123; // Use the DefaultFormattingConversionService but do not register defaults DefaultFormattingConversionService conversionService = new DefaultFormattingConversionService(false); // Ensure @NumberFormat is still supported conversionService.addFormatterForFieldAnnotation(new NumberFormatAnnotationFormatterFactory()); // Register date conversion with a specific global format DateFormatterRegistrar registrar = new DateFormatterRegistrar(); registrar.setFormatter(new DateFormatter("yyyyMMdd")); registrar.registerFormatters(conversionService); return conversionService; &#125;&#125; 注意 Joda-Time提供不同类型表示日期date,time,datetime,需要通过JodaTimeFormatterRegistrar进行 注册。或者使用DateTimeFormatterFactoryBean来进行创建formatters。 如果您使用Spring MVC,请记住明确配置使用的转换服务.对于基于Java的@Configuration,这意味着扩展WebMvcConfigurationSupport类并覆盖mvcConversionService()方法.对于XML,您应该使用mvc:annotation-driven元素的conversion-service属性。 有关详细信息，请参阅转换和格式。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>Spring Type Converter</tag>
        <tag>单例设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring注解属性覆盖]]></title>
    <url>%2F2019%2F08%2F06%2FSpring%E6%B3%A8%E8%A7%A3%E5%B1%9E%E6%80%A7%E8%A6%86%E7%9B%96%2F</url>
    <content type="text"><![CDATA[Spring注解属性覆盖1:隐性覆盖较低层次的注解覆盖其元注解的同名属性 AnnotationAttributes采用注解就近覆盖的设计原则。 @Component ​ | -@Service ​ | -@TransactionalService @Service较@Component,距离@TransactionalService注解更近，属于较低层次的注解。 2:显性覆盖@AliasFor提供的属性覆盖能力。 (1):理解Spring注解属性别名(Aliases) @AliasFor可用于同一注解属性方法之间相互别名。同一注解两个属性方法需要相互 “@AliasFor”，默认值必须相等。 多层次注解属性之间的@AliasFor关系只能由较低层次向较高层次建立。即就近原则。 AnnotatedElementUtils.getMergedAnnotationAttributes方法也符合属性别名完整语义。 Spring为Spring元注解和@AliasFor提供了属性覆盖和别名特性，最终由AnnotationAttributes 对象表达语义。 (2):代码实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 类描述:组合注解 * * @author liuenyuan * @date 2019/4/25 20:11 * @describe */@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Transactional//表明注解属性覆盖符合就近原则,由低层次向高层次建立。@Service(value = "transactionalService")public @interface TransactionalService &#123; /** * @return 服务Bean名称 **/ @AliasFor("value") String name() default "txManager"; /** * 覆盖&#123;@link Transactional#transactionManager()&#125;默认值 * * @return &#123;@link org.springframework.transaction.PlatformTransactionManager&#125;Bean名称,默认关联 * &lt;br/&gt; * "txManager"Bean **/ /** * String transactionManager() default "txManager"; **/ @AliasFor("name") String value() default "txManager"; /** * 建立&#123;@link Transactional#transactionManager()&#125;别名 * * @return &#123;@link org.springframework.transaction.PlatformTransactionManager&#125;Bean名称,默认关联 * "txManager"Bean. **/ @AliasFor(annotation = Transactional.class, attribute = "transactionManager") String manager() default "txManager";&#125; 3:重要的类1：ClassPathBeanDefinitionScanner 读取类路径下的候选Bean，默认选取@Component，@Service，@Repository，@Controller注解的类。继承了ClassPathScanningCandidateComponentProvider。在该类BeanDefinition集合的候选条件由includeFilters和excludeFilters字段决定，在方法isCandidateComponent里实现。 该类允许自定义类型过滤规则。常见的TypeFilter类。 AnnotationTypeFilter：匹配类是否还有指定注解 AssignableTypeFilter：判定此 Class 对象所表示的类或接口与指定的 Class 参数所表示的类或接口是否相同，或是否是其超类或超接口。 RegexPatternTypeFilter：匹配全类限定名是否符合指定正则表达式。 AspectJTypeFilter：使用AspectJ类型模式进行匹配 2：类元信息读取 (1)：MetadataReaderFactory：生成MetadataReader工厂 SimpleMetadataReaderFactory：使用ASM字节码操作技术 CachingMetadataReaderFactory：使用ASM字节码操作技术和带缓存。 (2)：使用Java反射获取类元信息 StandardClassMetadata：读取Class元信息 StandardAnnotationMetadata：读取注解元信息 StandardMethodMetadata：读取方法 (3)：使用ASM操作 AnnotationMetadataReadingVisitor：查找类上元注解信息 MethodMetadataReadingVisitor：查找方法上元注解信息 AnnotationAttributesReadingVisitor：元注解属性读取 (4)：类注解元信息读取接口 AnnotationMetadata：读取注解。通过getAnnotationTypes(String)获取”元注解” 信息，提供getAnnotationAttributes(String)方法获取指定注解的属性方法。 ClassMetadata：类注解 AnnotatedTypeMetadata：注解的元注解 3：Spring注解属性抽象 AnnotationAttributes AnnotatedElementUtils：对查找注解，元注解等注解的工具类 AnnotationUtils：用于处理注解的工具类。 ReflectionUtils：反射工具类。 代码示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 类描述: 组合注解启动类 * * @author liuenyuan * @date 2019/4/25 20:14 * @describe */@TransactionalServicepublic class ComposeAnnotationApplication &#123; public static void main(String[] args) throws IOException &#123; String className = ComposeAnnotationApplication.class.getName(); //构建MetadataReaderFactory MetadataReaderFactory metadataReaderFactory = new CachingMetadataReaderFactory(); //读取@TransactionalService MetadataReader信息 MetadataReader metadataReader = metadataReaderFactory.getMetadataReader(className); //读取@TransactionalService AnnotationMetadata信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); annotationMetadata.getAnnotationTypes().forEach(annotationType -&gt; &#123; Set&lt;String&gt; metaAnnotationTypes = annotationMetadata.getMetaAnnotationTypes(annotationType); metaAnnotationTypes.forEach(metaAnnotationType -&gt; System.out.println(String.format( "注解 %s 元标注; %s\n", annotationType, metaAnnotationType))); &#125;); &#125;&#125; @Test public void springStandardAnnotationMetadata() &#123; //读取@TransactionalService AnnotationMetadata信息 AnnotationMetadata annotationMetadata = new StandardAnnotationMetadata(ComposeAnnotationReflectionApplication.class); //获取所有的元注解(全类名)集合 Set&lt;String&gt; metaAnnotationTypes = annotationMetadata.getAnnotationTypes() .stream() //读取单注解元注解类型集合 .map(annotationMetadata::getMetaAnnotationTypes) //合并元注解类型集合 .collect(LinkedHashSet::new, Set::addAll, Set::addAll); //读取所有元注解类型 metaAnnotationTypes.forEach(metaAnnotation -&gt; &#123; //读取元注解属性 Map&lt;String, Object&gt; annotationAttributes = annotationMetadata.getAnnotationAttributes(metaAnnotation); if (!CollectionUtils.isEmpty(annotationAttributes)) &#123; annotationAttributes.forEach((name, value) -&gt; System.out.printf("注解 %s 属性 %s = %s\n", ClassUtils.getShortName(metaAnnotation), name, value)); &#125; &#125;); &#125; Spring从4.0.0.RELEASE版本开始支持多层次@Component派生性。 1:Spring中@Component,@Repository,@Service,@Controller就属于@Component派生注解。 称之为Spring模式注解。 4:注解驱动过渡时代：Spring Framework 2.x新引入了一些骨架式的Annotation 依赖注入Annotation：@Autowired(可注入单个Bean，也可注入集合)—&gt;限定类型Class方式。 依赖查找Annotation：@Qualifier 组件声明Annotation：@Component,@Service Spring MVC Annotation：@Controller,@RequestMapping,@ModelAttributes等。 支持可扩展的XML编写。即Spring的Schema和Handlers机制。 支持JSR-250规范@Resource注入，@PostConstruct，@PreDestroy等。 总结Spring2.5允许自定义Spring模式注解，不过该版本仅支持单层次的模式注解“派生”。但是编程手段不多，**主要 的原因在于框架层次仍未注解提供驱动注解的Spring应用上下文，并且仍需要XML配置驱动，即XML元素&lt;context:annotation-config&gt;和&lt;context-component-scan&gt;。 5:注解驱动黄金时代：Spring Framework 3.x全面拥抱Java5(泛型,变量参数等)，以及Spring Annotation引入。例如引入了配置类注解@Configuration,AnnotationConfigApplicationContext。但是没有引入替换&lt;context:component-scan/&gt;注解。 选择过渡方案@Import,@ImportResource(需要标注@Configuration注解)。Spring3.1引入注解@ComponentScan。引入了REST开发。 SpringWeb整合了Servlet3.0+按规范，利用javax.servlet.ServletContainerInitialier API实现传统Servlet容器 自动装配的能力，替换了传统的web.xml。 1:Spring3.1抽象了一套全新并统一配置属性API,包括配置属性存储接口Environment,以及配置属性源抽象PropertySource，这两个核心API奠定了SpringBoot外部化配置的基础，也是SpringCloud分布式配置基石。 2:然后是缓存抽象，主要API包括缓存Cache和缓存管理器CacheManager。配套注解Caching和Cacheable等 极大简化了数据缓存开发。 3:异步支持，引入了异步操作注解@Async,周期异步操作@Scheduled及异步Web请求处理操作DefferedResult。 4:校验方面，新增了注解@Validated，整合JSR-303和适配了Spring早期的Validator抽象。 5:Enabled模块驱动特性。将相同职责功能组件以模块化的方式装配。例如EnabledWebMvc。 6:注解驱动完善时代:Spring Framework 4.x引入了条件化注解@Conditional，通过与自定义Condition实现配合，弥补之前版本条件化配置装配的 短板。SpringBoot的所有@ConditionalOn注解均基于@Conditional派生注解，其抽象类*SpringBootCondition**也是Condition的实现。 Spring4.x兼容了Java Time API(JSR-310),@Repeatable及参数名称发现。Java8的@Repeatable出现，解决了 以往Annotation无法重复标注同一个类的限制。Spring4.2引入了事件监听器注解@EventListener。 Spring的派生特性需要确保注解之间属性方法签名一致。限制在Spring4.2新注解@AliasFor解除，实现了 同一注解类属性方法之间的别名。Spring4.3引入REST请求注解。 Spring4.x在Web注解驱动编程也有提示，例如@RestController,@RestControllerAdvice(对RestController AOP拦截通知)。 7:注解驱动当下时代:Spring Framework5.x在SpringBoot应用场景中，大量使用注解@ComponentScan扫描指定package,当扫描package所包含的类越多时, Spring模式注解耗费时间越长。针对这个问题,Spring5.x新引入了注解@Indexed,为Spring模式注解添加索引，提升启动性能。需要引入spring-context-indexer依赖。 7-1:Spring核心注解场景分类Spring模式注解: Spring注解 场景说明 起始版本 @Repository 数据仓库模式注解 2.0 @Component 通用组件模式注解 2.5 @Service 服务模式 2.5 @Controller Web控制器模式注解 2.5 @Configuration 配置类模式注解 3.0 装配注解 Spring注解 场景说明 起始版本 @ImportResource 替换XML元素&lt;import&gt; 2.5 @Import 限定@Autowired依赖注解范围 2.5 @ComponentScan 扫描指定package下标注Spring模式注解 3.1 依赖注入注解 Spring注解 场景说明 起始版本 @Autowired Bean依赖注解,支持多种依赖查找方式 2.5 @Qualifier 细粒度的@Autowired依赖查找 2.5 Java注解 场景说明 起始版本 @Resource Bean依赖注入,仅支持名称依赖查找 2.5 Bean定义注解 Spring注解 场景说明 起始版本 @Bean 替换XML元素&lt;bean&gt; 3.0 @DependsOn 替换XML属性&lt;bean depends-on=”…”/&gt; 3.0 @Lazy 替换XML属性&lt;bean lazy-init=”trus|false”/&gt; 3.0 @Primary 替换XML元素&lt;bean primary=”true|false”/&gt; 3.0 @Role 替换XML元素&lt;bean role=”…”/&gt; 3.1 @Lookup 替换XML属性&lt;bean lookup-method=”…”&gt; 4.1 Spring条件装配注解 Spring注解 场景说明 起始版本 @Profile 配置化条件装配 3.1 @Conditional 编程条件装配 3.1 配置属性注解 Spring注解 场景说明 起始版本 @PropertySource 配置属性抽象PropertySource注解 3.1 @PropertySources @PropertySource集合注解 4.0 生命周期回调注解 Java注解 场景说明 起始版本 @PostContruct 替换XML元素&lt;bean init-method=”…”/&gt; 2.5 @PreDestroy 替换XML元素&lt;bean destroy-method=”…”/&gt; 2.5 注解属性注解 Spring注解 场景说明 起始版本 @AliasFor 别名注解属性,实现复用目的 4.2 性能注解 Spring注解 场景说明 起始版本 @Indexed 提升Spring模式注解扫描效率 5.0 8:AnnotationMetadata注解的实现 在AnnotationMetadata语义上,基于Java反射StandardAnnotationMetadata和AnnotationMetadataReadingVisitor保持一致。基于Java反射API实现必然需要反射的Class被ClassLoader加载，当指定Java Package扫描Spring模式注解时,StandardAnnotationMetadata显然不适应。 因为应用不需要将指定Package下的Class全部加载。基于ASM实现的AnnotationMetadataReadingVisitor更适合这种场景，解释了为什么该类出现ClassPathScanningCandidateComponentProvider实现中。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Annotation</tag>
        <tag>Spring注解属性覆盖</tag>
        <tag>Spring核心注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava简介]]></title>
    <url>%2F2019%2F08%2F06%2FGuava%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[1.引言Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如：集合 [collections] 、缓存 [caching] 、原生类型支持 [primitives support] 、并发库 [concurrency libraries] 、通用注解 [common annotations] 、字符串处理 [string processing] 、I/O 等等。 所有这些工具每天都在被Google的工程师应用在产品服务中。 2.基本工具 使用和避免null: Optional 前置条件: Preconditions 常见Object方法: Objects 排序: Guava强大的”流畅风格比较器”: Ordering Throwables: 简化了异常和错误的传播与检查 : Throwables 编码类型: Charsets 3.集合 不可变集合: 用不变的集合进行防御性编程和性能提升: Immutable开头。 新集合类型: multisets, multimaps, tables, bidirectional maps等 强大的集合工具类: 提供java.util.Collections中没有的集合工具 扩展工具类：让实现和扩展集合类变得更容易，比如创建Collection的装饰器，或实现迭代器 4.缓存[Caches]Guava Cache: 本地缓存实现,支持多种缓存过期策略。 5.函数式风格[Functional idioms]Guava函数式支持可以显著简化代码,但请谨慎使用。 6.并发[Concurrency] ListenableFuture：完成后触发回调的Future Service框架：抽象可开启和关闭的服务，帮助你维护服务的状态逻辑 7.字符串处理[Strings]非常有用的字符串工具，包括分割、连接、填充等操作 8.原生类型[Primitives]扩展 JDK 未提供的原生类型（如int、char）操作， 包括某些类型的无符号形式 9.区间[Ranges]可比较类型的区间API，包括连续和离散类型 10.I/O简化I/O尤其是I/O流和文件的操作，针对Java5和6版本 11.散列[Hash]提供比Object.hashCode()更复杂的散列实现，并提供布鲁姆过滤器的实现 12. 事件总线[EventBus]发布-订阅模式的组件通信，但组件不需要显式地注册到其他组件中 13.数学运算[Math]优化的、充分测试的数学工具类 14.反射[Reflection]Guava 的 Java 反射机制工具类]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Guava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot自动配置原理]]></title>
    <url>%2F2019%2F08%2F05%2FSpringBoot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[SpringBoot自动配置原理1:产生背景 在Spring Framework时代,当Spring应用的@Component或者@Configuration Class需要被装配 时,应用需要借助@Import或者@ComponentScan的能力。由于应用依赖的Jar存在变化的可能, 因此其中的@Component或者@Configuration Class所在的包路径也会发生变化。 不鼓励开发人员通过@ComponentScan或者@SpringApplication注解方式扫描默认包。因为 它读取所有JAR中类,并且可能会造成默认Spring Boot错误 当Spring应用自动装配某些组件时,它需要一种综合性技术手段,重新深度结合Spring注解编程 模型,@Enable模块驱动和条件装配等Spring Framework原生特性,这种技术就是Spring Boot 自动装配。 2:理解Spring Boot自动装配(1):理解@EnableAutoConfiguration 用于激活Spring Boot自动装配特性。 (2):优雅的替换自动装配 开发人员可在任意一处定义配置类,从而覆盖那些被自动装配的组件。SpringBoot优先解析 自定义配置类。内建的配置类,一旦应用存在自定义实现，就不会再装配。 (3):失效自动装配 SpringBoot提供两种失效手段 代码配置方式 配置类型安全属性方法:@EnableAutoConfiguration.exclude() 配置排除类名方式:@EnableAutoConfiguration.excludeName() 外部化配置方式 配置属性:spring.autoconfigure.exclude 3:自动装配原理 依照@Enable模块驱动设计模式，@EnableAutoConguration必然是@Import 类ImportSelector 或者ImportBeanDefinitionRegistrar的实现类。 AutoConfigurationImportSelector主要执行逻辑: 1234567891011121314151617181920212223242526public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; //读取自动装配元信息配置文件 //"META-INF/"+ "spring-autoconfigure-metadata.properties" AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); //获取@EnableAutoConfiguration注解属性 AnnotationAttributes attributes = getAttributes(annotationMetadata); //获取自动装配Class候选列表 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); //移除重复的自动装配类名 configurations = removeDuplicates(configurations); //排除自动装配组件 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); //检查排除类名集合是否合法 checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); //过滤候选自动装配组件集合中Class不存在成员 configurations = filter(configurations, autoConfigurationMetadata); //触发自动装配导入事件 fireAutoConfigurationImportEvents(configurations, exclusions); return StringUtils.toStringArray(configurations);&#125; (1):读取候选装配组件 使用了Spring工厂加载类SpringFactoriesLoader。原理如下 搜索指定ClassLoader下所有的META-INF/spring.factories资源内容。 将一个或者多个META-INF/spring.factories资源内容作为Properties文件读取,并合并为 一个Key为接口的全类限定名,Value是实现类的全类名列表的Map,作为返回值。 再从上一步返回Map中查找并返回方法指定类名所映射的实现类全类名列表。 SpringBoot自动装配列表存在地方 spring-boot-autoconfigure模块 spring-boot-actuator-autoconfigure模块 spring-boot-devtools模块(可选) 由于@EnableAutoConfiguration配置可能存在配置组件类名重复定义情况,当获取所有候选类, 立即执行removeDuplicates(List)方法,利用Set不可重复性达到去重的目的。 (2):排除自动装配组件 当getExclusions(AnnotationMetadata metadata,AnnotationAttributes attributes) 执行后,程序将获取到一个自动装配Class排除列表。随后检查排除类名集合是否合法。当排除类 存在于当前的ClassLoader但是不在自动装配名单中,将触发排除类非法异常。 1234567891011121314private void checkExcludedClasses(List&lt;String&gt; configurations, Set&lt;String&gt; exclusions) &#123; List&lt;String&gt; invalidExcludes = new ArrayList&lt;&gt;(exclusions.size()); for (String exclusion : exclusions) &#123; //存在当前ClassLoader但是不在自动装配列表名单 if (ClassUtils.isPresent(exclusion, getClass().getClassLoader()) &amp;&amp; !configurations.contains(exclusion)) &#123; invalidExcludes.add(exclusion); &#125; &#125; if (!invalidExcludes.isEmpty()) &#123; handleInvalidExcludes(invalidExcludes); &#125;&#125; (3):过滤自动装配组件 移除排除类名单后Configurations配合AutoConfigurationMetadata对象执行过滤操作。 (4):@EnableAutoConfiguration自动装配事件 SpringBoot1.5开始引入AutoConfigurationImportListener接口,自定义Java EventListener ,仅监听AutoConfigurationImportEvent,然后实例同样被SpringFactoriesLoader加载。其中, ConditionEvaluationReportAutoConfigurationImportListener就是内建实现,用于 记录自动装配组件的条件评估详情。 (5):EnableAutoConfiguration自动装配生命周期 DeferredImportSelector作为ImportSelector变种,它在@Configuration Bean处理完毕 后才运作。在@Conditional场景尤为有用，同时该实现类可通过Ordered接口或者@Order 方式调整其优先顺序。 该接口提供两类方法: process()和selectImports()。前者二次处理selectImports()方法返回 的结果，后者负责决定本组应该导入的Configuration Class作为实际导入的结果。 (6):EnableAutoConfiguration排序自动装配组件 SpringBoot提供两种自动装配组件排序手段: 绝对自动装配顺序:@AutoConfigurationOrder 相对自动装配顺序:@AutoConfigurationBefore和@AutoConfigurationAfter。(常用) (7):EnableAutoConfiguration自动装配BasePackages SpringBoot1.3开始引用注解@AutoConfigurationPackage。 该注解的实现类常常用于默认包获取。例如JPA实现获取默认包。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>自动配置原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring @Enable模块驱动原理]]></title>
    <url>%2F2019%2F08%2F05%2FEnable%E6%A8%A1%E5%9D%97%E9%A9%B1%E5%8A%A8%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spring @Enable模块驱动原理1:概述@Enable模块驱动在Spring3.1后开始支持。这里的模块指具备相同领域的功能组件集合,组合所形成的一个独立的单元。例如Web MVC模块,AspectJ代理模块,Caching模块,JMX模块,Async模块等。通过@Enable模块驱动,可以开启响应的模块功能。 @Enable模块驱动可以分为”注解驱动”和”接口编程”两种实现方式。都需要配合@Import注解。 注解驱动:通过@Configuration类和@Bean方法声明类。例如Web MVC模块实现,即@EnableWebMvc注解通过导入DelegatingWebMvcConfiguration来实现。 接口编程:ImportSelector和ImportBeanDefinitionRegistrar的实现类。例如Caching模块实现,即 @EnableCaching注解通过导入CachingConfigurationSelector实现。 2:实现示例(1):注解驱动基于ImportSelector接口 @EnableWebMvc模块实现: 123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123;&#125; 该注解通过@Import导入一个配置类DelegatingWebMvcConfiguration: 1234@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; ......&#125; 该配置类又继承自WebMvcConfigurationSupport,里面定义一些Web Mvc必须Bean声明。 所以，基于注解驱动的@Enable模块驱动其实就是通过@Import来导入一个配置类，以此实现相应模块的组件注册，当这些组件注册到IOC容器中，这个模块对应的功能也就可以使用了。 (2):接口编程@EnableCaching模块实现。 123456789101112131415@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(CachingConfigurationSelector.class)public @interface EnableCaching &#123; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; @EnableCaching*注解通过@Import导入CachingConfigurationSelector类,该类间接实现了ImportSelector*。 ImportSelector使用Spring注解元信息抽象AnnotationMetadata作为方法参数,该参数内容为导入ImportSelector实现的@Configuration类元信息,进而动态的选择一个或者多个其他@Configuration类进行导入。 1234567891011121314/*** Interface to be implemented by types that determine which @&#123;@link Configuration&#125;* class(es) should be imported based on a given selection criteria, usually one or more* annotation attributes.*/public interface ImportSelector &#123; /** * Select and return the names of which class(es) should be imported based on * the &#123;@link AnnotationMetadata&#125; of the importing @&#123;@link Configuration&#125; class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);&#125; 基于ImportBeanDefinitionRegistrar接口 @MapperScan模块实现 12345678910111213141516171819202122232425public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware &#123; private ResourceLoader resourceLoader; /** * &#123;@inheritDoc&#125; */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AnnotationAttributes annoAttrs = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); ... Class&lt;? extends Annotation&gt; annotationClass = annoAttrs.getClass("annotationClass"); if (!Annotation.class.equals(annotationClass)) &#123; scanner.setAnnotationClass(annotationClass); &#125; ... scanner.registerFilters(); scanner.doScan(StringUtils.toStringArray(basePackages)); &#125; ....&#125; 该接口的编程复杂度相比较于ImportSelector更高,接口将Bean定义的注册交给开发人员。常常配合ClassPathBeanDefinitionScanner类进行批量注册BeanDefinition。 ImportBeanDefinitionRegistrar:除注解元信息AnnotationMetadata作为入参外,接口将 Bean定义注册交给开发人员。 1234567891011121314151617181920/*** Interface to be implemented by types that register additional bean definitions when* processing @&#123;@link Configuration&#125; classes. Useful when operating at the bean definition* level (as opposed to &#123;@code @Bean&#125; method/instance level) is desired or necessary.*/public interface ImportBeanDefinitionRegistrar &#123; /** * Register bean definitions as necessary based on the given annotation metadata of * the importing &#123;@code @Configuration&#125; class. * &lt;p&gt;Note that &#123;@link BeanDefinitionRegistryPostProcessor&#125; types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to &#123;@code @Configuration&#125; * class processing. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry */ public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry);&#125; 3:@Enable模块驱动原理1:概述 @Enable模块驱动,模块无论来自于Spring内建,还是自定义,均使用@Import实现,并且该注解的职责在于装载导入类,将其定义为Spring Bean。导入主要为@Configuration Class,ImportSelector实现及ImportBeanDefinitionRegistrar实现。 2:源码实现 (1):装载@Configuration Class。 @Configuration从Spring3.0开始引入,该版本还未引入@ComponentScan。因此,开发人员经常看到XML元素&lt;context:component-scan/&gt;与&lt;context:annotation-config&gt;同时存在。根据Spring的”可扩展XML编写”特性,可以知道&lt;context:annotation-config&gt;所对应的BeanDefinitionParser实现为AnnotationConfigBeanDefinitionParser。 AnnotationConfigBeanDefinitionParser 1234567891011121314151617181920212223/** * Parser for the &amp;lt;context:annotation-config/&amp;gt; element. * * @author Mark Fisher * @author Juergen Hoeller * @author Christian Dupuis * @since 2.5 * @see AnnotationConfigUtils */public class AnnotationConfigBeanDefinitionParser implements BeanDefinitionParser &#123; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; Object source = parserContext.extractSource(element); // Obtain bean definitions for all relevant BeanPostProcessors. Set&lt;BeanDefinitionHolder&gt; processorDefinitions = AnnotationConfigUtils.registerAnnotationConfigProcessors(parserContext.getRegistry(), source); ... return null; &#125;&#125; AnnotationConfigUtils在Spring3.0增加了@Configuration Class的处理实现ConfigurationClassPostProcessor: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class AnnotationConfigUtils &#123; /** * The bean name of the internally managed Configuration annotation processor. */ public static final String CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME = &quot;org.springframework.context.annotation.internalConfigurationAnnotationProcessor&quot;; /** * The bean name of the internally managed BeanNameGenerator for use when processing * &#123;@link Configuration&#125; classes. Set by &#123;@link AnnotationConfigApplicationContext&#125; * and &#123;@code AnnotationConfigWebApplicationContext&#125; during bootstrap in order to make * any custom name generation strategy available to the underlying * &#123;@link ConfigurationClassPostProcessor&#125;. * @since 3.1.1 */ public static final String CONFIGURATION_BEAN_NAME_GENERATOR = &quot;org.springframework.context.annotation.internalConfigurationBeanNameGenerator&quot;; ... /** * Register all relevant annotation post processors in the given registry. * @param registry the registry to operate on */ public static void registerAnnotationConfigProcessors(BeanDefinitionRegistry registry) &#123; registerAnnotationConfigProcessors(registry, null); &#125; public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, Object source) &#123; ... Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(4); if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; ... return beanDefs; &#125; ...&#125; 简单的说,ConfigurationClassPostProcessor无论实在XML配置驱动还是在注解驱动使用场景下,均通过AnnotationConfigUtils.registerAnnotationConfigProcessors(registry,source)方法执行得到装载,且为最高优先级。不但处理了@Configuration Class,也负责@Bean方法的Bean定义。 (2):ConfigurationClassPostProcessor处理 //主要处理方法落在processConfigBeanDefinitions(registry) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware &#123; ... /** * Prepare the Configuration classes for servicing bean requests at runtime * by replacing them with CGLIB-enhanced subclasses. */ @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; int factoryId = System.identityHashCode(beanFactory); if (this.factoriesPostProcessed.contains(factoryId)) &#123; throw new IllegalStateException( "postProcessBeanFactory already called on this post-processor against " + beanFactory); &#125; this.factoriesPostProcessed.add(factoryId); if (!this.registriesPostProcessed.contains(factoryId)) &#123; // BeanDefinitionRegistryPostProcessor hook apparently not supported... // Simply call processConfigurationClasses lazily at this point then. processConfigBeanDefinitions((BeanDefinitionRegistry) beanFactory); &#125; enhanceConfigurationClasses(beanFactory); beanFactory.addBeanPostProcessor(new ImportAwareBeanPostProcessor(beanFactory)); &#125; /** * Build and validate a configuration model based on the registry of * &#123;@link Configuration&#125; classes. */ public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;BeanDefinitionHolder&gt;(); String[] candidateNames = registry.getBeanDefinitionNames(); for (String beanName : candidateNames) &#123; BeanDefinition beanDef = registry.getBeanDefinition(beanName); if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123; ... &#125; else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); &#125; &#125; // Return immediately if no @Configuration classes were found if (configCandidates.isEmpty()) &#123; return; &#125; // Sort by previously determined @Order value, if applicable Collections.sort(configCandidates, new Comparator&lt;BeanDefinitionHolder&gt;() &#123; @Override public int compare(BeanDefinitionHolder bd1, BeanDefinitionHolder bd2) &#123; int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return (i1 &lt; i2) ? -1 : (i1 &gt; i2) ? 1 : 0; &#125; &#125;); // Detect any custom bean name generation strategy supplied through the enclosing application context SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet &amp;&amp; sbr.containsSingleton(CONFIGURATION_BEAN_NAME_GENERATOR)) &#123; BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); this.componentScanBeanNameGenerator = generator; this.importBeanNameGenerator = generator; &#125; &#125; // Parse each @Configuration class ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(configCandidates); Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;ConfigurationClass&gt;(configCandidates.size()); do &#123; parser.parse(candidates); parser.validate(); Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;ConfigurationClass&gt;(parser.getConfigurationClasses()); configClasses.removeAll(alreadyParsed); // Read the model and create bean definitions based on its content if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader( registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; this.reader.loadBeanDefinitions(configClasses); alreadyParsed.addAll(configClasses); candidates.clear(); if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123; String[] newCandidateNames = registry.getBeanDefinitionNames(); Set&lt;String&gt; oldCandidateNames = new HashSet&lt;String&gt;(Arrays.asList(candidateNames)); Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;String&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) &#123; alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); &#125; for (String candidateName : newCandidateNames) &#123; if (!oldCandidateNames.contains(candidateName)) &#123; BeanDefinition bd = registry.getBeanDefinition(candidateName); if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp; !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123; candidates.add(new BeanDefinitionHolder(bd, candidateName)); &#125; &#125; &#125; candidateNames = newCandidateNames; &#125; &#125; while (!candidates.isEmpty()); // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes if (sbr != null) &#123; if (!sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123; sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry()); &#125; &#125; if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123; ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); &#125; &#125; /** * Post-processes a BeanFactory in search of Configuration class BeanDefinitions; * any candidates are then enhanced by a &#123;@link ConfigurationClassEnhancer&#125;. * Candidate status is determined by BeanDefinition attribute metadata. * @see ConfigurationClassEnhancer */ public void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) &#123; Map&lt;String, AbstractBeanDefinition&gt; configBeanDefs = new LinkedHashMap&lt;String, AbstractBeanDefinition&gt;(); for (String beanName : beanFactory.getBeanDefinitionNames()) &#123; BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName); if (ConfigurationClassUtils.isFullConfigurationClass(beanDef)) &#123; if (!(beanDef instanceof AbstractBeanDefinition)) &#123; throw new BeanDefinitionStoreException("Cannot enhance @Configuration bean definition '" + beanName + "' since it is not stored in an AbstractBeanDefinition subclass"); &#125; ... configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef); &#125; &#125; if (configBeanDefs.isEmpty()) &#123; // nothing to enhance -&gt; return immediately return; &#125; ConfigurationClassEnhancer enhancer = new ConfigurationClassEnhancer(); for (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : configBeanDefs.entrySet()) &#123; AbstractBeanDefinition beanDef = entry.getValue(); // If a @Configuration class gets proxied, always proxy the target class beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE); try &#123; // Set enhanced subclass of the user-specified bean class Class&lt;?&gt; configClass = beanDef.resolveBeanClass(this.beanClassLoader); Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, this.beanClassLoader); if (configClass != enhancedClass) &#123; ... beanDef.setBeanClass(enhancedClass); &#125; &#125; ... &#125; &#125; &#125; ...&#125; 执行期间,最重要的组件莫过于ConfigurationClassParser,它将已注册的Spring BeanDefinition进行注解元信息解析,其中两个parse重载方法分别采用CGLIB实现的AnnotationMetadataReadingVisitor和Java反射实现的 StandardAnnotationMetadata。 ConfigurationClassParser 1234567891011121314151617181920212223242526272829303132333435363738class ConfigurationClassParser&#123; protected void processConfigurationClass(ConfigurationClass configClass) throws IOException &#123; if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123; return; &#125; ConfigurationClass existingClass = this.configurationClasses.get(configClass); if (existingClass != null) &#123; if (configClass.isImported()) &#123; if (existingClass.isImported()) &#123; existingClass.mergeImportedBy(configClass); &#125; // Otherwise ignore new imported config class; existing non-imported class overrides it. return; &#125; else &#123; // Explicit bean definition found, probably replacing an import. // Let's remove the old one and go with the new one. this.configurationClasses.remove(configClass); for (Iterator&lt;ConfigurationClass&gt; it = this.knownSuperclasses.values().iterator(); it.hasNext();) &#123; if (configClass.equals(it.next())) &#123; it.remove(); &#125; &#125; &#125; &#125; // Recursively process the configuration class and its superclass hierarchy. SourceClass sourceClass = asSourceClass(configClass); do &#123; sourceClass = doProcessConfigurationClass(configClass, sourceClass); &#125; while (sourceClass != null); ... &#125;&#125; doProcessConfigurationClass处理以下问题: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123; // Recursively process any member (nested) classes first processMemberClasses(configClass, sourceClass); // Process any @PropertySource annotations for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), PropertySources.class, org.springframework.context.annotation.PropertySource.class)) &#123; if (this.environment instanceof ConfigurableEnvironment) &#123; processPropertySource(propertySource); &#125; else &#123; logger.warn("Ignoring @PropertySource annotation on [" + sourceClass.getMetadata().getClassName() + "]. Reason: Environment must implement ConfigurableEnvironment"); &#125; &#125; // Process any @ComponentScan annotations Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; for (AnnotationAttributes componentScan : componentScans) &#123; // The config class is annotated with @ComponentScan -&gt; perform the scan immediately Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); // Check the set of scanned definitions for any further config classes and parse recursively if needed for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; if (ConfigurationClassUtils.checkConfigurationClassCandidate( holder.getBeanDefinition(), this.metadataReaderFactory)) &#123; parse(holder.getBeanDefinition().getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125; &#125; // Process any @Import annotations processImports(configClass, sourceClass, getImports(sourceClass), true); // Process any @ImportResource annotations if (sourceClass.getMetadata().isAnnotated(ImportResource.class.getName())) &#123; AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class); String[] resources = importResource.getStringArray("locations"); Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass("reader"); for (String resource : resources) &#123; String resolvedResource = this.environment.resolveRequiredPlaceholders(resource); configClass.addImportedResource(resolvedResource, readerClass); &#125; &#125; // Process individual @Bean methods Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass); for (MethodMetadata methodMetadata : beanMethods) &#123; configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass)); &#125; // Process default methods on interfaces processInterfaces(configClass, sourceClass); // Process superclass, if any if (sourceClass.getMetadata().hasSuperClass()) &#123; String superclass = sourceClass.getMetadata().getSuperClassName(); if (!superclass.startsWith("java") &amp;&amp; !this.knownSuperclasses.containsKey(superclass)) &#123; this.knownSuperclasses.put(superclass, configClass); // Superclass found, return its annotation metadata and recurse return sourceClass.getSuperClass(); &#125; &#125; // No superclass -&gt; processing is complete return null; &#125; 处理@PropertySource注解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081private void processPropertySource(AnnotationAttributes propertySource) throws IOException &#123; String name = propertySource.getString("name"); if (!StringUtils.hasLength(name)) &#123; name = null; &#125; String encoding = propertySource.getString("encoding"); if (!StringUtils.hasLength(encoding)) &#123; encoding = null; &#125; String[] locations = propertySource.getStringArray("value"); Assert.isTrue(locations.length &gt; 0, "At least one @PropertySource(value) location is required"); boolean ignoreResourceNotFound = propertySource.getBoolean("ignoreResourceNotFound"); Class&lt;? extends PropertySourceFactory&gt; factoryClass = propertySource.getClass("factory"); PropertySourceFactory factory = (factoryClass == PropertySourceFactory.class ? DEFAULT_PROPERTY_SOURCE_FACTORY : BeanUtils.instantiateClass(factoryClass)); for (String location : locations) &#123; try &#123; String resolvedLocation = this.environment.resolveRequiredPlaceholders(location); Resource resource = this.resourceLoader.getResource(resolvedLocation); addPropertySource(factory.createPropertySource(name, new EncodedResource(resource, encoding))); &#125; catch (IllegalArgumentException ex) &#123; // Placeholders not resolvable if (ignoreResourceNotFound) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Properties location [" + location + "] not resolvable: " + ex.getMessage()); &#125; &#125; else &#123; throw ex; &#125; &#125; catch (IOException ex) &#123; // Resource not found when trying to open it if (ignoreResourceNotFound &amp;&amp; (ex instanceof FileNotFoundException || ex instanceof UnknownHostException)) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Properties location [" + location + "] not resolvable: " + ex.getMessage()); &#125; &#125; else &#123; throw ex; &#125; &#125; &#125; &#125; private void addPropertySource(PropertySource&lt;?&gt; propertySource) &#123; String name = propertySource.getName(); MutablePropertySources propertySources = ((ConfigurableEnvironment) this.environment).getPropertySources(); if (propertySources.contains(name) &amp;&amp; this.propertySourceNames.contains(name)) &#123; // We've already added a version, we need to extend it PropertySource&lt;?&gt; existing = propertySources.get(name); PropertySource&lt;?&gt; newSource = (propertySource instanceof ResourcePropertySource ? ((ResourcePropertySource) propertySource).withResourceName() : propertySource); if (existing instanceof CompositePropertySource) &#123; ((CompositePropertySource) existing).addFirstPropertySource(newSource); &#125; else &#123; if (existing instanceof ResourcePropertySource) &#123; existing = ((ResourcePropertySource) existing).withResourceName(); &#125; CompositePropertySource composite = new CompositePropertySource(name); composite.addPropertySource(newSource); composite.addPropertySource(existing); propertySources.replace(name, composite); &#125; &#125; else &#123; if (this.propertySourceNames.isEmpty()) &#123; propertySources.addLast(propertySource); &#125; else &#123; String firstProcessed = this.propertySourceNames.get(this.propertySourceNames.size() - 1); propertySources.addBefore(firstProcessed, propertySource); &#125; &#125; this.propertySourceNames.add(name); &#125; 处理@ComponentScan注解 123456789101112131415161718// Process any @ComponentScan annotationsSet&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; for (AnnotationAttributes componentScan : componentScans) &#123; // The config class is annotated with @ComponentScan -&gt; perform the scan immediately Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); // Check the set of scanned definitions for any further config classes and parse recursively if needed for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; if (ConfigurationClassUtils.checkConfigurationClassCandidate( holder.getBeanDefinition(), this.metadataReaderFactory)) &#123; parse(holder.getBeanDefinition().getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125;&#125; 处理@Import注解,@ImportResource,@Bean注解。其中@Import处理方法processImports与processConfigurationClass(ConfigurationClass configClass)形成递归调用。实现多层次@Import元标注的ConfigurationClass解析。解析后的ConfigurationClass将会被ConfigurationClassBeanDefinitionReader再次注册为SpringBean。ConfigurationClassBeanDefinitionReader将@Import,@ImportResource,@Bean所关联的Bean定义一并注册了。 (3):ConfigurationClassBeanDefinitionReader:将解析的Configuration Classs注册为Spring Bean。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class ConfigurationClassBeanDefinitionReader&#123; ... public void loadBeanDefinitions(Set&lt;ConfigurationClass&gt; configurationModel) &#123; TrackedConditionEvaluator trackedConditionEvaluator = new TrackedConditionEvaluator(); for (ConfigurationClass configClass : configurationModel) &#123; loadBeanDefinitionsForConfigurationClass(configClass, trackedConditionEvaluator); &#125; &#125; /** * Read a particular &#123;@link ConfigurationClass&#125;, registering bean definitions * for the class itself and all of its &#123;@link Bean&#125; methods. */ private void loadBeanDefinitionsForConfigurationClass(ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123; ... if (configClass.isImported()) &#123; registerBeanDefinitionForImportedConfigurationClass(configClass); &#125; for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123; loadBeanDefinitionsForBeanMethod(beanMethod); &#125; loadBeanDefinitionsFromImportedResources(configClass.getImportedResources()); loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars()); &#125; /** * Register the &#123;@link Configuration&#125; class itself as a bean definition. */ private void registerBeanDefinitionForImportedConfigurationClass(ConfigurationClass configClass) &#123; ... &#125; /** * Read the given &#123;@link BeanMethod&#125;, registering bean definitions * with the BeanDefinitionRegistry based on its contents. */ private void loadBeanDefinitionsForBeanMethod(BeanMethod beanMethod) &#123; ... &#125; private void loadBeanDefinitionsFromImportedResources( Map&lt;String, Class&lt;? extends BeanDefinitionReader&gt;&gt; importedResources) &#123; ... &#125; private void loadBeanDefinitionsFromRegistrars(Map&lt;ImportBeanDefinitionRegistrar, AnnotationMetadata&gt; registrars) &#123; for (Map.Entry&lt;ImportBeanDefinitionRegistrar, AnnotationMetadata&gt; entry : registrars.entrySet()) &#123; entry.getKey().registerBeanDefinitions(entry.getValue(), this.registry); &#125; &#125;&#125; (4):ConfigurationClassUtils:判定Configuration Class的级别 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596abstract class ConfigurationClassUtils &#123; private static final String CONFIGURATION_CLASS_FULL = "full"; private static final String CONFIGURATION_CLASS_LITE = "lite"; private static final String CONFIGURATION_CLASS_ATTRIBUTE = Conventions.getQualifiedAttributeName(ConfigurationClassPostProcessor.class, "configurationClass"); private static final String ORDER_ATTRIBUTE = Conventions.getQualifiedAttributeName(ConfigurationClassPostProcessor.class, "order"); private static final Log logger = LogFactory.getLog(ConfigurationClassUtils.class); private static final Set&lt;String&gt; candidateIndicators = new HashSet&lt;String&gt;(4); static &#123; candidateIndicators.add(Component.class.getName()); candidateIndicators.add(ComponentScan.class.getName()); candidateIndicators.add(Import.class.getName()); candidateIndicators.add(ImportResource.class.getName()); &#125; ... /** * Check the given metadata for a configuration class candidate * (or nested component class declared within a configuration/component class). * @param metadata the metadata of the annotated class * @return &#123;@code true&#125; if the given class is to be registered as a * reflection-detected bean definition; &#123;@code false&#125; otherwise */ public static boolean isConfigurationCandidate(AnnotationMetadata metadata) &#123; return (isFullConfigurationCandidate(metadata) || isLiteConfigurationCandidate(metadata)); &#125; /** * Check the given metadata for a full configuration class candidate * (i.e. a class annotated with &#123;@code @Configuration&#125;). * @param metadata the metadata of the annotated class * @return &#123;@code true&#125; if the given class is to be processed as a full * configuration class, including cross-method call interception */ public static boolean isFullConfigurationCandidate(AnnotationMetadata metadata) &#123; return metadata.isAnnotated(Configuration.class.getName()); &#125; /** * Check the given metadata for a lite configuration class candidate * (e.g. a class annotated with &#123;@code @Component&#125; or just having * &#123;@code @Import&#125; declarations or &#123;@code @Bean methods&#125;). * @param metadata the metadata of the annotated class * @return &#123;@code true&#125; if the given class is to be processed as a lite * configuration class, just registering it and scanning it for &#123;@code @Bean&#125; methods */ public static boolean isLiteConfigurationCandidate(AnnotationMetadata metadata) &#123; // Do not consider an interface or an annotation... if (metadata.isInterface()) &#123; return false; &#125; // Any of the typical annotations found? for (String indicator : candidateIndicators) &#123; if (metadata.isAnnotated(indicator)) &#123; return true; &#125; &#125; // Finally, let's look for @Bean methods... try &#123; return metadata.hasAnnotatedMethods(Bean.class.getName()); &#125; ... &#125; /** * Determine whether the given bean definition indicates a full &#123;@code @Configuration&#125; * class, through checking &#123;@link #checkConfigurationClassCandidate&#125;'s metadata marker. */ public static boolean isFullConfigurationClass(BeanDefinition beanDef) &#123; return CONFIGURATION_CLASS_FULL.equals(beanDef.getAttribute(CONFIGURATION_CLASS_ATTRIBUTE)); &#125; /** * Determine whether the given bean definition indicates a lite &#123;@code @Configuration&#125; * class, through checking &#123;@link #checkConfigurationClassCandidate&#125;'s metadata marker. */ public static boolean isLiteConfigurationClass(BeanDefinition beanDef) &#123; return CONFIGURATION_CLASS_LITE.equals(beanDef.getAttribute(CONFIGURATION_CLASS_ATTRIBUTE)); &#125; ...&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Enable模块驱动</tag>
        <tag>ImportSelector</tag>
        <tag>ImportBeanDefinitionRegistrar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring事件监听机制]]></title>
    <url>%2F2019%2F08%2F05%2FSpring%E4%BA%8B%E4%BB%B6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Spring提供的基本事件1: ContextRefreshEvent: 上下文刷新事件当ApplicationContext容器初始化完成或者被刷新的时候，就会发布该事件。比如调用ConfigurableApplicationContext接口中的refresh()方法。此处的容器初始化指的是所有的Bean都被成功装载，后处理（post-processor）Bean被检测到并且激活，所有单例Bean都被预实例化，ApplicationContext容器已经可以使用。只要上下文没有被关闭，刷新可以被多次触发。XMLWebApplicationContext支持热刷新，GenericApplicationContext不支持热刷新。 2: ContextStartedEvent: 上下文启动事件当ApplicationContext启动的时候发布事件，即调用ConfigurableApplicationContext接口的start方法的时候。这里的启动是指，所有的被容器管理生命周期的Bean接受到一个明确的启动信号。在经常需要停止后重新启动的场合比较适用。 3: ContextStoppedEvent: 上下文停止事件当ApplicationContext容器停止的时候发布事件，调用ConfigurableApplicationContext的close方法的时候。这里的停止是指，所有被容器管理生命周期的Bean接到一个明确的停止信号。 4: ContextClosedEvent: 上下文关闭事件当ApplicationContext关闭的时候发布事件，即调用ConfigurableApplicationContext的close方法的时候，关闭指的是所有的单例Bean都被销毁。关闭上下后，不能重新刷新或者重新启动。 5: RequestHandledEvent: Spring处理Web请求结束事件只能用于DispatcherServlet的web应用，Spring处理用户请求结束后，系统会触发该事件。 123456789101112131415private void publishRequestHandledEvent( HttpServletRequest request, HttpServletResponse response, long startTime, Throwable failureCause) &#123; if (this.publishEvents) &#123; // Whether or not we succeeded, publish an event. long processingTime = System.currentTimeMillis() - startTime; int statusCode = (responseGetStatusAvailable ? response.getStatus() : -1); this.webApplicationContext.publishEvent( new ServletRequestHandledEvent(this, request.getRequestURI(), request.getRemoteAddr(), request.getMethod(), getServletConfig().getServletName(), WebUtils.getSessionId(request), getUsernameForRequest(request), processingTime, failureCause, statusCode)); &#125;&#125; 实现 ApplicationEvent，容器事件，必须被ApplicationContext发布。ApplicationListener，监听器，可由容器中任何监听器Bean担任。实现了ApplicationListener接口之后，需要实现方法onApplicationEvent()，在容器将所有的Bean都初始化完成之后，就会执行该方法。 观察者模式概述观察者模式，Observer Pattern。定义对象间一对多的依赖关系，使得每当一个对象改变状态，则所有依赖与它的对象都会得到通知，并被自动更新。 观察者模式的角色名称： Subject被观察者:定义被观察者必须实现的职责，它能动态的增加取消观察者，它一般是抽象类或者是实现类，仅仅完成作为被观察者必须实现的职责：管理观察者并通知观察者。 Observer观察者:观察者接受到消息后，即进行更新操作，对接收到的信息进行处理。 ConcreteSubject具体的被观察者:定义被观察者自己的业务逻辑，同时定义对哪些事件进行通知。 ConcreteObserver具体的观察者:每个观察者接收到消息后的处理反应是不同的，每个观察者都有自己的处理逻辑。 观察者模式的优点 观察者和被观察者之间是抽象耦合，不管是增加观察者还是被观察者都非常容易扩展。实现松耦合 建立一套触发机制。 观察者模式的缺点观察者模式需要考虑开发效率和运行效率问题，一个被观察者，多个观察者，开发和调试比较复杂，Java消息的通知默认是顺序执行的，一个观察者卡壳，会影响整体的执行效率。这种情况一般考虑异步的方式。例如考虑使用消息队列(发布/订阅模式)。 观察者模式和发布订阅模式区别虽然两种模式都存在订阅者和发布者（具体观察者可认为是订阅者、具体目标可认为是发布者），但是观察者模式是由具体目标调度的，即观察者和被观察者彼此相识，而发布/订阅模式是统一由调度中心调的，所以观察者模式的订阅者与发布者之间是存在依赖的，而发布/订阅模式则不会(完全解耦)。 使用场景 观察者模式，多用于单个应用内部 发布订阅模式，则更多的是一种跨应用的模式(cross-application pattern)，比如我们常用的消息中间件 Spring中观察者模式前言Spring在事件处理机制中使用了观察者模式： 事件，ApplicationEvent，该抽象类继承了EventObject，EventObject是JDK中的类，并建议所有的事件都应该继承自EventObject。 事件监听器，ApplicationListener，是一个接口，该接口继承了EventListener接口。EventListener接口是JDK中的，建议所有的事件监听器都应该继承EventListener。 事件发布，ApplicationEventPublisher，ApplicationContext继承了该接口，在ApplicationContext的抽象实现类AbstractApplicationContext中做了实现 AbstractApplicationContext类中publishEvent方法实现: 1234567891011public void publishEvent(ApplicationEvent event) &#123; Assert.notNull(event, "Event must not be null"); if (logger.isTraceEnabled()) &#123; logger.trace("Publishing event in " + getDisplayName() + ": " + event); &#125; //事件发布委托给ApplicationEventMulticaster来执行 getApplicationEventMulticaster().multicastEvent(event); if (this.parent != null) &#123; this.parent.publishEvent(event); &#125;&#125; ApplicationEventMulticaster的multicastEvent方法的实现在SimpleApplicationEventMulticaster类中： 12345678910111213141516public void multicastEvent(final ApplicationEvent event) &#123; //获得监听器集合，遍历监听器，可支持同步和异步的广播事件 for (final ApplicationListener listener : getApplicationListeners(event)) &#123; Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(new Runnable() &#123; public void run() &#123; listener.onApplicationEvent(event); &#125; &#125;); &#125; else &#123; listener.onApplicationEvent(event); &#125; &#125;&#125; 这就执行了了onApplicationEvent方法，这里是事件发生的地方。 Spring如何根据事件找到事件对应的监听器在Spring容器初始化的时候，也就是在refresh方法中： 1234567891011121314151617public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; ...... try &#123; ...... // Initialize event multicaster for this context. //初始化一个事件注册表 initApplicationEventMulticaster(); ...... // Check for listener beans and register them. //注册事件监听器 registerListeners(); ...... &#125; &#125;&#125; initApplicationEventMulticaster方法初始化事件注册表： 12345678910111213protected void initApplicationEventMulticaster() &#123; //获得beanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //先查找BeanFactory中是否有ApplicationEventMulticaster if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); &#125; else &#123;//如果BeanFactory中不存在，就创建一个SimpleApplicationEventMulticaster this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); &#125;&#125; 在AbstractApplicationEventMulticaster类中有如下属性： 123456//注册表private final ListenerRetriever defaultRetriever = new ListenerRetriever(false);//注册表的缓存private final Map&lt;ListenerCacheKey, ListenerRetriever&gt; retrieverCache = new ConcurrentHashMap&lt;ListenerCacheKey, ListenerRetriever&gt;(64);private BeanFactory beanFactory; ListenerRetriever的结构如下： 123456//用来存放监听事件public final Set&lt;ApplicationListener&gt; applicationListeners;//存放监听事件的类名称public final Set&lt;String&gt; applicationListenerBeans;private final boolean preFiltered; 初始化注册表之后，就会把事件注册到注册表中，registerListeners()： 12345678910111213protected void registerListeners() &#123; //获取所有的Listener，把事件的bean放到ApplicationEventMulticaster中 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); //把事件的名称放到ApplicationListenerBean里去。 for (String lisName : listenerBeanNames) &#123; getApplicationEventMulticaster().addApplicationListenerBean(lisName); &#125;&#125; Spring使用反射机制，通过方法getBeansOfType获取所有继承了ApplicationListener接口的监听器，然后把监听器放到注册表中，所以我们可以在Spring配置文件中配置自定义监听器，在Spring初始化的时候，会把监听器自动注册到注册表中去。 ApplicationContext发布事件可以参考上面的内容。发布事件的时候的一个方法，getApplicationListeners： 12345678910111213141516171819202122232425262728293031323334353637383940414243protected Collection&lt;ApplicationListener&gt; getApplicationListeners(ApplicationEvent event) &#123; //获取事件类型 Class&lt;? extends ApplicationEvent&gt; eventType = event.getClass(); //或去事件源类型 Class sourceType = event.getSource().getClass(); ListenerCacheKey cacheKey = new ListenerCacheKey(eventType, sourceType); //从缓存中查找ListenerRetriever ListenerRetriever retriever = this.retrieverCache.get(cacheKey); //缓存中存在，直接返回对应的Listener if (retriever != null) &#123; return retriever.getApplicationListeners(); &#125; else &#123;//缓存中不存在，就获取相应的Listener retriever = new ListenerRetriever(true); LinkedList&lt;ApplicationListener&gt; allListeners = new LinkedList&lt;ApplicationListener&gt;(); Set&lt;ApplicationListener&gt; listeners; Set&lt;String&gt; listenerBeans; synchronized (this.defaultRetriever) &#123; listeners = new LinkedHashSet&lt;ApplicationListener&gt;(this.defaultRetriever.applicationListeners); listenerBeans = new LinkedHashSet&lt;String&gt;(this.defaultRetriever.applicationListenerBeans); &#125; //根据事件类型，事件源类型，获取所需要的监听事件 for (ApplicationListener listener : listeners) &#123; if (supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListeners.add(listener); allListeners.add(listener); &#125; &#125; if (!listenerBeans.isEmpty()) &#123; BeanFactory beanFactory = getBeanFactory(); for (String listenerBeanName : listenerBeans) &#123; ApplicationListener listener = beanFactory.getBean(listenerBeanName, ApplicationListener.class); if (!allListeners.contains(listener) &amp;&amp; supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListenerBeans.add(listenerBeanName); allListeners.add(listener); &#125; &#125; &#125; OrderComparator.sort(allListeners); this.retrieverCache.put(cacheKey, retriever); return allListeners; &#125;&#125; 根据事件类型，事件源类型获取所需要的监听器supportsEvent(listener, eventType, sourceType)： 1234567protected boolean supportsEvent( ApplicationListener listener, Class&lt;? extends ApplicationEvent&gt; eventType, Class sourceType) &#123; SmartApplicationListener smartListener = (listener instanceof SmartApplicationListener ? (SmartApplicationListener) listener : new GenericApplicationListenerAdapter(listener)); return (smartListener.supportsEventType(eventType) &amp;&amp; smartListener.supportsSourceType(sourceType));&#125; 这里没有进行实际的处理，实际处理在smartListener.supportsEventType(eventType)和smartListener.supportsSourceType(sourceType)方法中。 smartListener.supportsEventType(eventType)： 12345678910public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) &#123; Class typeArg = GenericTypeResolver.resolveTypeArgument(this.delegate.getClass(), ApplicationListener.class); if (typeArg == null || typeArg.equals(ApplicationEvent.class)) &#123; Class targetClass = AopUtils.getTargetClass(this.delegate); if (targetClass != this.delegate.getClass()) &#123; typeArg = GenericTypeResolver.resolveTypeArgument(targetClass, ApplicationListener.class); &#125; &#125; return (typeArg == null || typeArg.isAssignableFrom(eventType));&#125; 该方法主要的逻辑就是根据事件类型判断是否和监听器参数泛型的类型是否一致。 smartListener.supportsSourceType(sourceType)方法的实现为： 123public boolean supportsSourceType(Class&lt;?&gt; sourceType) &#123; return true;&#125; 定义自己的监听器要明确指定参数泛型，表明该监听器支持的事件，如果不指明具体的泛型，则没有监听器监听事件。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring事件监听机制</tag>
        <tag>观察者模式</tag>
        <tag>设计模式</tag>
        <tag>发布订阅模式</tag>
        <tag>Spring提供基本事件</tag>
        <tag>Spring事件源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义SpringBoot自动装配]]></title>
    <url>%2F2019%2F08%2F05%2F%E8%87%AA%E5%AE%9A%E4%B9%89SpringBoot%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[自定义SpringBoot自动装配1：自动装配Class命名规则AutoConfiguration，其中\代表功能或者模块名。 2：自动装配package命名规则123456$&#123;root-package&#125; |- autoconfigure |- $&#123;module-package&#125; |- *AutoConfiguration |- $&#123;sub-module-package&#125; |- ... 其中${root_package}是根模块，如com.ley。 ${module_package}是功能模块，如web.servlet。 而${sub_module_package}是子模块，如error。 3：自定义SpringBootStarter官方建议将自动装配模块代码存放到autoconfigure模块中，starter模块依赖该模块，并且附加其他需要依赖。当然也可以将autoconfigure和stater合并到单模块。 (1)：Spring Boot Starter命名规则 开发人员将Starter发布为${module}-spring-boot-autoconfigure和${module}-spring-boot-starter两个jar文件。 开发人员不要使用server,management,spring等作为配置Key命名空间。尽量采用独立的命名空间。 (2)：实现Spring Boot Starter (a)：新建Spring Boot Starter工程—–formatter-spring-boot-autoconfigure。 构建一个Maven功能，pom.xml如下。 123456789101112131415161718192021&lt;dependencies&gt; &lt;!-- Compile dependencies --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- @ConfigurationProperties annotation processing (metadata for IDEs) --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; (b)：实现DefaultFormatter自动装配—-FormatterAutoConfiguration (c)：META-INF/spring.factories资源声明FormatterAutoConfiguration 123# FormatterAutoConfiguration 自动装配声明org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ com.ley.formatter.autoconfigure.FormatterAutoConfiguration (d)：构建Spring Boot Starter—-formatter-spring-boot-starter 1234567891011121314151617181920&lt;dependencies&gt; &lt;!--formatter spring boot autoconfigure--&gt; &lt;dependency&gt; &lt;groupId&gt;com.gitee.ley1996&lt;/groupId&gt; &lt;artifactId&gt;formatter-spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring boot 基础依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;!-- 说明formatter-spring-boot-starter不应该 传递spring-boot-starter依赖。 --&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在开发Spring Boot Starter的过程中，请保持spring-boot-starter等相关依赖声明为 、&lt;optional&gt;true&lt;/optional&gt;。 4：Spring Boot 提交化自动装配条件注解总结： Class Conditions Bean Conditions Property Conditions Resource Conditions Web Application Conditions SpEL Expression Conditions 4.1：Class条件注解 ConditionalOnClass：当指定类存在时，在Sprign Boot 1.0~2.0稳定。 ConditionalOnMissingClass：当指定类不存在时，从Spring Boot 1.4开始才保持稳定。推荐使用value()替代。当指定类不存在时，并不需要该类显示地依赖到当前工程或者Starter。 4.2：Bean条件注解 ConditionalOnBean：匹配BeanFactory中Bean的类型和名称。 其中Bean查找策略为SearchStrategy，包含当前，父类及所有。 ConditionalOnMissingBean：当指定Bean不存在时。从Spring Boot 1.2.5开始，增加ignored()和ignoredType()两个方法，用于忽略或者排除指定Bean。 4.3：属性条件注解 ConditionalOnProperty为属性条件注解，其属性来源于Spring Environment。其中Java系统属性(systemProperties)和环境变量(systemEnvironment)是典型的Spring Environment属性来源。在SpringBoot环境中，application.properties或者application.yml也是其中来源之一。 当自动装配组件需要默认装配时，可以使用matchIfMissing()属性值调整为true。 4.4：Resource条件注解 ConditionOnResource为Resource条件注解。其中resources()指定只有资源必须存在方可成立。 4.5：Web应用条件注解。 ConditionalOnWebApplication：判断当前应用是Web类型。 ConditionalOnNotWebApplication：当前应用不是Web类型。 4.6：Spring表达式条件注解 ConditionalOnExpression，其中value()用于评估表达式的真伪。当表达多组配置属性时，可以使用@ConditionalOnExpression。例如${formatter.enabled:true} 总结使用Spring Boot提供的条件注解,以及自动装配顺序注解,实现自己的配置类,然后在META-INF/ spring.factories中声明该类即可。如下所示： 123# FormatterAutoConfiguration 自动装配声明org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ com.ley.formatter.autoconfigure.FormatterAutoConfiguration]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>SpringBoot自动装配</tag>
        <tag>条件化注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring整合Mybatis原理探索]]></title>
    <url>%2F2019%2F08%2F05%2FSpring%E6%95%B4%E5%90%88Mybatis%E5%8E%9F%E7%90%86%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[Spring整合Mybatis原理探索@MapperScan注解实现 1:MapperScannerRegistrar类 实现ImportBeanDefinitionRegistrar接口,注册默认@Mapper注解标注的接口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //获取@MapperScan注解上属性 AnnotationAttributes mapperScanAttrs = AnnotationAttributes .fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); if (mapperScanAttrs != null) &#123; registerBeanDefinitions(mapperScanAttrs, registry); &#125; &#125; void registerBeanDefinitions(AnnotationAttributes annoAttrs, BeanDefinitionRegistry registry) &#123;//扫描指定包下包含默认Mybatis注解@Mapper的接口,并注册到Spring Bean工厂中 ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); // this check is needed in Spring 3.1 Optional.ofNullable(resourceLoader).ifPresent(scanner::setResourceLoader); Class&lt;? extends Annotation&gt; annotationClass = annoAttrs.getClass("annotationClass"); if (!Annotation.class.equals(annotationClass)) &#123; scanner.setAnnotationClass(annotationClass); &#125; Class&lt;?&gt; markerInterface = annoAttrs.getClass("markerInterface"); if (!Class.class.equals(markerInterface)) &#123; scanner.setMarkerInterface(markerInterface); &#125; Class&lt;? extends BeanNameGenerator&gt; generatorClass = annoAttrs.getClass("nameGenerator"); if (!BeanNameGenerator.class.equals(generatorClass)) &#123; scanner.setBeanNameGenerator(BeanUtils.instantiateClass(generatorClass)); &#125; Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = annoAttrs.getClass("factoryBean"); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) &#123; scanner.setMapperFactoryBean(BeanUtils.instantiateClass(mapperFactoryBeanClass)); &#125; scanner.setSqlSessionTemplateBeanName(annoAttrs.getString("sqlSessionTemplateRef")); scanner.setSqlSessionFactoryBeanName(annoAttrs.getString("sqlSessionFactoryRef")); List&lt;String&gt; basePackages = new ArrayList&lt;&gt;(); basePackages.addAll( Arrays.stream(annoAttrs.getStringArray("value")) .filter(StringUtils::hasText) .collect(Collectors.toList())); basePackages.addAll( Arrays.stream(annoAttrs.getStringArray("basePackages")) .filter(StringUtils::hasText) .collect(Collectors.toList())); basePackages.addAll( Arrays.stream(annoAttrs.getClassArray("basePackageClasses")) .map(ClassUtils::getPackageName) .collect(Collectors.toList())); scanner.registerFilters(); scanner.doScan(StringUtils.toStringArray(basePackages)); &#125; 2:ClassPathMapperScanner 继承了ClassPathBeanDefinitionScanner类,该类扫描指定包下的模式注解,并注册到Spring Bean工厂中。 实现主要方法研究 注册BeanDefinition过滤接口 12345678910111213141516171819202122232425262728293031323334353637/** * Configures parent scanner to search for the right interfaces. It can search * for all interfaces or just for those that extends a markerInterface or/and * those annotated with the annotationClass */public void registerFilters() &#123; boolean acceptAllInterfaces = true; // if specified, use the given annotation and / or marker interface if (this.annotationClass != null) &#123; addIncludeFilter(new AnnotationTypeFilter(this.annotationClass)); acceptAllInterfaces = false; &#125; // override AssignableTypeFilter to ignore matches on the actual marker interface if (this.markerInterface != null) &#123; //由于生成的BeanDefinition为MapperFactoryBean,所以BeanClass不是原来的类名 addIncludeFilter(new AssignableTypeFilter(this.markerInterface) &#123; @Override protected boolean matchClassName(String className) &#123; return false; &#125; &#125;); acceptAllInterfaces = false; &#125; if (acceptAllInterfaces) &#123; // default include filter that accepts all classes addIncludeFilter((metadataReader, metadataReaderFactory) -&gt; true); &#125; // exclude package-info.java addExcludeFilter((metadataReader, metadataReaderFactory) -&gt; &#123; String className = metadataReader.getClassMetadata().getClassName(); return className.endsWith("package-info"); &#125;);&#125; 注册MapperFactoryBean 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &#123; definition = (GenericBeanDefinition) holder.getBeanDefinition(); String beanClassName = definition.getBeanClassName(); LOGGER.debug(() -&gt; "Creating MapperFactoryBean with name '" + holder.getBeanName() + "' and '" + beanClassName + "' mapperInterface"); // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean //添加要与类型匹配的通用参数值注意：单个通用参数值将只使用一次*，而不是多次匹配。 //MapperFactoryBean是个泛型类,泛型参数是Mybatis的DAO全类限定名 definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); / definition.setBeanClass(this.mapperFactoryBean.getClass()); definition.getPropertyValues().add("addToConfig", this.addToConfig); boolean explicitFactoryUsed = false; if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) &#123; //如果配置了SqlSesiionFactoryBean,获取运行期间的SqlSessionFactory Bean引用 definition.getPropertyValues().add("sqlSessionFactory", new RuntimeBeanReference(this.sqlSessionFactoryBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionFactory != null) &#123; definition.getPropertyValues().add("sqlSessionFactory", this.sqlSessionFactory); explicitFactoryUsed = true; &#125; if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn(() -&gt; "Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored."); &#125; definition.getPropertyValues().add("sqlSessionTemplate", new RuntimeBeanReference(this.sqlSessionTemplateBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionTemplate != null) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn(() -&gt; "Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored."); &#125; definition.getPropertyValues().add("sqlSessionTemplate", this.sqlSessionTemplate); explicitFactoryUsed = true; &#125; if (!explicitFactoryUsed) &#123; LOGGER.debug(() -&gt; "Enabling autowire by type for MapperFactoryBean with name '" + holder.getBeanName() + "'."); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); &#125; &#125; &#125; 设置候选BeanDefinition条件 12345//判断候选的BeanDefinition是否是接口和独立类@Overrideprotected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) &#123; return beanDefinition.getMetadata().isInterface() &amp;&amp; beanDefinition.getMetadata().isIndependent();&#125; 相关类 ClassPathMapperScanner:扫描Bean并注册Bean工厂中 MapperFactoryBean:Mapper Bean工程 MapperScannerRegistrar:提供解析MapperScan注解和批量注册Bean SqlSessionDaoSupport:提供SqlSession 总结实现批量注册Bean时,提供扫描包注解+标注候选注解+实现ImportBeanDefinitionRegistrar接口+ 继承ClassPathBeanDefinitionScanner+实现FactoryBean接口。]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>Spring</tag>
        <tag>MapperScan注解实现原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Environment抽象]]></title>
    <url>%2F2019%2F08%2F05%2FSpring%20Environment%E6%8A%BD%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[Spring Environment抽象1:概述Spring中Environment是Spring3.1版本引入的,是Spring核心框架定义的一个接口,用来表示整个应用运行时环境。该环境模型只接受两种应用环境profiles(配置文件)和properties(属性)。与属性访问相关的方法通过PropertyResolver超接口访问。 建模关键 profile(配置文件) 一个profile是一组Bean定义的逻辑分组,只有当配置文件被激活的时候,才会将对应逻辑上组织的Bean定义注册到容器中。 Bean添加到profile可以通过XML或者Annotation方式。 Environment对象对于profile机制所扮演的角色是用来指定哪些profile是当前活跃或者缺省活跃。可以通过getActiveProfiles或者getDefaultProfiles获取。 proprety(属性) 一个应用属性有很多来源:属性文件(properties files),JVM系统属性(getSystemProperties),系统变量属性(getSystemEnvironment),JNDI,servlet上下文参数,临时属性对象,Maps等。 Environment对于property所扮演的角色提供给使用一个方便服务接口用于 配置属性源 从属性源解析和获取属性 容器上下文(ApplicationContext)所获取的bean,如果想直接使用Environment对象访问profile状态或者获取属性。有以下方式。 EnvironmentAware接口 @Inject 或者 @Autowired注入一个 Environment对象 绝大多数情况,bean都不需要直接访问Environment对象,而是通过类似@Value注解方式把属性值注入进来。 这个接口定义在包 org.springframework.core.env 中。下面是Spring围绕环境抽象Environment各个接口/类之间的继承关系: 2:Environment接口相关类介绍 接口|类 介绍 PropertyResolver 接口,抽象对属性源的访问比如是否包含某个属性，读取属性，解析占位符，将读取到的属性转换成指定类型 (提供读操作)默认实现PropertySourcesPropertyResolver Environment 接口,继承自PropertyResolver,对环境属性访问和default/active profile访问的抽象 。 ConfigurablePropertyResolver 接口，为PropertyResolver接口抽象的属性源访问做了配置方面的增强。(提供写操作。) ConfigurableEnvironment 接口，在所继承的接口之上增加了设置defaut/active profile的能力，增加/删除环境对象中属性源的能力 ConfigurableWebEnvironment 接口，向接口ConfigurableEnvironment增强了根据Servlet上下文/配置初始化属性源的能力 AbstractEnvironment Environment抽象基类，实现了ConfigurableEnvironment StandardEnvironment 实现类,针对标准Spring应用(非Web应用)环境, 在AbstractEnvironment基础上提供了属性源systemEnvironment(来自System.getenv())和systemProperties(来自System.getProperties()) StandardServletEnvironment 实现类,针对标准Spring Servlet Web应用的环境， 增加了servletContextInitParams/servletConfigInitParams/jndiProperties 3:外部化配置抽象相关类 接口|类 介绍 PropertySource 用来抽象属性键值对(外部化配置,即属性源)配置基类。例如Map,Properties,ServletConfig,ServletContext PropertySources 对PropertySource抽象属性键值对外部化配置提供集合操作。 MutablePropertySources PropertySources默认实现。 MapPropertySource Map对象中读取属性键值对 PropertiesPropertySource Properties对象中读取属性键值对 ResourcePropertySource Resource对象读取中读取属性键值对。只支持.xml和.properties文件。底层实现使用了工具类PropertiesLoaderUtils。 CompositePropertySource 聚合一组PropertySource。 Web环境实现类和JNDI实现类和随机数实现类 ServletConfigPropertySource,ServletContextPropertySource, JndiPropertySource,RandomValuePropertySource 命令行参数实现类 CommandLinePropertySource 4:混淆定义 上下文:用来处理分层传递抽象,代表着应用。 环境:当前上下文运行环境,存储各种全局变量。比如JDK信息,内存信息等等。 5:核心API PropertySource:属性源。key-value属性对抽象 PropertyResolver:属性解析器。用于解析相应key的value Profile:配置。只有激活的配置profile的组件/配置才会注册到Spring容器,类似于maven中profile。 Environment:环境，本身也是个属性解析器PropertyResolver。 6:属性解析器相关类详细介绍PropertySourcesPropertyResolver该类是Spring内建提供的PropertyResolver唯一实现类。环境抽象Environment属性解析委托给该类。包括对属性类型之间必要转换。Converter和ConverterService。实际的占位符解析委托给PropertyPlaceholderHelper。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class PropertySourcesPropertyResolver extends AbstractPropertyResolver &#123; ... @Nullable private final PropertySources propertySources; //内部持有一组PropertySource // 由此可以看出propertySources的顺序很重要~~~ // 并且还能处理占位符~~~~~ resolveNestedPlaceholders支持内嵌、嵌套占位符 @Nullable protected &lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetValueType, boolean resolveNestedPlaceholders) &#123; if (this.propertySources != null) &#123; for (PropertySource&lt;?&gt; propertySource : this.propertySources) &#123; Object value = propertySource.getProperty(key); if (value != null) &#123; if (resolveNestedPlaceholders &amp;&amp; value instanceof String) &#123; value = resolveNestedPlaceholders((String) value); &#125; logKeyFound(key, propertySource, value); return convertValueIfNecessary(value, targetValueType); &#125; &#125; &#125; return null; &#125; ...&#125;public abstract class AbstractPropertyResolver implements ConfigurablePropertyResolver &#123; ... @Nullable private volatile ConfigurableConversionService conversionService; @Nullable private PropertyPlaceholderHelper nonStrictHelper; @Nullable private PropertyPlaceholderHelper strictHelper; private boolean ignoreUnresolvableNestedPlaceholders = false; private String placeholderPrefix = SystemPropertyUtils.PLACEHOLDER_PREFIX; private String placeholderSuffix = SystemPropertyUtils.PLACEHOLDER_SUFFIX; @Nullable private String valueSeparator = SystemPropertyUtils.VALUE_SEPARATOR; private final Set&lt;String&gt; requiredProperties = new LinkedHashSet&lt;&gt;(); ...&#125; 7:应用环境抽象EnvironmentEnvironment接口:环境的读操作 1234567891011121314151617181920212223242526272829303132333435363738394041public interface Environment extends PropertyResolver &#123; /** * Return the set of profiles explicitly made active for this environment. Profiles * are used for creating logical groupings of bean definitions to be registered * conditionally, for example based on deployment environment. Profiles can be * activated by setting &#123;@linkplain AbstractEnvironment#ACTIVE_PROFILES_PROPERTY_NAME * "spring.profiles.active"&#125; as a system property or by calling * &#123;@link ConfigurableEnvironment#setActiveProfiles(String...)&#125;. * &lt;p&gt;If no profiles have explicitly been specified as active, then any * &#123;@linkplain #getDefaultProfiles() default profiles&#125; will automatically be activated. * @see #getDefaultProfiles * @see ConfigurableEnvironment#setActiveProfiles * @see AbstractEnvironment#ACTIVE_PROFILES_PROPERTY_NAME */ String[] getActiveProfiles(); /** * Return the set of profiles to be active by default when no active profiles have * been set explicitly. * @see #getActiveProfiles * @see ConfigurableEnvironment#setDefaultProfiles * @see AbstractEnvironment#DEFAULT_PROFILES_PROPERTY_NAME */ String[] getDefaultProfiles(); /** * Return whether one or more of the given profiles is active or, in the case of no * explicit active profiles, whether one or more of the given profiles is included in * the set of default profiles. If a profile begins with '!' the logic is inverted, * i.e. the method will return true if the given profile is &lt;em&gt;not&lt;/em&gt; active. * For example, &lt;pre class="code"&gt;env.acceptsProfiles("p1", "!p2")&lt;/pre&gt; will * return &#123;@code true&#125; if profile 'p1' is active or 'p2' is not active. * @throws IllegalArgumentException if called with zero arguments * or if any profile is &#123;@code null&#125;, empty or whitespace-only * @see #getActiveProfiles * @see #getDefaultProfiles */ boolean acceptsProfiles(String... profiles);&#125; ConfigurableEnvironment:增加环境的写操作 1234567891011121314151617181920public interface ConfigurableEnvironment extends Environment, ConfigurablePropertyResolver &#123; // 指定该环境下的 profile 集 void setActiveProfiles(String... profiles); // 增加此环境的 profile void addActiveProfile(String profile); // 设置默认的 profile void setDefaultProfiles(String... profiles); // 返回此环境的 PropertySources MutablePropertySources getPropertySources(); // 尝试返回 System.getenv() 的值，若失败则返回通过 System.getenv(string) 的来访问各个键的映射 Map&lt;String, Object&gt; getSystemEnvironment(); // 尝试返回 System.getProperties() 的值，若失败则返回通过 System.getProperties(string) 的来访问各个键的映射 Map&lt;String, Object&gt; getSystemProperties(); void merge(ConfigurableEnvironment parent);&#125; AbstractEnvironment:作为环境接口抽象实现,主要实现了profile相关功能 12345678910111213141516171819202122232425262728293031public abstract class AbstractEnvironment implements ConfigurableEnvironment &#123; public static final String IGNORE_GETENV_PROPERTY_NAME = "spring.getenv.ignore"; // 请参考：ConfigurableEnvironment#setActiveProfiles public static final String ACTIVE_PROFILES_PROPERTY_NAME = "spring.profiles.active"; // 请参考：ConfigurableEnvironment#setDefaultProfiles public static final String DEFAULT_PROFILES_PROPERTY_NAME = "spring.profiles.default"; private final Set&lt;String&gt; defaultProfiles = new LinkedHashSet&lt;&gt;(getReservedDefaultProfiles()); // 默认的profile名称 protected static final String RESERVED_DEFAULT_PROFILE_NAME = "default"; ... protected Set&lt;String&gt; doGetActiveProfiles() &#123; synchronized (this.activeProfiles) &#123; if (this.activeProfiles.isEmpty()) &#123; String profiles = getProperty(ACTIVE_PROFILES_PROPERTY_NAME); if (StringUtils.hasText(profiles)) &#123; setActiveProfiles(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(profiles))); &#125; &#125; return this.activeProfiles; &#125; &#125; ...&#125; 如果 activeProfiles 为空,则从 Properties 中获取 spring.profiles.active 配置;如果不为空，则调用 setActiveProfiles() 设置 profile,最后返回。 从这里可以知道，API设置的activeProfiles优先级第一，其次才是属性配置。 8:应用环境配置激活(@Profile和ProfileCondition)123456789@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(ProfileCondition.class)public @interface Profile &#123; String[] value();&#125; 从Spring4.0开始提供Conditional接口,该注解实现原理基于Condition条件接口,Condition条件接口计算结果实现类为ConditionEvaluator,该类是个内部类。 ProfileCondition 1234567891011121314151617181920class ProfileCondition implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; // 因为value值是个数组，所以此处有多个值 用的MultiValueMap MultiValueMap&lt;String, Object&gt; attrs = metadata.getAllAnnotationAttributes(Profile.class.getName()); if (attrs != null) &#123; for (Object value : attrs.get("value")) &#123; // 多个值中，但凡只要有一个acceptsProfiles了，那就返回true~ if (context.getEnvironment().acceptsProfiles(Profiles.of((String[]) value))) &#123; return true; &#125; &#125; return false; &#125; return true; &#125;&#125; @Profile的value可以指定多个值,并且只需要有一个值符合了条件,@Profile标注的方法、类就会生效，就会被加入到容器内。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Environment抽象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git分支的创建与合并]]></title>
    <url>%2F2019%2F08%2F05%2FGit%E5%88%86%E6%94%AF%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6%2F</url>
    <content type="text"><![CDATA[Git分支的创建与合并Git管理项目代码，常见流程。1.开发公司网站。 2.为了开发某个新功能新建一个分支（假如叫develop），并在该分支上进行开发。 3.接到测试组的Bug反馈，返回主分支，新建一个新的分支（bugFix），在该分支上修复Bug，然后与主分支master合并。 4.将分支切换回develop，继续开发新功能，结束后和主分支master合并。 分支的新建与切换假如公司网站项目已经开发了一段时间，并且使用Git提交了几次更新，提交历史如下图所示： 为了开发新的功能，新建分支develop并切换到该分支： 1234$ git branch develop$ git checkout developSwitched to branch 'develop' 也可以使用命令 git checkout -b 直接新建并切换： 12$ git checkout -b developSwitched to a new branch 'develop' 执行完上述命令后，仓库历史大致如下所示： Git新建了一个分支指针develop，然后将HEAD指向develop。 接下来在该分支上开心的开发新功能，比如新建了公司网站About页面，添加了内容然后提交了此次修改： 12345678$ vim About.html$ git add About.html$ git commit -a -m "add About.html page"[develop b462691] add About.html page 1 file changed, 12 insertions(+) create mode 100644 About.html 此时，仓库历史如下图所示： 这时候接到测试组公司网站主页index.html的Bug反馈，于是将分支切换回主分支master，然后新建分支bugFix，修复Bug，并提交该修复： 1234567891011$ git checkout masterSwitched to branch 'master'$ git checkout -b "bugFix"Switched to a new branch 'bugFix'$ vim index.html$ git commit -a -m "update index.html page"[bugFix 11a3074] update index.html page 1 file changed, 2 insertions(+), 2 deletions(-) 此时，仓库历史如下图所示： ` 假如确定Bug修复后，可以切换回master分支，然后将bugFix和master分支合并： 12345$ git merge bugFixUpdating e7ad858..11a3074Fast-forward index.html | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-) 合并时出现了“Fast forward”的提示。如果顺着一个分支走下去可以到达另一个分支的话，那么Git在合并两者时，只会简单地把指针右移，因为这种单线的历史分支不存在任何需要解决的分歧，所以这种合并过程可以称为快进（Fast forward）。 此时bugFix分支已经完成了历史使命，可以使用命令 git branch -d 将其删除： 合并master与bugFix，并删除bugFix分支后，仓库历史如下图所示： Bug修复后，切换回develop分支继续开发新的功能，并且提交： 分支合并和合并master分支与bugFix分支那样，合并master与develop分支过程也差不多： 1234567$ git checkout masterSwitched to branch 'master'$ git merge developMerge made by the 'recursive' strategy. About.html | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) 由于master指向的C4并不是develop指向C5的直接祖先C2，所以合并方式不是“Fast forward”，Git 会用两个分支的末端（C4 和 C5）以及它们的共同祖先（C2）进行一次简单的三方合并计算。 合并master和develop后，仓库历史如下图所示： 解决合并冲突假如在不同分支中都对同一个文件进行了修改，那么合并的时候就会发生冲突。比如在master分支和develop分支上都修改了About.html页面，然后进行分支合并： 1234$ git merge developAuto-merging About.htmlCONFLICT (content): Merge conflict in About.htmlAutomatic merge failed; fix conflicts and then commit the result. Git作了合并，但没有提交，它会停下来等你解决冲突。 可是使用命令 git status 查看哪些文件存在冲突： 123456789101112$ git statusOn branch masterYou have unmerged paths. (fix conflicts and run "git commit") (use "git merge --abort" to abort the merge)Unmerged paths: (use "git add &lt;file&gt;..." to mark resolution) both modified: About.htmlno changes added to commit (use "git add" and/or "git commit -a") 任何包含未解决冲突的文件都会以未合并（unmerged）的状态列出。编辑About.html页面，可看到文件包含类似下面部分的内容： 123456&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD &lt;footer&gt;2016~2017 All Rights Reserved&lt;/footer&gt;======= &lt;footer&gt;&amp;copy;2016~2017&lt;/footer&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; develop 可以看到 ======= 隔开的上半部分，是HEAD（即 master 分支，在运行merge命令时所切换到的分支）中的内容，下半部分是在develop分支中的内容。解决冲突的办法无非是二者选其一或者由你亲自整合到一起。 1&lt;footer&gt;&amp;copy; 2016~2017 All Rights Reserved&lt;/footer&gt; 转载:http://mrbird.cc/Git分支的创建与合并.html]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Component注解派生性原理]]></title>
    <url>%2F2019%2F08%2F04%2FComponent%E6%B3%A8%E8%A7%A3%E6%B4%BE%E7%94%9F%E6%80%A7%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[@Component注解的派生性原理1:模式注解Stereotype Annotation俗称为模式注解。Spring核心部分提供了几种内建的模式注解,如@Component,@Repository,@Service,@Controller,@Configuration等。这些注解均派生于@Component。 由于Java语言规定,Annotation不允许继承,没有类派生子类的特性,因此Spring采用元标注的方式实现注解之间的派生。 2:@Component派生性@Component注解作为Spring容器托管的通用模式组件,任何被@Component标注的组件均为组件扫描的候选对象。 任何论证过程离不开所处的环境,需要开发人员具备一定工程意识,包括软件版本,特性范围,兼容情况等。因此,论证过程从最低版本开始推导,逐步证明不同版本得提升和差异。 3:@Component注解派生性原理当ClassPathBeanDefinitionScanner#doScan(String... basePackages)调用时,它利用basePackages参数迭代执行的findCandidateComponents(String basePackage),每次执行结果都生成候选的BeanDefinition集合,即candidates变量。 123456789101112131415 public class ClassPathBeanDefinitionScanner extends ClassPathScanningCandidateComponentProvider&#123; ... protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, "At least one base package must be specified"); //获取候选的BeanDefinition集合 Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(); for (String basePackage : basePackages) &#123; Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); ... &#125; return beanDefinitions; &#125; ...&#125; 而findCandidateComponents(String basePackage)从父类ClassPathScanningCandidateComponentProvider 中继承。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class ClassPathScanningCandidateComponentProvider implements EnvironmentCapable, ResourceLoaderAware &#123; ... public Set&lt;BeanDefinition&gt; findCandidateComponents(String basePackage) &#123; Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;BeanDefinition&gt;(); try &#123; //获取查询的package,并处理占位符情况$&#123;...&#125;,转换为ClassLoader资源(.class)搜索路径 String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + resolveBasePackage(basePackage) + '/' + this.resourcePattern; Resource[] resources = this.resourcePatternResolver.getResources(packageSearchPath); ... //resource迭代执行,当资源可读取时,获取该资源的MetadataReader对象 for (Resource resource : resources) &#123; ... if (resource.isReadable()) &#123; try &#123; //包含了类和注解元信息读取方法 MetadataReader metadataReader = this.metadataReaderFactory.getMetadataReader(resource); //判断资源是否为候选的组件,通过excludeFilters和includeFilters进行判断 if (isCandidateComponent(metadataReader)) &#123; //基于ASM,支持AnnotatedBeanDefinition接口 ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader); sbd.setResource(resource); sbd.setSource(resource); //判断BeanDefinition是否候选组件 if (isCandidateComponent(sbd)) &#123; ... candidates.add(sbd); &#125; ... &#125; &#125; ... return candidates; &#125; ... /** * Determine whether the given class does not match any exclude filter * and does match at least one include filter. * @param metadataReader the ASM ClassReader for the class * @return whether the class qualifies as a candidate component */ protected boolean isCandidateComponent(MetadataReader metadataReader) throws IOException&#123; for (TypeFilter tf : this.excludeFilters) &#123; if (tf.match(metadataReader, this.metadataReaderFactory)) &#123; return false; &#125; &#125; for (TypeFilter tf : this.includeFilters) &#123; if (tf.match(metadataReader, this.metadataReaderFactory)) &#123; return isConditionMatch(metadataReader); &#125; &#125; return false; &#125; /** * Determine whether the given bean definition qualifies as candidate. * &lt;p&gt;The default implementation checks whether the class is not an interface * and not dependent on an enclosing class. * &lt;p&gt;Can be overridden in subclasses. * @param beanDefinition the bean definition to check * @return whether the bean definition qualifies as a candidate component */ protected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) &#123; AnnotationMetadata metadata = beanDefinition.getMetadata(); return (metadata.isIndependent() &amp;&amp; (metadata.isConcrete() || (metadata.isAbstract() &amp;&amp; metadata.hasAnnotatedMethods(Lookup.class.getName())))); &#125; /** * Register the default filter for &#123;@link Component @Component&#125;. * &lt;p&gt;This will implicitly register all annotations that have the * &#123;@link Component @Component&#125; meta-annotation including the * &#123;@link Repository @Repository&#125;, &#123;@link Service @Service&#125;, and * &#123;@link Controller @Controller&#125; stereotype annotations. * &lt;p&gt;Also supports Java EE 6's &#123;@link javax.annotation.ManagedBean&#125; and * JSR-330's &#123;@link javax.inject.Named&#125; annotations, if available. * */ @SuppressWarnings("unchecked") protected void registerDefaultFilters() &#123; this.includeFilters.add(new AnnotationTypeFilter(Component.class)); ClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader(); try &#123; this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation&gt;) ClassUtils.forName("javax.annotation.ManagedBean", cl)), false)); ... &#125; try &#123; this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation&gt;) ClassUtils.forName("javax.inject.Named", cl)), false)); ... &#125; &#125;&#125; 默认情况下,ClassPathScanningCandidateComponentProvider构造参数useDefaultFilters为true,并且显示传递给父类构造参数。该方法给属性includeFilters增添了@Component类型AnnotationTypeFilter的TypeFilter。 ClassPathBeanDefinitionScanner默认过滤器引入标注@Component,@Repository,@Service或者@Controller等类。同理,它也能够标注所有@Component的&quot;派生&quot;注解。 @Component注解只包含一个value属性定义，所以其“派生”的注解也只能包含一个vlaue属性定义。 Dubbo实现@Service注解扫描实例: ClassPathBeanDefinitionScanner允许自定义类型过滤规则。因此,Dubbo的@Service没有标注@Component情况下，通过scanner.addIncludeFilter(new AnnotationTypeFilter(Service.class))方式达到识别@Service标注类情况。但是没有使用@Component注解的派生性。 Mybatis实现@Mapper注解扫描实例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class ClassPathMapperScanner extends ClassPathBeanDefinitionScanner&#123; ... public ClassPathMapperScanner(BeanDefinitionRegistry registry) &#123; super(registry, false); &#125; /** * Configures parent scanner to search for the right interfaces. It can search * for all interfaces or just for those that extends a markerInterface or/and * those annotated with the annotationClass */ public void registerFilters() &#123; boolean acceptAllInterfaces = true; // if specified, use the given annotation and / or marker interface if (this.annotationClass != null) &#123; addIncludeFilter(new AnnotationTypeFilter(this.annotationClass)); acceptAllInterfaces = false; &#125; // override AssignableTypeFilter to ignore matches on the actual marker interface if (this.markerInterface != null) &#123; addIncludeFilter(new AssignableTypeFilter(this.markerInterface) &#123; @Override protected boolean matchClassName(String className) &#123; return false; &#125; &#125;); acceptAllInterfaces = false; &#125; if (acceptAllInterfaces) &#123; // default include filter that accepts all classes addIncludeFilter(new TypeFilter() &#123; @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; return true; &#125; &#125;); &#125; // exclude package-info.java addExcludeFilter(new TypeFilter() &#123; @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; String className = metadataReader.getClassMetadata().getClassName(); return className.endsWith("package-info"); &#125; &#125;); &#125; /** * &#123;@inheritDoc&#125; */ @Override protected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) &#123; return beanDefinition.getMetadata().isInterface() &amp;&amp; beanDefinition.getMetadata().isIndependent(); &#125; private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &#123; definition = (GenericBeanDefinition) holder.getBeanDefinition(); ... //复杂对象构建考虑使用FactoryBean接口 // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean //添加泛型参数 definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); // issue #59 definition.setBeanClass(this.mapperFactoryBean.getClass()); definition.getPropertyValues().add("addToConfig", this.addToConfig); ... &#125; &#125; ...&#125; 4:思考扩展思考1:利用ClassPathBeanDefinitionScanner类配合includeFilters和excludeFilters定制化批量注册Bean到Spring容器中。常常可以通过注解方式来包含或者排除候选类。 TypeFilter常用实现 AnnotationTypeFilter:注解类型过滤器 AssignableTypeFilter:确定此对象表示的类或者接口是否为给定类或者接口相同。 RegexPatternTypeFilter:判断给定的类名是否符合指定正则表达式。 思考2:复杂对象构建考虑使用FactoryBean实现类。 思考3:如果是读取类和注解信息可以考虑基于ASM或者反射,使用方式往下可以获取。当获取已加载的类信息可以考虑反射(反射大前提是被反射的Class被ClassLoader加载),ASM用于不需要将类路径package下的Class全部加载,Spring应用指定Java package扫描Spring模式注解时,利用的就是基于ASM方式获取类或者注解信息。基于ASM获取会获得更大性能。 思考4:资源读取考虑使用ResourcePatternResolver,这个对象的获取可以通过Spring提供的工具类 ResourcePatternUtils.getResourcePatternResolver(resourceLoader)。在使用的时候,考虑处理 占位符${...}的情况,注意资源是否可读。 5:多层次@Component派生性(1):具体发展过程不再细说,详解请看SpringBoot编程思想这本书。其多层次@Component注解派生性构建在Spring4.x。其核心处理类为AnnotationMetadataReadingVisitor,其采用递归的方式查找元注解。 (2):Spring中,MetadataReader接口唯一实现非公开类SimpleMetadataReader。可以通过SimpleMetadataReaderFactory(ASM字节码操作)和CachingMetadataReaderFactory获取。 其中在SimpleMetadataReader实现上看,ClassMetadataReadingVisitor和AnnotationMetadataReadingVisitor分别是ClassMetadatta和AnnotationMetadata实现类。 由于ClassPathBeanDefinitionScanner在寻找候选的BeanDefinition过程中,将指定basePackage参数下 的*.class资源进行元信息解析,也就是ClassMetadata和AnnotationMetadata对象。 AnnotationMetadataReadingVisitor实现上使用了AnnotationAttributesReadingVisitor，该类主要实现方法是visitEnd()。Spring2.5实现未采用层次递归获取Annotation[],所以仅支持单层次的@Component派生。Spring3.x实现仅两层@Component派生。Spring4.x开始采用递归方式查找元注解。 (3):思考扩展 考虑使用ASM的方式读取类或者注解相关信息。(不需要全部将指定路径下的类加载) MetadataReaderFactory:获取MetadataReader工厂 SimpleMetadataReaderFactory:简单获取MetadataReader工厂实现 ClassReader:基于ASM读取类相关信息,公开类,不建议单独使用。 AnnotationMetadataReadingVisitor:基于ASM读取注解元数据相关信息,不建议单独使用。 MethodMetadataReadingVisitor:基于ASM读取方法相关信息,不建议单独使用。 CachingMetadataReaderFactory:继承SimpleMetadataReaderFactory,增加缓存MetadataReader资源功能。 MetadataReader:获取访问类和注解相关信息。通过MetadataReaderFactory获取。 Resource getResource():获取类文件资源引用 ClassMetadata getClassMetadata():读取基础类的基本元数据 AnnotationMetadata getAnnotationMetadata():读取底层类完整注解元数据,包含注解方法的注解元数据。 考虑使用反射的方式读取类或者注解相关信息(比较费时而且该类必须被ClassLoader加载) StandardClassMetadata:基于反射读取类元数据,可建议单独使用。 StandardAnnotationMetadata:基于反射读取注解元数据,可建议单独使用 StandardMethodMetadata:基于反射读取方法元数据,可建议单独使用 考虑使用Spring内部支持的有用工具类,都是来自于spring-core包中。多使用spring内建API,学习他们的长处。 ClassUtils:类工具类 CollectionUtils:集合工具类 NumberUtils:Number工具类 MimeTypeUtils:媒体类型工具类 IdGenerator:Id生成器 StringUtils:字符串工具类 ResourceUtils:资源工具类 ReflectionUtils:反射工具类 MethodIntrospector:方法自省工具类(EventListenerMethodProcessor#processBean中有使用) PatternMatchUtils:正则资源匹配工具类 ObjectUtils:对象工具类 3:组合注解组合注解指某个注解”元标注”一个或多个其他注解，其目的在于将这些关联的注解行为组合成单个自定义注解。 Spring Framework的类加载通过ASM实现，如ClassReader。相对于ClassLoader体系，Spring ASM更为底层，读取的是类资源，直接操作其中的字节码，获取相关元信息。如MetadataReader接口。 1234567891011121314151617181920212223242526/** * Simple facade for accessing class metadata, * as read by an ASM &#123;@link org.springframework.asm.ClassReader&#125;. * * @author Juergen Hoeller * @since 2.5 */public interface MetadataReader &#123; /** * Return the resource reference for the class file. */ Resource getResource(); /** * Read basic class metadata for the underlying class. */ ClassMetadata getClassMetadata(); /** * Read full annotation metadata for the underlying class, * including metadata for annotated methods. */ AnnotationMetadata getAnnotationMetadata();&#125; AnnotationMetadataReadingVisitor同时实现了ClassMetadata及AnnotationMetadata。因此，元注解的实现集中到AnnotationMetadataReadingVisitor和AnnotationAttributesReadingVisitor之中。 MetadataReader对象通过MetadataReaderFactory对象获取。 12345678910111213141516171819202122232425262728/** * Factory interface for &#123;@link MetadataReader&#125; instances. * Allows for caching a MetadataReader per original resource. * * @author Juergen Hoeller * @since 2.5 * @see SimpleMetadataReaderFactory * @see CachingMetadataReaderFactory */public interface MetadataReaderFactory &#123; /** * Obtain a MetadataReader for the given class name. * @param className the class name (to be resolved to a ".class" file) * @return a holder for the ClassReader instance (never &#123;@code null&#125;) * @throws IOException in case of I/O failure */ MetadataReader getMetadataReader(String className) throws IOException; /** * Obtain a MetadataReader for the given resource. * @param resource the resource (pointing to a ".class" file) * @return a holder for the ClassReader instance (never &#123;@code null&#125;) * @throws IOException in case of I/O failure */ MetadataReader getMetadataReader(Resource resource) throws IOException;&#125; 具体某个注解的元注解信息则通过getMetaAnnotationTypes(String)方法查询。 AnnotationMetadata实现AnnotationMetadataReadingVisitor(ASM实现)，StandardAnnotationMetadata(反射)。 注解元信息抽象:AnnotationMetadata AnnotationMetadataReadingVisitor AnnotationAttributesReadingVisitor(递归查找元注解) 类元信息抽象:ClassMetadata 方法元信息抽象:MethodMetadata 注解属性抽象:AnnotationAttributes 属性环境抽象:Environment 属性文件抽象:PropertySource 元信息读取抽象:MetadataReader 通过MetadataReaderFactory获取 方法内省:MethodIntrospector 1234Map&lt;Method, EventListener&gt; annotatedMethods = null; annotatedMethods = MethodIntrospector.selectMethods(targetType, (MethodIntrospector.MetadataLookup&lt;EventListener&gt;) method -&gt; AnnotatedElementUtils.findMergedAnnotation(method, EventListener.class)); 注解工具类:AnnotationUtils]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Spring注解属性抽象AnnotationAttributes</tag>
        <tag>模式注解</tag>
        <tag>Component注解派生性原理</tag>
      </tags>
  </entry>
</search>
